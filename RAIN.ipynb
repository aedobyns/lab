{
 "metadata": {
  "name": "",
  "signature": "sha256:48124a2a22fd5ea71669f535633e032baf0a2dd96bab222b1d603e9f13872c8e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "initialization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "from scipy import signal, fft, arange\n",
      "import matplotlib.pyplot as plt\n",
      "from pandas import Series, DataFrame\n",
      "import pandas as pd\n",
      "import sys\n",
      "import matplotlib.patches as patches\n",
      "import time as t\n",
      "import sys\n",
      "import os, errno\n",
      "from numpy import NaN, Inf, arange, isscalar, asarray, array\n",
      "from matplotlib.widgets import *\n",
      "import datetime\n",
      "from matplotlib import cbook\n",
      "from scipy.signal import butter, lfilter\n",
      "from __future__ import division\n",
      "from math import log\n",
      "#\n",
      "#Upload\n",
      "#Data and Settings. \n",
      "#\n",
      "def mkdir_p(path):\n",
      "    '''\n",
      "    This function creates a folder at the end of the specified path, unless the folder already exsists. \n",
      "    '''\n",
      "    try:\n",
      "        os.makedirs(path)\n",
      "    except OSError as exc: # Python >2.5\n",
      "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
      "            pass\n",
      "        else: raise\n",
      "            \n",
      "def load_data():\n",
      "    '''\n",
      "    this function loads in the data file, which should be a single wave in a tab seperated text file with no header.\n",
      "    '''\n",
      "    load_path = raw_input(\"Full File Path for data input: \")\n",
      "    path = raw_input(\"Full File Path for data output: \")\n",
      "\n",
      "    if path[-1] == '/':\n",
      "        path = path[:-1]\n",
      "\n",
      "    folder = raw_input(\"Sample Name: \")\n",
      "    #rate = float(raw_input(\"Sample rate in seconds/frame: \"))\n",
      "\n",
      "    time, data = np.loadtxt(load_path, delimiter=\"\\t\", usecols=(0,1),  unpack=True)\n",
      "    mkdir_p(path+'/'+folder)\n",
      "    rate = time[1] - time[0] #changed so that there isn't a prompt for it\n",
      "\n",
      "    Settings = {'Uploaded File Location':load_path, 'Save Location':path, \n",
      "                'Sample Folder':folder, 'Sample Rate (s/frame)':rate} \n",
      "    #this is the object that will contain all information about the analysis that was performed. it is saved out as a CSV later. \n",
      "    #A new one is initialized everytime the data is loaded in.\n",
      "\n",
      "    Data = {'original':Series(data = data, index = time)}\n",
      "    Results = {} #make this here to clean all old results\n",
      "\n",
      "    print 'Sample',folder, 'is', (time[-1]-time[0]), 'seconds long'\n",
      "    return Data, Settings, Results\n",
      "\n",
      "def string_eval(string):\n",
      "    try:\n",
      "        num = float(string)\n",
      "        return num\n",
      "    except ValueError:\n",
      "        return string\n",
      "\n",
      "def load_settings(Settings):\n",
      "    '''\n",
      "    '''\n",
      "    from ast import literal_eval\n",
      "    load_set_path = raw_input(\"Full File Path for Settings file: \")\n",
      "    \n",
      "    settings_temp = pd.read_csv(load_set_path, index_col=0, header=0)\n",
      "    exclusion_list = ['Uploaded File Location', 'Sample Folder', \n",
      "                      'Sample Rate (s/frame)', 'Save Location', \n",
      "                      'Baseline', 'Baseline rolling', 'Settings File']\n",
      "    settings_temp = settings_temp.ix[:,0]\n",
      "    for key, val in settings_temp.iteritems():\n",
      "        \n",
      "        if key in exclusion_list:\n",
      "            continue\n",
      "        else:\n",
      "            #print key, val\n",
      "            Settings[key] = string_eval(val)\n",
      "            \n",
      "            if val == 'True':\n",
      "                Settings[key] = True\n",
      "            if val == 'False':\n",
      "                Settings[key] = False\n",
      "                \n",
      "    Settings['Settings File'] = load_set_path\n",
      "    return Settings\n",
      "\n",
      "def display_settings(Settings):\n",
      "    '''\n",
      "    '''\n",
      "    Settings_copy = Settings.copy()\n",
      "    \n",
      "    if 'Baseline rolling' in Settings_copy.keys():\n",
      "        Settings_copy['Baseline rolling'] = True\n",
      "    Settings_copy = DataFrame.from_dict(Settings_copy, orient='index')\n",
      "    Settings_copy.columns = ['Value']\n",
      "    Settings_copy = Settings_copy.sort()\n",
      "    return Settings_copy\n",
      "\n",
      "#\n",
      "#Transform\n",
      "#wrappers and functions\n",
      "#\n",
      "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
      "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
      "    The Savitzky-Golay filter removes high frequency noise from data.\n",
      "    It has the advantage of preserving the original shape and\n",
      "    features of the signal better than other types of filtering\n",
      "    approaches, such as moving averages techniques.\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array_like, shape (N,)\n",
      "        the values of the time history of the signal.\n",
      "    window_size : int\n",
      "        the length of the window. Must be an odd integer number.\n",
      "    order : int\n",
      "        the order of the polynomial used in the filtering.\n",
      "        Must be less then `window_size` - 1.\n",
      "    deriv: int\n",
      "        the order of the derivative to compute (default = 0 means only smoothing)\n",
      "    Returns\n",
      "    -------\n",
      "    ys : ndarray, shape (N)\n",
      "        the smoothed signal (or it's n-th derivative).\n",
      "    Notes\n",
      "    -----\n",
      "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
      "    suited for smoothing noisy data. The main idea behind this\n",
      "    approach is to make for each point a least-square fit with a\n",
      "    polynomial of high order over a odd-sized window centered at\n",
      "    the point.\n",
      "    Examples\n",
      "    --------\n",
      "    t = np.linspace(-4, 4, 500)\n",
      "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
      "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.plot(t, y, label='Noisy signal')\n",
      "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
      "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
      "       Data by Simplified Least Squares Procedures. Analytical\n",
      "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
      "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
      "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
      "       Cambridge University Press ISBN-13: 9780521880688\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from math import factorial\n",
      "\n",
      "    try:\n",
      "        window_size = np.abs(np.int(window_size))\n",
      "        order = np.abs(np.int(order))\n",
      "    except ValueError, msg:\n",
      "        raise ValueError(\"window_size and order have to be of type int\")\n",
      "    if window_size % 2 != 1 or window_size < 1:\n",
      "        raise TypeError(\"window_size size must be a positive odd number\")\n",
      "    if window_size < order + 2:\n",
      "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
      "    order_range = range(order+1)\n",
      "    half_window = (window_size -1) // 2\n",
      "    # precompute coefficients\n",
      "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
      "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
      "    # pad the signal at the extremes with\n",
      "    # values taken from the signal itself\n",
      "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
      "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
      "    y = np.concatenate((firstvals, y, lastvals))\n",
      "    return np.convolve( m[::-1], y, mode='valid')\n",
      "\n",
      "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
      "    nyq = 0.5 * fs\n",
      "    low = lowcut / nyq\n",
      "    high = highcut / nyq\n",
      "    b, a = butter(order, [low, high], btype='band')\n",
      "    return b, a\n",
      "\n",
      "\n",
      "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
      "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
      "    y = lfilter(b, a, data)\n",
      "    return y\n",
      "def user_input_trans(settings):\n",
      "    '''\n",
      "    this function allows the user to specify and save their settings for later \n",
      "    analysis in an interactive way.\n",
      "    The only argument passed in and out is the Settings Dictionary.\n",
      "    '''\n",
      "    \n",
      "    #print \"Enter the parameters of the functions you would like to use to transform your data. \"\n",
      "    #print \"If you do not want to use a function, enter 'none'\"\n",
      "    \n",
      "    if 'Linear Fit' in Settings.keys():\n",
      "        print \"Previous Linear Fit setting: %s\" %Settings['Linear Fit']\n",
      "    lin_param1 = linear_settings()\n",
      "    settings['Linear Fit'] = lin_param1\n",
      "    \n",
      "    if 'Bandpass Lowcut' in Settings.keys():\n",
      "        print \"Previous Bandpass setting: %s, %s, %s\" %(Settings['Bandpass Lowcut'], \n",
      "                                                        Settings['Bandpass Highcut'], \n",
      "                                                        Settings['Bandpass Polynomial'])\n",
      "    lowcut, highcut, poly_band = bandpass_settings()\n",
      "    settings['Bandpass Lowcut'] = lowcut\n",
      "    settings['Bandpass Highcut'] = highcut\n",
      "    settings['Bandpass Polynomial'] = poly_band\n",
      "    \n",
      "    if 'Savitzky-Golay Window Size' in Settings.keys():\n",
      "        print \"Previous Savitzky-Golay setting: %s, %s\" %(Settings['Savitzky-Golay Window Size'], \n",
      "                                                        Settings['Savitzky-Golay Polynomial'])\n",
      "    window_sav, poly_sav = savgolay_settings()\n",
      "    settings['Savitzky-Golay Window Size'] = window_sav\n",
      "    settings['Savitzky-Golay Polynomial'] = poly_sav\n",
      "    \n",
      "    if window_sav != 'none':\n",
      "        settings['Absolute Value'] = True\n",
      "    \n",
      "    else:\n",
      "        if 'Absolute Value' in Settings.keys():\n",
      "            print \"Previous Absolute Value: %s\" %Settings['Absolute Value']\n",
      "        abs_set = abs_settings()\n",
      "        settings['Absolute Value'] = abs_set\n",
      "    \n",
      "    print \"Settings Saved\"\n",
      "    return settings\n",
      "\n",
      "def savgolay_settings():\n",
      "    print \"Enter the Savitzky Golay filter settings seperated by a comma. Window size must be odd.\"\n",
      "    \n",
      "    temp_list = raw_input(\"Savitzky Golay Settings (window, polynomial): \").lower()\n",
      "    \n",
      "    temp_list = temp_list.split(',')\n",
      "    \n",
      "    if temp_list[0] == \"none\" or temp_list[0] == \"false\":\n",
      "        window = \"none\"\n",
      "        poly = \"none\"\n",
      "    else:\n",
      "        window = int(temp_list[0])\n",
      "        poly = int(temp_list[1])\n",
      "    return window, poly\n",
      "    '''\n",
      "    if len(temp_list) != 2:\n",
      "        print \"ERROR: There should be two parameters separated by a comma.\"\n",
      "        print \" \"\n",
      "        savgolay_settings()\n",
      "    if window % 2 == 0:\n",
      "        print \"ERROR: window size must be odd.\"\n",
      "        print \" \"\n",
      "        savgolay_settings()\n",
      "    '''\n",
      "def bandpass_settings():\n",
      "    print \"Enter the butterworth bandpass settings seperated by a comma. cuts are in hertz and poly should be an interger.\"\n",
      "    \n",
      "    temp_list = raw_input(\"Bandpass Settings (lowcut, highcut,polynomial): \").lower()\n",
      "    \n",
      "    temp_list = temp_list.split(',')\n",
      "    \n",
      "    if temp_list[0] == \"none\" or temp_list[0] == \"false\":\n",
      "        lowcut = \"none\"\n",
      "        highcut = \"none\"\n",
      "        poly = \"none\"\n",
      "    else:\n",
      "        lowcut = float(temp_list[0])\n",
      "        highcut = float(temp_list[1])\n",
      "        poly = int(temp_list[2])\n",
      "    return lowcut, highcut, poly\n",
      "\n",
      "def abs_settings():\n",
      "    print \"Enter True or False to turn on or off the absolute value.\"\n",
      "    abs_set = raw_input(\"Absolute Value (True/False): \").lower()\n",
      "    \n",
      "    if abs_set == \"true\":\n",
      "        abs_set = True\n",
      "    else:\n",
      "        abs_set = False\n",
      "    return abs_set\n",
      "\n",
      "def linear_settings():\n",
      "    print \"Enter True or False to turn on or off the linear fit.\"\n",
      "    lin_param = raw_input(\"Linear Fit (True/False): \").lower()\n",
      "    \n",
      "    if lin_param == \"true\":\n",
      "        lin_param = True\n",
      "    else:\n",
      "        lin_param = False\n",
      "    return lin_param\n",
      "\n",
      "def linear_subtraction(data):\n",
      "    '''\n",
      "    '''\n",
      "    time = arange(len(data)) #arb time array, each val an int\n",
      "\n",
      "    A = np.vstack([time, np.ones(len(time))]).T #matrix required for solving the lstsq, which we want for the fit\n",
      "    m, c = np.linalg.lstsq(A, data)[0] # find coef. for the y = m*x + c equation\n",
      "\n",
      "    count = 0\n",
      "    ls_tf = []\n",
      "\n",
      "    for point in data: #this is the line subtraction\n",
      "        x = (m * count) + c \n",
      "        y = point - x\n",
      "        ls_tf.append(y)\n",
      "        count = count +1\n",
      "    \n",
      "    return np.array(ls_tf)\n",
      "    \n",
      "def transform_wrapper(Data, Settings):\n",
      "    '''\n",
      "    wrapper for RAIN\n",
      "    '''\n",
      "    Data['trans'] = DataFrame(index = Data['original'].index)\n",
      "    for label, column in Data['original'].iteritems():\n",
      "        data_trans = transformation(column, Settings)\n",
      "        Data['trans'][label] = data_trans\n",
      "    return Data\n",
      "\n",
      "def transformation(Data, Settings):\n",
      "    \n",
      "    data_trans = np.array(Data)\n",
      "    \n",
      "    if Settings['Linear Fit'] == True:\n",
      "        data_trans = linear_subtraction(data_trans)\n",
      "        \n",
      "    if Settings['Bandpass Lowcut'] != 'none':\n",
      "        data_trans = butter_bandpass_filter(data_trans, Settings['Bandpass Lowcut'], \n",
      "                                            Settings['Bandpass Highcut'], \n",
      "                                            1/Settings['Sample Rate (s/frame)'], \n",
      "                                            order= Settings['Bandpass Polynomial'])\n",
      "    \n",
      "    if Settings['Absolute Value'] == True:\n",
      "        data_trans = abs(data_trans)\n",
      "    \n",
      "    if Settings['Savitzky-Golay Window Size'] != 'none':\n",
      "        data_trans =savitzky_golay(data_trans, Settings['Savitzky-Golay Window Size'], \n",
      "                                   Settings['Savitzky-Golay Polynomial'])\n",
      "    \n",
      "    #baseline and thresholding is moved to its own call threshold()\n",
      "    #base, data_shift =baseline(data_trans,settings['Sample Rate (s/frame)']) \n",
      "    #settings['Baseline'] = base\n",
      "    \n",
      "    #data_trans = Series(data = data_trans, index = Data['original'].index)\n",
      "    #Data['trans'] = data_trans\n",
      "    #graph_trans(Data)\n",
      "    return data_trans\n",
      "\n",
      "def graph_trans(Data):\n",
      "    figure = plt.plot(Data['trans'].index, Data['trans'], 'k')\n",
      "    plt.title('Transformed Data')\n",
      "    plt.xlabel('Time (s)')\n",
      "    plt.ylabel('Relative Amplitude')\n",
      "    DataCursor(figure)\n",
      "    plt.show(figure)\n",
      "\n",
      "#\n",
      "#Baseline\n",
      "#\n",
      "#\n",
      "def user_input_base(Settings):\n",
      "    '''\n",
      "    \n",
      "    '''\n",
      "    if 'Baseline Type' in Settings.keys():\n",
      "        print \"Previous Baseline Type: %s\" %Settings['Baseline Type']\n",
      "        \n",
      "    baseline_type = raw_input('Enter Linear or Rolling: ').lower()\n",
      "    \n",
      "    if baseline_type == 'linear':\n",
      "        print \"Linear baseline is NOT recommended. Use rolling instead. Really, you'll be happier for it.\"\n",
      "        Settings['Baseline Type'] = baseline_type\n",
      "    \n",
      "    elif baseline_type == 'linear' or baseline_type == 'rolling':\n",
      "        \n",
      "        Settings['Baseline Type'] = baseline_type\n",
      "        if 'Rolling Baseline Window' in Settings.keys():\n",
      "            print \"Previous Rolling Baseline Window: %s\" %Settings['Rolling Baseline Window']\n",
      "        print \"Enter the window size of the rolling baseline in milliseconds.\"\n",
      "        Settings['Rolling Baseline Window'] = float(raw_input('Window size in ms: '))\n",
      "        window = float(Settings['Rolling Baseline Window'])\n",
      "        \n",
      "        #convert window (ms) to index\n",
      "        window = int((window/1000.0)/Settings['Sample Rate (s/frame)'])\n",
      "        \n",
      "        if window < 2:\n",
      "            print (\"You entered a window size so small it won't run. Give me a larger window size.\")\n",
      "            user_input_base(Settings)\n",
      "    \n",
      "    else:\n",
      "        print 'That was not an acceptable baseline type. Try again.'\n",
      "        user_input_base(Settings)\n",
      "    return Settings\n",
      "\n",
      "def baseline(Data, Settings):\n",
      "    '''\n",
      "    asks the user which type of thresholding they'd like to use: linear or rolling.\n",
      "    linear baseline assumes that the first .1s of data are 'baseline' and not an event\n",
      "    rolling will take a moving average of a given window size, but will clip one window \n",
      "    length of data (half of the window size from each end)\n",
      "    returns an array (either shift or rolling mean), the Settings dict, and the time and data_trans arrays (which are modified)\n",
      "    '''\n",
      "    if Settings['Baseline Type'] == 'linear':\n",
      "        base, data_shift =baseline_lin(np.array(Data['trans']),\n",
      "                                       Settings['Sample Rate (s/frame)'])\n",
      "        Settings['Baseline'] = base\n",
      "        data_shift = Series(data = data_shift, index = Data['original'].index)\n",
      "        Data['shift'] = data_shift\n",
      "        #return data_shift, Settings, time, data_trans\n",
      "    \n",
      "    elif Settings['Baseline Type'] == 'rolling':\n",
      "           \n",
      "        rolling_mean, data_roll, time_roll = baseline_rolling(Data['original'].index, \n",
      "                                                              np.array(Data['trans']), \n",
      "                                                              Settings['Rolling Baseline Window'])\n",
      "        data_roll = Series(data = data_roll, index = time_roll)\n",
      "        rolling_mean = Series(data = rolling_mean, index = time_roll)\n",
      "        Data['rolling'] = data_roll\n",
      "        Settings['Baseline rolling'] = rolling_mean\n",
      "        \n",
      "    graph_baseline(Data, Settings)\n",
      "    return Data, Settings\n",
      "\n",
      "def baseline_lin(data,rate):\n",
      "    '''\n",
      "    input data array (list) and rate value (capture rate in seconds), returns the baserate average and the shifted data array.\n",
      "    using the first 0.1 s of data, find average of all data values. this becomes the baseline. \n",
      "    this means that the first 0.5 seconds of data MUST be clean and not include and event.\n",
      "    baseline is used later in burst measurements\n",
      "    import numpy as np\n",
      "    '''\n",
      "    \n",
      "    index = 0.1/rate #find the index of the first 0.1 seconds of data\n",
      "    baserate = np.mean(data[:index]) #average all points to obtain baserate\n",
      "    \n",
      "    datashift = []\n",
      "    \n",
      "    #may be able to use np.subtract(data,base) instead, but this seems to work correctly.\n",
      "    for x in data:\n",
      "        foo = (x-baserate)\n",
      "        datashift.append(foo)\n",
      "        \n",
      "    return abs(baserate), datashift\n",
      "        \n",
      "def baseline_rolling(time, data_trans, window):\n",
      "    \n",
      "    rolling_mean = pd.rolling_mean(data_trans, window)\n",
      "    \n",
      "    time = time[(window/2):-(window/2)]\n",
      "    data_trans = data_trans[(window/2):-(window/2)]\n",
      "    rolling_mean = rolling_mean[window:]\n",
      "    \n",
      "    #sanity check\n",
      "    if len(data_trans) != len(rolling_mean):\n",
      "        raise Exception(\"Something has gone horribly wrong. The data arrays are no longer the same size nor aligning. Restart the notebooke and try again.\")\n",
      "    return rolling_mean, data_trans, time\n",
      "\n",
      "def graph_baseline(Data, Settings):\n",
      "    '''\n",
      "    plot the results of the baseline thresholding. will handle both linear and rolling\n",
      "    '''\n",
      "    \n",
      "    if Settings['Baseline Type'] == 'linear':\n",
      "        \n",
      "        plt.plot(Data['shift'].index, Data['shift'], 'k') #in this instance, baseline = shift\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Amp')\n",
      "        plt.hlines(0,Data['shift'].index[0],Data['shift'].index[-1],colors='b')\n",
      "        #plt.xlim(xmin = min(time), xmax = (min(time)+10))\n",
      "        #plt.ylim(ymin = min(data_baseline), ymax = max(data_baseline))\n",
      "        plt.title('Linear Baseline')\n",
      "\n",
      "        plt.show()\n",
      "    \n",
      "    elif Settings['Baseline Type'] == 'rolling':\n",
      "        \n",
      "        plt.plot(Data['rolling'].index, Data['rolling'], 'k')\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Amp')\n",
      "        plt.plot(Settings['Baseline rolling'].index, Settings['Baseline rolling'], 'b') #in this instance, baseline = rolling average\n",
      "        plt.title('Rolling Baseline')\n",
      "        #plt.xlim(xmin = min(time), xmax = (min(time)+10))\n",
      "       # plt.ylim(ymin = min(data_baseline), ymax = max(data_baseline))\n",
      "        \n",
      "        plt.show()\n",
      "\n",
      "#\n",
      "#Event-Peak Detection\n",
      "#\n",
      "#\n",
      "\n",
      "def peakdet(v, delta, x = None):\n",
      "    \"\"\"\n",
      "    Converted from MATLAB script at http://billauer.co.il/peakdet.html\n",
      "    \n",
      "    Returns two arrays\n",
      "    \n",
      "    function [maxtab, mintab]=peakdet(v, delta, x)\n",
      "    %PEAKDET Detect peaks in a vector\n",
      "    %        [MAXTAB, MINTAB] = PEAKDET(V, DELTA) finds the local\n",
      "    %        maxima and minima (\"peaks\") in the vector V.\n",
      "    %        MAXTAB and MINTAB consists of two columns. Column 1\n",
      "    %        contains indices in V, and column 2 the found values.\n",
      "    %      \n",
      "    %        With [MAXTAB, MINTAB] = PEAKDET(V, DELTA, X) the indices\n",
      "    %        in MAXTAB and MINTAB are replaced with the corresponding\n",
      "    %        X-values.\n",
      "    %\n",
      "    %        A point is considered a maximum peak if it has the maximal\n",
      "    %        value, and was preceded (to the left) by a value lower by\n",
      "    %        DELTA.\n",
      "    \n",
      "    % Eli Billauer, 3.4.05 (Explicitly not copyrighted).\n",
      "    % This function is released to the public domain; Any use is allowed.\n",
      "    \n",
      "    \"\"\"\n",
      "    maxtab = []\n",
      "    mintab = []\n",
      "       \n",
      "    if x is None:\n",
      "        x = arange(len(v))\n",
      "    \n",
      "    v = asarray(v)\n",
      "    \n",
      "    if len(v) != len(x):\n",
      "        raise Exception('Input vectors v and x must have same length')\n",
      "    \n",
      "    if not isscalar(delta):\n",
      "        raise Exception('Input argument delta must be a scalar')\n",
      "    \n",
      "    if delta <= 0:\n",
      "        raise Exception('Input argument delta must be positive')\n",
      "    \n",
      "    mn, mx = Inf, -Inf\n",
      "    mnpos, mxpos = NaN, NaN\n",
      "    \n",
      "    lookformax = False #why set to True in original text?\n",
      "    \n",
      "    for i in arange(len(v)):\n",
      "        this = v[i]\n",
      "        if this > mx:\n",
      "            mx = this\n",
      "            mxpos = x[i]\n",
      "        if this < mn:\n",
      "            mn = this\n",
      "            mnpos = x[i]\n",
      "        \n",
      "        if lookformax:\n",
      "            if this < mx-delta:\n",
      "                maxtab.append((mxpos, mx))\n",
      "                mn = this\n",
      "                mnpos = x[i]\n",
      "                lookformax = False\n",
      "        else:\n",
      "            if this > mn+delta:\n",
      "                mintab.append((mnpos, mn))\n",
      "                mx = this\n",
      "                mxpos = x[i]\n",
      "                lookformax = True\n",
      " \n",
      "    return array(maxtab), array(mintab)\n",
      "\n",
      "def rrinterval(maxptime): \n",
      "    \"\"\"\n",
      "    find time from r peak to r peak, called the R-R interval. Input array must be a list of numbers (float).\n",
      "    \"\"\"\n",
      "    maxptime = maxptime.tolist()\n",
      "    \n",
      "    rrint = [] #empty array for ttot to go into\n",
      "    \n",
      "    for time in maxptime[1:]: #for each r peak, starting with the second one\n",
      "        s2time = maxptime.index(time) \n",
      "        s2 = maxptime[s2time-1]\n",
      "        meas = time - s2 #measure the interval by subtracting\n",
      "        rrint.append(meas) #append the measurement to the ttotal array\n",
      "    return rrint #return array\n",
      "\n",
      "#\n",
      "#Event-Burst Detection\n",
      "#\n",
      "#\n",
      "def event_burstdet_settings(Settings):\n",
      "    \n",
      "    if 'Threshold' in Settings.keys():\n",
      "        print \"Previous threshold value: %s\" %Settings['Threshold']\n",
      "    \n",
      "    if Settings['Baseline Type'] == 'linear':\n",
      "        threshperc = raw_input(\"Enter a threshold proportion value between 0 and %s: \" %round(max(Data['shift'])/Settings['Baseline'],4))\n",
      "        threshperc = float(threshperc)\n",
      "        Settings['Threshold'] = threshperc\n",
      "        \n",
      "    if Settings['Baseline Type'] == 'rolling':\n",
      "        max_data_rolling = max(Data['rolling'])\n",
      "        max_baseline_rolling = max(Settings['Baseline rolling'])\n",
      "        threshperc = raw_input(\"Enter a threshold value between 0 and %s: \" %round(max_data_rolling-max_baseline_rolling,4))\n",
      "        threshperc = float(threshperc)\n",
      "        \n",
      "        Settings['Threshold'] = threshperc\n",
      "    \n",
      "    if 'Inter-event interval minimum (seconds)' in Settings.keys():\n",
      "        print \"Previous interval value: %s\" %Settings['Inter-event interval minimum (seconds)']\n",
      "        \n",
      "    cluster_time = raw_input(\"Enter the minimum inter-event interval in seconds:\")\n",
      "    cluster_time = float(cluster_time)\n",
      "    Settings['Inter-event interval minimum (seconds)'] = cluster_time\n",
      "    \n",
      "    return Settings\n",
      "\n",
      "def event_burstdet(Data, Settings, Results):\n",
      "    \n",
      "    if Settings['Baseline Type'] == 'linear': #data[shift]\n",
      "        bstart, bend, bdur = burstduration_lin(Data['shift'].index, np.array(Data['shift']), \n",
      "                                               Settings['Baseline'], \n",
      "                                               Settings['Threshold'], \n",
      "                                               Settings['Inter-event interval minimum (seconds)'])\n",
      "        \n",
      "        \n",
      "    elif Settings['Baseline Type'] == 'rolling': #data[rolling]\n",
      "        bstart, bend, bdur, b_start_amp, b_end_amp = burstduration_rolling(Data['rolling'].index, \n",
      "                                                                           np.array(Data['rolling']), \n",
      "                                                                           Settings['Baseline rolling'], \n",
      "                                                                           Settings['Threshold'], \n",
      "                                                                           Settings['Inter-event interval minimum (seconds)'])\n",
      "        \n",
      "    results_bursts = DataFrame({'Burst Start': bstart})\n",
      "    results_bursts['Burst End'] = bend\n",
      "    results_bursts['Burst Duration'] = bdur\n",
      "    if Settings['Baseline Type'] == 'rolling':\n",
      "        results_bursts['Burst Start Amplitude'] = b_start_amp\n",
      "        results_bursts['Burst End Amplitude'] = b_end_amp\n",
      "    \n",
      "    interburst = interburstinterval(bstart, bend)\n",
      "    interburst.append(NaN)\n",
      "    results_bursts['Interburst Interval'] = interburst\n",
      "\n",
      "    tot = ttotal(bstart)\n",
      "    tot.append(NaN)\n",
      "    results_bursts['Total Cycle Time'] = tot\n",
      "    \n",
      "    Results['Bursts'] = results_bursts\n",
      "    Results['Bursts Summary'] = results_bursts.describe()\n",
      "    return Data, Settings, Results\n",
      "\n",
      "def burstduration_rolling(time, data, baseline_rolling, threshperc, cluster_time):\n",
      "    \"\"\"\n",
      "    threshperc is the percentage of the baseline that the threshold will be above; cluster_time should be changed based on the type of data (default for ECG is 0.006)\n",
      "    baserate needs to be calculated and passed into this argument\n",
      "    data should already be transformed, smoothed, and baseline shifted (shifting is technically optional, but it really doesn't matter)\n",
      "    returns the lists of start times, end times, and duration times\n",
      "    \"\"\"\n",
      "    \n",
      "    if len(time) != len(data): #logic check, are the number of data points and time points the same?\n",
      "        raise Exception('You cannot have more time points than there are data points. Get that sorted, buddy.')    \n",
      "    \n",
      "    burst_start = [] #empty array for burst start\n",
      "    burst_end = [] #empty array for burst end\n",
      "    burst_duration = [] #empty array to calculate burst durration\n",
      "    b_start_amp = []\n",
      "    b_end_amp = []\n",
      "    \n",
      "    threshold = np.array(baseline_rolling + threshperc) #calculate the point at which a event is considered a peak\n",
      "    \n",
      "    burst = False #burst flag, should start not in a burst\n",
      "\n",
      "    index = -1\n",
      "    for point in data: #for each data point in the set\n",
      "        index = index +1\n",
      "        #print index, \"=\", t.clock()\n",
      "        \n",
      "        if burst == False and point > threshold[index]: #if we are not in a burst already, the value is higher than the threshold, AND the last burst didn't end less than .2 ms ago\n",
      "            tpoint = time[index] #find the actual time given teh time index\n",
      "            burst_start.append(tpoint) #add the time at point as the begining of the burst\n",
      "            b_start_amp.append(threshold[index])\n",
      "            burst = True #burst flag, we are now in a burst \n",
      "        \n",
      "        if burst == True and  point <= threshold[index]: #if we are in a burst and the point falls below the threshold\n",
      "            \n",
      "            if len(burst_end) == 0 or len(burst_start) == 0: #if this is the first end\n",
      "                tpoint = time[index] #find the actual time given teh time index\n",
      "                burst_end.append (tpoint) #add the time at point as the end of the burst\n",
      "                b_end_amp.append(threshold[index])\n",
      "                burst = False #burst flag, we are now out of the burst\n",
      "            \n",
      "            else:\n",
      "                tpoint = time[index] #find the actual time given teh time index\n",
      "                burst_end.append (tpoint) #add the time at point as the end of the burst\n",
      "                b_end_amp.append(threshold[index])\n",
      "                burst = False #burst flag, we are now out of the burst\n",
      "                if burst_start[-1] < (burst_end[-2] + cluster_time):#if the new burst is too close to the last one, delete the second to last end and the last start\n",
      "                    del burst_end[-2]\n",
      "                    del b_end_amp[-2]\n",
      "                    del burst_start[-1]\n",
      "                    del b_start_amp[-1]\n",
      "    \n",
      "    if burst == True and len(burst_start) == 1+len(burst_end): #we exit the for loop but are in a burst\n",
      "        del burst_start[-1] #delete the last burst start time\n",
      "        del b_start_amp[-1]\n",
      "        \n",
      "    if len(burst_start) != len(burst_end):\n",
      "        raise Exception('Unexpectedly, the number of burst start times and end times are not equal. Seeing as this is physically impossible, I quit the program for you. Begin hunting for the fatal flaw. Good luck!')\n",
      "        \n",
      "    #print t.clock(), \"- start duration array\"\n",
      "    for foo in burst_start: #for each burst\n",
      "        index = burst_start.index(foo)\n",
      "        duration = burst_end[index] - burst_start[index] #calculate duration by subtracting the start time from the end time, found by indexing\n",
      "        burst_duration.append(duration) #add the burst duration to the duration list\n",
      "    #print t.clock(), \"-end duration array\"\n",
      "    \n",
      "    return burst_start, burst_end, burst_duration, b_start_amp, b_end_amp\n",
      "\n",
      "def burstduration_lin(time, data, baserate, threshperc, cluster_time):\n",
      "    \"\"\"\n",
      "    threshperc is the percentage of the baseline that the threshold will be above; cluster_time should be changed based on the type of data (default for ECG is 0.006)\n",
      "    baserate needs to be calculated and passed into this argument\n",
      "    data should already be transformed, smoothed, and baseline shifted (shifting is technically optional, but it really doesn't matter)\n",
      "    returns the lists of start times, end times, and duration times\n",
      "    \"\"\"\n",
      "    \n",
      "    if len(time) != len(data): #logic check, are the number of data points and time points the same?\n",
      "        raise Exception('You cannot have more time points than there are data points. Get that sorted, buddy.')    \n",
      "    \n",
      "    burst_start = [] #empty array for burst start\n",
      "    burst_end = [] #empty array for burst end\n",
      "    burst_duration = [] #empty array to calculate burst durration\n",
      "    \n",
      "    threshold = baserate * threshperc #calculate the point at which a event is considered a peak\n",
      "    \n",
      "    burst = False #burst flag, should start not in a burst\n",
      "\n",
      "    index = -1\n",
      "    for point in data: #for each data point in the set\n",
      "        index = index +1\n",
      "        #print index, \"=\", t.clock()\n",
      "        \n",
      "        if burst == False and point > threshold: #if we are not in a burst already, the value is higher than the threshold, AND the last burst didn't end less than .2 ms ago\n",
      "            tpoint = time[index] #find the actual time given teh time index\n",
      "            burst_start.append(tpoint) #add the time at point as the begining of the burst\n",
      "            burst = True #burst flag, we are now in a burst \n",
      "        \n",
      "        if burst == True and  point <= threshold: #if we are in a burst and the point falls below the threshold\n",
      "            \n",
      "            if len(burst_end) == 0 or len(burst_start) == 0: #if this is the first end\n",
      "                tpoint = time[index] #find the actual time given teh time index\n",
      "                burst_end.append (tpoint) #add the time at point as the end of the burst\n",
      "                burst = False #burst flag, we are now out of the burst\n",
      "            \n",
      "            else:\n",
      "                tpoint = time[index] #find the actual time given teh time index\n",
      "                burst_end.append (tpoint) #add the time at point as the end of the burst\n",
      "                burst = False #burst flag, we are now out of the burst\n",
      "                if burst_start[-1] < (burst_end[-2] + cluster_time):#if the new burst is too close to the last one, delete the second to last end and the last start\n",
      "                    del burst_end[-2]\n",
      "                    del burst_start[-1]\n",
      "    \n",
      "    if burst == True and len(burst_start) == 1+len(burst_end): #we exit the for loop but are in a burst\n",
      "        del burst_start[-1] #delete the last burst start time\n",
      "    \n",
      "    if len(burst_start) != len(burst_end):\n",
      "        raise Exception('Unexpectedly, the number of burst start times and end times are not equal. Seeing as this is physically impossible, I quit the program for you. Begin hunting for the fatal flaw. Good luck!')\n",
      "        \n",
      "    #print t.clock(), \"- start duration array\"\n",
      "    for foo in burst_start: #for each burst\n",
      "        index = burst_start.index(foo)\n",
      "        duration = burst_end[index] - burst_start[index] #calculate duration by subtracting the start time from the end time, found by indexing\n",
      "        burst_duration.append(duration) #add the burst duration to the duration list\n",
      "    #print t.clock(), \"-end duration array\"\n",
      "    \n",
      "    return burst_start, burst_end, burst_duration\n",
      "\n",
      "\n",
      "def interburstinterval(burst_start, burst_end):\n",
      "    \"\"\"\n",
      "    this function is used to find the inter-burst interval. \n",
      "    this is defined as the difference between the last end and the new start time\n",
      "    Dependent on numpy, burst_start, and burst_end\n",
      "    \"\"\"\n",
      "    \n",
      "    ibi = []\n",
      "    \n",
      "    for end in burst_end[:-1]: #for each end time except the last one\n",
      "        tindex = burst_end.index(end) #find the start time index\n",
      "        start = burst_start[tindex+1] #find start time\n",
      "        ibi.append(start-end) #subtract the old end time from the start time\n",
      "    \n",
      "    return ibi\n",
      "\n",
      "def ttotal(burst_start): \n",
      "    \"\"\"\n",
      "    find time from start to start, called the interburst interval. Input array must be a list of numbers (float).\n",
      "    \"\"\"\n",
      "    \n",
      "    ttotal = [] #empty array for ttot to go into\n",
      "    \n",
      "    for time in burst_start[1:]: #for each start time, starting with the second one\n",
      "        s2time = burst_start.index(time) \n",
      "        s2 = burst_start[s2time-1]\n",
      "        meas = time - s2 #measure the interval by subtracting\n",
      "        ttotal.append(meas) #append the measurement to the ttotal array\n",
      "    return ttotal #return array\n",
      "\n",
      "def burst_plot(Data, Settings, Results):\n",
      "    '''\n",
      "    wrapper to plot the results of the peak detection. \n",
      "    use the time and data_shift arrays for the data. use maxptime and maxpeaks to plot peaks.\n",
      "    '''     \n",
      "    if Settings['Baseline Type'] == 'linear':\n",
      "        bend = Results['Bursts']['Burst End'].tolist()\n",
      "        bstart = Results['Bursts']['Burst Start'].tolist()\n",
      "        bendy = []\n",
      "        for point in bend:\n",
      "            bendy.append(Settings['Baseline']*Settings['Threshold'])\n",
      "\n",
      "        bstarty = []\n",
      "        for point in bstart:\n",
      "            bstarty.append(Settings['Baseline']*Settings['Threshold'])\n",
      "            \n",
      "        plt.plot(Data['shift'].index, Data['shift'], 'k') #in this instance, baseline = shift\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Amp')\n",
      "        plt.hlines(0,Data['shift'].index[0],Data['shift'].index[-1],colors='b')\n",
      "        plt.hlines((Settings['Baseline']*Settings['Threshold']),Data['shift'].index[0],Data['shift'].index[-1],colors='r')\n",
      "        #plt.xlim(xmin = min(time), xmax = (min(time)+10))\n",
      "        #plt.ylim(ymin = min(data_baseline), ymax = max(data_baseline))\n",
      "        plt.plot(Results['Peaks'].index,Results['Peaks']['Peaks Amplitude'], marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "        plt.plot(bstart, bstarty, marker = \"v\", color=\"y\", linestyle= \"None\")\n",
      "        plt.plot(bend, bendy, marker = \"v\", color=\"m\", linestyle= \"None\")\n",
      "        plt.title('Event Detection')\n",
      "\n",
      "        plt.show()\n",
      "    \n",
      "    elif Settings['Baseline Type'] == 'rolling':\n",
      "        \n",
      "        plt.plot(Data['rolling'].index, Data['rolling'], 'k')\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Amp')\n",
      "        plt.plot(Settings['Baseline rolling'].index, Settings['Baseline rolling'], 'b') #in this instance, baseline = rolling average\n",
      "        plt.plot(Settings['Baseline rolling'].index, Settings['Baseline rolling']+Settings['Threshold'], 'r')\n",
      "        plt.plot(Results['Peaks'].index,Results['Peaks']['Peaks Amplitude'], marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "        plt.plot(Results['Bursts']['Burst Start'], Results['Bursts']['Burst Start Amplitude'], marker = \"v\", color=\"y\", linestyle= \"None\")\n",
      "        plt.plot(Results['Bursts']['Burst End'], Results['Bursts']['Burst End Amplitude'], marker = \"v\", color=\"m\", linestyle= \"None\")\n",
      "        plt.title('Event Detection')\n",
      "        #plt.xlim(xmin = min(time), xmax = (min(time)+10))\n",
      "        #plt.ylim(ymin = min(data_baseline), ymax = max(data_baseline))\n",
      "        \n",
      "        plt.show()\n",
      "def burstarea(data, time, burst_start, burst_end, dx = 10):\n",
      "    \"\"\"\n",
      "    integral, area under curve of each burst. Use start and end times to split the y values into short lists. \n",
      "    need the time array to do this\n",
      "    \"\"\"\n",
      "    from scipy.integrate import simps, trapz #import the integral functions\n",
      "    \n",
      "    time = list(time) #time array must be a list for the indexting to work.\n",
      "    \n",
      "    burst_area = [] #empty array for the areas to go into\n",
      "    #count = 0\n",
      "    for i in np.arange(len(burst_start)): #for each index in the start array\n",
      "        end = time.index(burst_end[i]) #using the value at each i in the burst_end array, index in the time array to get the time index. this will be the same index # as the data array\n",
      "        start = time.index(burst_start[i])\n",
      "        area = trapz(data[start:end], x=time[start:end], dx= dx) #find area using the trapz function, but only \n",
      "        burst_area.append(area)\n",
      "        #count = count + 1\n",
      "        #print \"%s = %s\" %(count,area)\n",
      "    return burst_area\n",
      "\n",
      "def burstarea_wrapper(Data, Results):\n",
      "    '''\n",
      "    wrapper for burst area. since this function takes a while, it is seperated out for safety and effecency.\n",
      "    '''\n",
      "    start = t.clock()\n",
      "    #bend = Results['Bursts']['Burst End'].tolist()\n",
      "    #bstart = Results['Bursts']['Burst Start'].tolist()\n",
      "    \n",
      "    if Settings['Baseline Type'] == 'linear':\n",
      "        b_area = burstarea(np.array(Data['trans']), \n",
      "                                Data['trans'].index, \n",
      "                                Results['Bursts']['Burst Start'].tolist(), \n",
      "                                Results['Bursts']['Burst End'].tolist())\n",
      "    \n",
      "    elif Settings['Baseline Type'] == 'rolling':\n",
      "        b_area = burstarea(np.array(Data['rolling']), \n",
      "                                Data['rolling'].index, \n",
      "                                Results['Bursts']['Burst Start'].tolist(), \n",
      "                                Results['Bursts']['Burst End'].tolist())\n",
      "    Results['Bursts']['Burst Area'] = b_area\n",
      "    end = t.clock()\n",
      "    print 'burstarea took', (end-start), 'seconds to complete', len(Results['Bursts']['Burst Start']), 'integrals, or', round(((len(Results['Bursts']['Burst Start']))/(end-start)),3), 'integrals/second. How impressive!'\n",
      "    \n",
      "    Results['Bursts Summary'] = Results['Bursts'].describe()\n",
      "    \n",
      "    return Results\n",
      "\n",
      "def burst_peaks(data, burst_start, burst_end, time=0, delta=0.04, rate=0.00025):#This code fails, do not use! use burst_peaks2\n",
      "    \"\"\"\n",
      "    given the burst start and end time, along with the looser peak detect, calculate the number of peaks in a given burst\n",
      "    dependent on burstduration, numpy, sys, and peakdet\n",
      "    default delta is 0.04, based on ECG data, seems to catch QRS and sometimes P and/or T\n",
      "    data MUST be transformed, but not shifted. peakdet will reject it if it has negative values\n",
      "    time varible is the value of time at the the first index of the time array. You can input it in as time=TIME_ARRAY[0]\n",
      "    rate is the collection rate of the data set. \n",
      "    \"\"\"\n",
      "    \n",
      "    if len(burst_start) != len(burst_end): #logic check, before we start\n",
      "        raise Exception('Unexpectedly, the number of burst start times and end times are not equal. Seeing as this is physically impossible, I quit the program for you. Begin hunting for the fatal flaw. Good luck!')\n",
      "    \n",
      "    if (len(burst_start) == 0) or (len(burst_end) == 0): #logic check, are they empty lists\n",
      "        raise Exception('One of the input arrays is an empty list')\n",
      "        \n",
      "    maxtab, mintab= peakdet(data, delta) #generate the maxtab array of times and heights\n",
      "    \n",
      "    maxptime = maxtab[:,0] #extract the time column\n",
      "    maxptime = (np.multiply(maxptime,rate) + time) #convert from index to ms\n",
      "    \n",
      "    index = 0 #initalize burst index to zero\n",
      "    burstpeaknum = [] #empty array for where the number of peaks will go. index # = burst #\n",
      "    burstpeaks = [] #empty tuple of peak locations. index # = burst #\n",
      "    plist= [] #make blank plist\n",
      "    \n",
      "    \n",
      "    for time in maxptime: #for each peak found in maxtab. remember that maxtab has multipule columns, so only take time.\n",
      "        \n",
      "        if index == (len(burst_start)-1) and time > burst_end[index]:\n",
      "            burstpeaks.append(plist) #put list of peaks in burst peaks list\n",
      "            burstpeaknum.append(len(plist)) #add count of peaks to burst peak num list\n",
      "            \n",
      "        \n",
      "        if time > burst_end[-1]:\n",
      "            break\n",
      "        \n",
      "        if burst_start[index] < time < burst_end[index]: # if the peak is within the duration of the burst\n",
      "            plist.append(time)\n",
      "            \n",
      "            if time == maxptime[-1]:#if the current peak is the last one\n",
      "                burstpeaks.append(plist) #put list of peaks in burst peaks list\n",
      "                burstpeaknum.append(len(plist)) #add count of peaks to burst peak num list\n",
      "        \n",
      "        if index < (len(burst_start)-1) and time > burst_start[index+1]: #if the next peak is actually in the NEXT burst AND it isn't the last burst\n",
      "            burstpeaks.append(plist) #put list of peaks in burst peaks list\n",
      "            burstpeaknum.append(len(plist)) #add count of peaks to burst peak num list\n",
      "            index = (index+1) #go to the next burst\n",
      "            plist=[] #make a new list for the new peak\n",
      "            plist.append(time) #add this timepoint to the new list\n",
      "          \n",
      "               \n",
      "    return burstpeaknum, burstpeaks, maxtab\n",
      "\n",
      "#\n",
      "#Save\n",
      "#\n",
      "#\n",
      "def Save_Results(Settings, Results):\n",
      "    '''\n",
      "    Save function for all files out of SWAN. All files must be present, otherwise it will not save. all files in the same folder with the same name will be saved over, except for the Settings file, which always has a unique name.\n",
      "    '''\n",
      "    path = Settings['Save Location']\n",
      "    folder = Settings['Sample Folder']\n",
      "    rate = Settings['Sample Rate (s/frame)']\n",
      "    #bstart = results_bursts['Burst Start']\n",
      "    \n",
      "    #bstart_gHRV = (np.subtract(bstart,bstart[0])) #get the relative time for each burst start, needed for gHRV to run using the tot\n",
      "    #np.savetxt(r'%s/%s/%s_ttot_times.txt' %(path, folder, folder), bstart_gHRV)\n",
      "    #maxptime_gHRV = (np.subtract(maxptime, maxptime[0])) #get the relative time for each R peak, needed for gHRV to run\n",
      "    #np.savetxt(r'%s/%s/%s_rr_times.txt' %(path,folder, folder), maxptime_gHRV)\n",
      "\n",
      "    Results['Bursts'].to_csv(r'%s/%s/%s_burst_results.csv' %(path, folder, folder))\n",
      "    Results['Bursts Summary'].to_csv(r'%s/%s/%s_burst_results_summary.csv'%(path,folder, folder))\n",
      "    Results['Peaks'].to_csv(r'%s/%s/%s_peak_results.csv'%(path, folder, folder))\n",
      "    Results['Peaks Summary'].to_csv(r'%s/%s/%s_peak_results_summary.csv'%(path, folder, folder))\n",
      "    \n",
      "    Settings_panda = DataFrame.from_dict(Settings, orient='index')\n",
      "    colname = 'Settings: ' + str(datetime.datetime.now())\n",
      "    Settings_panda.columns = [colname]\n",
      "    Settings_panda = Settings_panda.sort()\n",
      "    Settings_panda.to_csv(r'%s/%s/%s_%s.csv'%(path, folder, folder,colname))\n",
      "    \n",
      "    print \"All results saved to\", path+'/'+folder\n",
      "    print \"Thank you for chosing SWAN for all your basic analysis needs. Proceed for graphs and advanced analysis.\"\n",
      "    \n",
      "#\n",
      "#Line Plots\n",
      "#general plots as well as graphing functions\n",
      "#several of the other functions have specific, paired functions, thus their code is not listed here\n",
      "#\n",
      "def line_plot(Data, Settings, Results):\n",
      "    '''\n",
      "    plots a dual line plot of your raw signal and your transformed signal with events overlayed.\n",
      "    automatically the first 10 seconds of data are displayed. you can pan around inside to find the part you want to see.\n",
      "    '''\n",
      "    fig, ax = plt.subplots(2, sharex= True)\n",
      "    \n",
      "    ax[0].plot(Data['original'].index, Data['original'], 'k')\n",
      "    ax[0].set_title('Raw Data')\n",
      "    ax[0].set_ylabel('Amplitude')\n",
      "    \n",
      "    if Settings['Baseline Type'] == 'linear':\n",
      "        bend = Results['Bursts']['Burst End'].tolist()\n",
      "        bstart = Results['Bursts']['Burst Start'].tolist()\n",
      "        bendy = []\n",
      "        for point in bend:\n",
      "            bendy.append(Settings['Baseline']*Settings['Threshold'])\n",
      "\n",
      "        bstarty = []\n",
      "        for point in bstart:\n",
      "            bstarty.append(Settings['Baseline']*Settings['Threshold'])\n",
      "            \n",
      "        ax[1].plot(Data['shift'].index, Data['shift'], 'k') #in this instance, baseline = shift\n",
      "        ax[1].set_xlabel('Time (s)')\n",
      "        ax[1].set_ylabel('Relative Amplitude')\n",
      "        ax[1].hlines(0,Data['shift'].index[0],Data['shift'].index[-1],colors='b')\n",
      "        ax[1].hlines((Settings['Baseline']*Settings['Threshold']),Data['shift'].index[0],Data['shift'].index[-1],colors='r')\n",
      "        ax[1].plot(Results['Peaks'].index,Results['Peaks']['Peaks Amplitude'], marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "        ax[1].plot(bstart, bstarty, marker = \"v\", color=\"y\", linestyle= \"None\")\n",
      "        ax[1].plot(bend, bendy, marker = \"v\", color=\"m\", linestyle= \"None\")\n",
      "        ax[1].set_title('Data Analysis')\n",
      "\n",
      "        plt.show()\n",
      "    \n",
      "    elif Settings['Baseline Type'] == 'rolling':\n",
      "        \n",
      "        ax[1].plot(Data['rolling'].index, Data['rolling'], 'k')\n",
      "        ax[1].set_xlabel('Time (s)')\n",
      "        ax[1].set_ylabel('Relative Amplitude')\n",
      "        ax[1].plot(Settings['Baseline rolling'].index, Settings['Baseline rolling'], 'b') #in this instance, baseline = rolling average\n",
      "        ax[1].plot(Settings['Baseline rolling'].index, Settings['Baseline rolling']+Settings['Threshold'], 'r')\n",
      "        ax[1].plot(Results['Peaks'].index,Results['Peaks']['Peaks Amplitude'], marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "        ax[1].plot(Results['Bursts']['Burst Start'], Results['Bursts']['Burst Start Amplitude'], marker = \"v\", color=\"y\", linestyle= \"None\")\n",
      "        ax[1].plot(Results['Bursts']['Burst End'], Results['Bursts']['Burst End Amplitude'], marker = \"v\", color=\"m\", linestyle= \"None\")\n",
      "        ax[1].set_title('Data Analysis')\n",
      "        \n",
      "    plt.show()\n",
      "\n",
      "def plot_rawdata(Data):\n",
      "    figure = plt.plot(Data['original'].index, Data['original'], 'k')\n",
      "    plt.title('Raw Data')\n",
      "    plt.xlabel('Time (s)')\n",
      "    plt.ylabel('Amplitude')\n",
      "    DataCursor(figure)\n",
      "    plt.show(figure) \n",
      "    \n",
      "class DataCursor(object):\n",
      "    \"\"\"A simple data cursor widget that displays the x,y location of a\n",
      "    matplotlib artist when it is selected.\"\"\"\n",
      "    def __init__(self, artists, tolerance=5, offsets=(-20, 20), \n",
      "                 template='x: %0.2f\\ny: %0.2f', display_all=False):\n",
      "        \"\"\"Create the data cursor and connect it to the relevant figure.\n",
      "        \"artists\" is the matplotlib artist or sequence of artists that will be \n",
      "            selected. \n",
      "        \"tolerance\" is the radius (in points) that the mouse click must be\n",
      "            within to select the artist.\n",
      "        \"offsets\" is a tuple of (x,y) offsets in points from the selected\n",
      "            point to the displayed annotation box\n",
      "        \"template\" is the format string to be used. Note: For compatibility\n",
      "            with older versions of python, this uses the old-style (%) \n",
      "            formatting specification.\n",
      "        \"display_all\" controls whether more than one annotation box will\n",
      "            be shown if there are multiple axes.  Only one will be shown\n",
      "            per-axis, regardless. \n",
      "        \"\"\"\n",
      "        self.template = template\n",
      "        self.offsets = offsets\n",
      "        self.display_all = display_all\n",
      "        if not cbook.iterable(artists):\n",
      "            artists = [artists]\n",
      "        self.artists = artists\n",
      "        self.axes = tuple(set(art.axes for art in self.artists))\n",
      "        self.figures = tuple(set(ax.figure for ax in self.axes))\n",
      "\n",
      "        self.annotations = {}\n",
      "        for ax in self.axes:\n",
      "            self.annotations[ax] = self.annotate(ax)\n",
      "\n",
      "        for artist in self.artists:\n",
      "            artist.set_picker(tolerance)\n",
      "        for fig in self.figures:\n",
      "            fig.canvas.mpl_connect('pick_event', self)\n",
      "\n",
      "    def annotate(self, ax):\n",
      "        \"\"\"Draws and hides the annotation box for the given axis \"ax\".\"\"\"\n",
      "        annotation = ax.annotate(self.template, xy=(0, 0), ha='right',\n",
      "                xytext=self.offsets, textcoords='offset points', va='bottom',\n",
      "                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
      "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0')\n",
      "                )\n",
      "        annotation.set_visible(False)\n",
      "        return annotation\n",
      "\n",
      "    def __call__(self, event):\n",
      "        \"\"\"Intended to be called through \"mpl_connect\".\"\"\"\n",
      "        # Rather than trying to interpolate, just display the clicked coords\n",
      "        # This will only be called if it's within \"tolerance\", anyway.\n",
      "        x, y = event.mouseevent.xdata, event.mouseevent.ydata\n",
      "        annotation = self.annotations[event.artist.axes]\n",
      "        if x is not None:\n",
      "            if not self.display_all:\n",
      "                # Hide any other annotation boxes...\n",
      "                for ann in self.annotations.values():\n",
      "                    ann.set_visible(False)\n",
      "            # Update the annotation in the current axis..\n",
      "            annotation.xy = x, y\n",
      "            annotation.set_text(self.template % (x, y))\n",
      "            annotation.set_visible(True)\n",
      "            event.canvas.draw()\n",
      "\n",
      "            \n",
      "#\n",
      "#Event Frequency plots\n",
      "#\n",
      "#\n",
      "def frequency_plot_peaks(Results):\n",
      "    rri = Results['Peaks']['Intervals'].tolist()\n",
      "    del rri[-1] #the last value is NaN, so we delete it.\n",
      "    rri_new = []\n",
      "    for i in rri:\n",
      "        bpm = 60/i\n",
      "        rri_new.append(bpm)\n",
      "    time_int = Results['Peaks'].index.tolist()\n",
      "    del time_int[-1] #must be the same length as rri\n",
      "\n",
      "    plt.ylabel('Event Rate (events/min.)')\n",
      "    plt.xlabel('Time (s)')\n",
      "    plt.title('Event Freqency-Peak detection')\n",
      "    plt.plot(time_int, rri_new)\n",
      "    plt.show()\n",
      "    \n",
      "def frequency_plot_bursts(Results):\n",
      "    tct = Results['Bursts']['Total Cycle Time'].tolist()\n",
      "    del tct[-1] #the last value is NaN, so we delete it.\n",
      "\n",
      "    tct_new = []\n",
      "    for i in tct:\n",
      "        bpm = 60/i\n",
      "        tct_new.append(bpm)\n",
      "    tct = tct_new\n",
      "\n",
      "    time_int = Results['Bursts']['Burst Start'].tolist()\n",
      "    del time_int[-1] #must be the same length as rri\n",
      "    plt.plot(time_int, tct)\n",
      "    plt.ylabel('Event Rate (events/min.)')\n",
      "    plt.xlabel('Time (s)')\n",
      "    plt.title('Event Freqency-Burst detection')\n",
      "    plt.show()\n",
      "\n",
      "#            \n",
      "# Poincare plots\n",
      "#\n",
      "#\n",
      "def poincare(data_array):\n",
      "    \"\"\"\n",
      "    Given a 1d array of data, create a Poincare plot along with the SD1 and SD2 parameters\n",
      "    usees matplotlib.patches.Ellipse to create the fit elipse\n",
      "    equations are derived from Brennan and http://www.mif.pg.gda.pl/homepages/graff/Tzaa/Guzik_geometry_asymetry.pdf cause OMG THIS MAKES SENSE NOW\n",
      "    \"\"\"\n",
      "    \n",
      "    x = data_array[:(len(data_array)-1)]\n",
      "    y = data_array[1:]\n",
      "    \n",
      "    xc = np.mean(x)\n",
      "    yc = np.mean(y)\n",
      "    \n",
      "    #SD1 = np.sqrt((1/len(x)) * sum(((x-y) - np.mean(x-y))^2)/2)\n",
      "    #SD2 = np.sqrt((1/len(x)) * sum(((x+y) - np.mean(x+y))^2)/2)    \n",
      "    \n",
      "    SD1 = 0\n",
      "    SD2 = 0\n",
      "    \n",
      "    for i in np.arange(len(x)):\n",
      "        \n",
      "        d1 = np.power(abs((x[i]-xc)-(y[i]-yc))/np.sqrt(2), 2)\n",
      "        SD1 = SD1 + d1\n",
      "        \n",
      "        d2 = np.power(abs((x[i]-xc)+(y[i]-yc))/np.sqrt(2), 2)\n",
      "        SD2 = SD2 + d2\n",
      "    \n",
      "    SD1 = np.sqrt(SD1/len(x))\n",
      "    SD2 = np.sqrt(SD2/len(x))\n",
      "    \n",
      "    return x, y, xc, yc, SD1, SD2 \n",
      "\n",
      "def poincare_plot(series):\n",
      "    '''\n",
      "    input a dataframe column or series to automatically generate a poincare plot. it will also print out the SD1 and SD2 Values.\n",
      "    '''\n",
      "    temp_series = series.tolist()\n",
      "    \n",
      "    x, y, xc, yc, SD1, SD2 = poincare(temp_series[:-1])\n",
      "\n",
      "    SD1RR = ('SD1 = ' +str(np.round(SD1,4)))\n",
      "    SD2RR = ('SD2 = ' +str(np.round(SD2,4)))\n",
      "    SDRR = (SD1RR, SD2RR)\n",
      "    ax = plt.subplot(111, aspect = \"equal\")\n",
      "    ellipse = patches.Ellipse(xy=(xc, yc), width = SD2, height = SD1, angle = 45, fill = False, color = \"r\")\n",
      "    ax.add_artist(ellipse)\n",
      "    plt.plot(xc, yc, color=\"r\", marker= \"+\")\n",
      "    plt.scatter(x, y, color = 'k', marker = '.')\n",
      "    plt.title('Poincare Plot-%s' %series.name)\n",
      "    #plt.text(-4,-4,SDRR) #this is commented out because it isn't running. not sure why.\n",
      "    plt.show()\n",
      "\n",
      "    print series.name, \"results:\"\n",
      "    print SD1RR+' s'\n",
      "    print SD2RR+' s'\n",
      "\n",
      "    \n",
      "#\n",
      "#Power Spectral Density\n",
      "#\n",
      "#\n",
      "def PSD_Peaks(Results, results_PSD, Settings_PSD):\n",
      "    Fxx_rii, Pxx_rii = PSD_rri(Results['Peaks'], hz)\n",
      "    results_PSD['Peakdet'] = Results_PSD(Fxx_rii, Pxx_rii)\n",
      "    plt.plot(Fxx_rii, Pxx_rii)\n",
      "    plt.xlim(xmin = 0, xmax = hz/2)\n",
      "    plt.xlabel(\"Frequency (Hz)\")\n",
      "    plt.ylabel(r\"PSD $(ms^ 2$/Hz)\")\n",
      "    plt.title(\"PSD-Peaks\")\n",
      "    plt.show()\n",
      "\n",
      "def PSD_bursts(Results, results_PSD, Settings_PSD):\n",
      "    Fxx_tct, Pxx_tct = PSD_tct(Results['Bursts'], hz)\n",
      "    results_PSD['Burstdet'] = Results_PSD(Fxx_tct, Pxx_tct)\n",
      "    plt.plot(Fxx_tct, Pxx_tct)\n",
      "    plt.xlim(xmin = 0, xmax = hz/2)\n",
      "    plt.xlabel(\"Frequency (Hz)\")\n",
      "    plt.ylabel(r\"PSD $(ms^ 2$/Hz)\")\n",
      "    plt.title(\"PSD-Bursts\")\n",
      "    plt.show()\n",
      "    \n",
      "def PSD_rri(results_peaks, hz):\n",
      "    '''\n",
      "    Power spectral density plot of rr intervals. this argument takes the results_peaks dataframe\n",
      "    '''\n",
      "    #adopted form Rhenan Bartels Ferreira \n",
      "    #https://github.com/RhenanBartels/biosignalprocessing/blob/master/psdRRi.py\n",
      "\n",
      "    from numpy import arange, cumsum, logical_and\n",
      "    from scipy.signal import welch\n",
      "    from scipy.interpolate import splrep, splev\n",
      "\n",
      "    rri = Results['Peaks']['Intervals'].tolist()\n",
      "    del rri[-1] #the last value is NaN, so we delete it.\n",
      "    rri_new = []\n",
      "    for i in rri:\n",
      "        bpm = 60/i\n",
      "        rri_new.append(bpm)\n",
      "    rri = rri_new\n",
      "    \n",
      "    t = Results['Peaks'].index.tolist()\n",
      "    del t[-1] #must be the same length as rri\n",
      "    \n",
      "    #Evenly spaced time array using hz\n",
      "    tx = arange(t[0], t[-1], 1.0 / hz)\n",
      "\n",
      "    #Interpolate RRi serie\n",
      "    tck = splrep(t, rri, s = 0)\n",
      "    rrix = splev(tx, tck, der=0)\n",
      "\n",
      "    #Number os estimations\n",
      "    P = int((len(tx) - 256 / 128)) + 1 #AD doesn't know what this does, but i dare not touch a damn thing.\n",
      "\n",
      "    #PSD with Welch's Method\n",
      "    Fxx, Pxx = welch(rrix, fs=hz, window=\"hanning\", nperseg=256, noverlap=128, detrend=\"linear\")\n",
      "\n",
      "    return Fxx, Pxx\n",
      "\n",
      "def PSD_tct(results_bursts, hz):\n",
      "    '''\n",
      "    Power spectral density plot of total cycle time. this argument takes the results_burst dataframe\n",
      "    '''\n",
      "    #adopted form Rhenan Bartels Ferreira \n",
      "    #https://github.com/RhenanBartels/biosignalprocessing/blob/master/psdRRi.py\n",
      "\n",
      "    from numpy import arange, cumsum, logical_and\n",
      "    from scipy.signal import welch\n",
      "    from scipy.interpolate import splrep, splev\n",
      "\n",
      "    tct = Results['Bursts']['Total Cycle Time'].tolist()\n",
      "    del tct[-1] #the last value is NaN, so we delete it.\n",
      "    tct_new = []\n",
      "    for i in tct:\n",
      "        bpm = 60/i\n",
      "        tct_new.append(bpm)\n",
      "    tct = tct_new\n",
      "    \n",
      "    t = Results['Bursts']['Burst Start'].tolist()\n",
      "    del t[-1] #must be the same length as rri\n",
      "    \n",
      "    #Evenly spaced time array using hz\n",
      "    tx = arange(t[0], t[-1], 1.0 / hz)\n",
      "\n",
      "    #Interpolate RRi serie\n",
      "    tck = splrep(t, tct, s = 0)\n",
      "    tctx = splev(tx, tck, der=0)\n",
      "\n",
      "    #Number os estimations\n",
      "    P = int((len(tx) - 256 / 128)) + 1 #AD doesn't know what this does, but i dare not touch a damn thing.\n",
      "\n",
      "    #PSD with Welch's Method\n",
      "    Fxx, Pxx = welch(tctx, fs=hz, window=\"hanning\", nperseg=256, noverlap=128, detrend=\"linear\")\n",
      "\n",
      "    return Fxx, Pxx\n",
      "\n",
      "def Results_PSD(Fxx, Pxx):\n",
      "    '''\n",
      "    Generates the result for peakdet interval PSD (PSD_rri)\n",
      "    '''\n",
      "    from scipy.integrate import simps\n",
      "\n",
      "    results_psd = Series(index = ['ULF', 'VLF', 'LF','HF','LF/HF'])\n",
      "    FXX = Series(Fxx)\n",
      "    PXX = Series(Pxx)\n",
      "\n",
      "    results_psd['ULF'] = simps(PXX[FXX<ulf].tolist(), FXX[FXX<ulf].tolist(), dx =dx)\n",
      "    results_psd['VLF'] = simps(PXX[(ulf<FXX) & (FXX<=vlf)].tolist(),FXX[(ulf<FXX) & (FXX<=vlf)].tolist(), dx= dx)\n",
      "    results_psd['LF'] = simps(PXX[(vlf<FXX) & (FXX<=lf)].tolist(),FXX[(vlf<FXX) & (FXX<=lf)].tolist(), dx= dx)\n",
      "    results_psd['HF'] = simps(PXX[(lf<FXX) & (FXX<=hf)].tolist(),FXX[(lf<FXX) & (FXX<=hf)].tolist(), dx= dx)\n",
      "    results_psd['LF/HF'] = results_psd['LF']/results_psd['HF']\n",
      "    return results_psd\n",
      "#\n",
      "#Histogram Entropy\n",
      "#\n",
      "#\n",
      "def histent_peaks(Results):\n",
      "    #from __future__ import division\n",
      "    #from math import log\n",
      "    RR = Results['Peaks']['Intervals'].tolist()\n",
      "    NumBin = int(2 * (log(len(RR), 2))); print 'Number of Bins=', NumBin\n",
      "    binarray = np.linspace(min(RR), max(RR), NumBin)\n",
      "    no, xo = np.histogram(RR, binarray); #print no\n",
      "\n",
      "    # normalize the distribution to make area under distribution function unity\n",
      "    no = no/sum(no); #print no\n",
      "\n",
      "    # find the bins that have no samples to prevent log(0) in calculation\n",
      "    no = no[np.nonzero(no)]    \n",
      "\n",
      "    # if all of the samples fall in one bin regardless of the bin size\n",
      "    # means we have the most predictable sitution and the entropy is 0\n",
      "    # if we have uniformly dist function, the max entropy will be 1\n",
      "\n",
      "    HistEntropy = [-1*(x * log(x, 2))/(log(NumBin,2)) for x in no]\n",
      "    HistEntropy = sum(HistEntropy)\n",
      "    #print 'HistEntropy=', HistEntropy\n",
      "\n",
      "    #plot that hot hot interval\n",
      "    plt.hist(RR,binarray)\n",
      "    plt.xlabel('Peak Intervals')\n",
      "    plt.ylabel('Count')\n",
      "    plt.title('Peak Interval Histogram')\n",
      "    plt.show()\n",
      "    \n",
      "    if 'Histogram Entropy' not in Results.keys():\n",
      "        Results['Histogram Entropy'] = Series(data = HistEntropy, index = ['Peak Intervals'])\n",
      "    else:\n",
      "        Results['Histogram Entropy']['Peak Intervals'] = HistEntropy\n",
      "    return Results\n",
      "\n",
      "def histent_bursts(Results):\n",
      "    #from __future__ import division\n",
      "    #from math import log\n",
      "    tot = Results['Bursts']['Total Cycle Time'].tolist()\n",
      "    tot = np.array(tot, dtype= 'float')\n",
      "    NumBin = int(2 * (log(len(tot), 2))); print 'Number of Bins=', NumBin\n",
      "    binarray = np.linspace(min(tot), max(tot), NumBin)\n",
      "    no, xo = np.histogram(tot, binarray); #print no\n",
      "\n",
      "    # normalize the distribution to make area under distribution function unity\n",
      "    no = no/sum(no); #print no\n",
      "\n",
      "    # find the bins that have no samples to prevent log(0) in calculation\n",
      "    no = no[np.nonzero(no)]    \n",
      "\n",
      "    # if all of the samples fall in one bin regardless of the bin size\n",
      "    # means we have the most predictable sitution and the entropy is 0\n",
      "    # if we have uniformly dist function, the max entropy will be 1\n",
      "\n",
      "    HistEntropy = [-1*(x * log(x, 2))/(log(NumBin,2)) for x in no]\n",
      "    HistEntropy =  sum(HistEntropy)\n",
      "\n",
      "    #plot that hot hot interval\n",
      "    plt.hist(tot,binarray)\n",
      "    plt.xlabel('Burst Total Cycle Time')\n",
      "    plt.ylabel('Count')\n",
      "    plt.title('Burst Total Cycle Time Histogram')\n",
      "    plt.show()\n",
      "    #HistEntropy = sum(HistEntropy)\n",
      "    \n",
      "    \n",
      "    if 'Histogram Entropy' not in Results.keys():\n",
      "        Results['Histogram Entropy'] = Series(data = HistEntropy, index = ['Burst Intervals'])\n",
      "    else:\n",
      "        Results['Histogram Entropy']['Burst Intervals'] = HistEntropy\n",
      "    return Results\n",
      "\n",
      "#END SWAN CODE\n",
      "print \"SWAN components loaded.\"\n",
      "\n",
      "from PIL import Image\n",
      "#END RAIIM/RAIN CODE\n",
      "\n",
      "print \"RAIN ready!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "SWAN components loaded.\n",
        "RAIN ready!\n"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "LCpro Load"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Manual ImageJ extraction\n",
      "Settings = {}\n",
      "Results ={}\n",
      "Settings['folder']= \"/Users/abigaildobyns/Documents/Test Run of ARIA plugin/Melisa/Pup_19\"\n",
      "Settings['Sample Name'] = 'Pup_19'\n",
      "\n",
      "Data = {}\n",
      "Data['original'] = pd.read_csv(r'%s/%s_ROI.csv' %(Settings['folder'], Settings['Sample Name']), index_col= 'time(s)', sep=',') #load the intensity time series for each roi. should be a text file named exactly 'ROI normalized.txt'\n",
      "print \"Loaded 'ROI normalized.txt'\"\n",
      "\n",
      "Settings['Sample Rate (s/frame)'] = Data['original'].index[1] - Data['original'].index[0]\n",
      "\n",
      "roi_param = pd.read_csv(r'%s/%s_ROI_loc.csv' %(Settings['folder'],Settings['Sample Name']), index_col=0, sep='\\t')#load the parameter list.\n",
      "print \"Loaded 'Parameter List_edit.txt'\"\n",
      "\n",
      "im = Image.open(r'%s/%s_MaxIntensity.png' %(Settings['folder'], Settings['Sample Name'])) #MUST BE RBG and .png. seriously, I'm not kidding.\n",
      "print \"Loaded 'rbg.png'\"\n",
      "\n",
      "roi_x = roi_param['XM'].tolist() #extract the x column as an array and store it as a value. this is handy for later calculations\n",
      "roi_y = roi_param['YM'].tolist() #extract the y column as an array and store it as a value. this is handy for later calculations\n",
      "new_index = [] #make an empty temp list\n",
      "for i in np.arange(len(roi_param.index)): #for each index in roi_loc\n",
      "    new_index.append('Mean'+str(roi_param.index[i])) #make a string from the index name in the same format as the data\n",
      "roi_loc = DataFrame({'x':roi_x, 'y':roi_y}, index= new_index) #reassign roi_loc to a dataframe with the properly named index. this means that we can use the same roi name to call from either the data or location dataframes\n",
      "\n",
      "print 'roi_loc parsed'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loaded 'ROI normalized.txt'\n",
        "Loaded 'Parameter List_edit.txt'\n",
        "Loaded 'rbg.png'\n",
        "roi_loc parsed\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#LCPro File extraction\n",
      "Settings = {}\n",
      "Results ={}\n",
      "Settings['folder']= \"/Users/abigaildobyns/Documents/Test Run of ARIA plugin/Melisa/Pup_19\"\n",
      "Settings['Sample Name'] = 'Pup_19'\n",
      "\n",
      "Data = {}\n",
      "def load_RAAIM(folder):\n",
      "    '''\n",
      "    this function takes a path to where all of the LC_pro saved files are. There should be 3 files:\n",
      "    'ROI normailed.text' - the ROI intensity time series data. Units should be in time (not frame) and relative intensity\n",
      "    'Parameter List_edit.txt' - this is the events' information file. Duplicate ROIs are expected (since an ROI can have multipule events). The orignal LC_pro file can be loaded, as long as the name is changed to match. \n",
      "    'rbg.png' - A still of the video, must be .png. If it is a .tif, it will load, but it will be pseudo colored. it can be just a frame or some averaged measures.\n",
      "    \n",
      "    if the files are not named properly or the path is wrong, it will throw a file not found error.\n",
      "    '''\n",
      "    data = pd.read_csv(r'%s/ROI normalized.txt' %(folder), index_col= 'time(s)', sep='\\t') #load the intensity time series for each roi. should be a text file named exactly 'ROI normalized.txt'\n",
      "    print \"Loaded 'ROI normalized.txt'\"\n",
      "    \n",
      "    roi_param = pd.read_csv(r'%s/Parameter List_edit.txt' %(folder), index_col='ROI', sep='\\t')#load the parameter list.\n",
      "    print \"Loaded 'Parameter List_edit.txt'\"\n",
      "    \n",
      "    im = Image.open(r'%s/rbg.png' %(folder)) #MUST BE RBG and .png. seriously, I'm not kidding.\n",
      "    print \"Loaded 'rbg.png'\"\n",
      "    \n",
      "    del data['Unnamed: 0'] #lc_pro outputs a weird blank column named this everytime. I don't know why, but it does. this line deletes it safely.\n",
      "    roi_loc, roi_x, roi_y, data = lcpro_param_parse(roi_param, data , original=True) #use the parameter list to get the x and y location for each ROI\n",
      "    print \"Configured Data\"\n",
      "    \n",
      "    #events_x, events_y = get_events(data = data, roi_param = roi_param) #use the parameter list to get the location and amplitude of each event for every ROI\n",
      "    #print \"LCPro events extracted\"\n",
      "    \n",
      "    path = folder +\"/plots\"\n",
      "    mkdir_p(path) #makes a plots folder inside the path where the data was loaded from\n",
      "    print \"Made plots folder\"\n",
      "    \n",
      "    return data, roi_param, im, roi_loc, roi_x, roi_y, events_x, events_y\n",
      "    \n",
      "def lcpro_param_parse(roi_param, data , original = True):\n",
      "    '''\n",
      "    This function takes the Dataframe created by opening the 'Parameter List.txt' from LC_Pro.\n",
      "    It returns the location data as both a concise list datafram of only locations (roi_loc), an x and y list (roi_x, roi_y). \n",
      "    It also changes the names in the roi_loc file to be the same as they are in the data dataframe, which is \n",
      "    '''\n",
      "    roi_loc = roi_param[['X', 'Y']] #make a new dataframe that contains only the x and y coordinates\n",
      "    roi_loc.drop_duplicates(inplace= True) #roi_param has duplicate keys (rois) because the parameters are based on events, which lc_pro detects. a single roi can have many events. doing it in place like this does cause an error, but don't let it both you none.\n",
      "    roi_x = roi_loc['X'].tolist() #extract the x column as an array and store it as a value. this is handy for later calculations\n",
      "    roi_y = roi_loc['Y'].tolist() #extract the y column as an array and store it as a value. this is handy for later calculations\n",
      "    new_index = [] #make an empty temp list\n",
      "    for i in np.arange(len(roi_loc.index)): #for each index in roi_loc\n",
      "        new_index.append('Roi'+str(roi_loc.index[i])) #make a string from the index name in the same format as the data\n",
      "    roi_loc = DataFrame({'x':roi_x, 'y':roi_y}, index= new_index) #reassign roi_loc to a dataframe with the properly named index. this means that we can use the same roi name to call from either the data or location dataframes\n",
      "    \n",
      "    if len(data.columns) != len(new_index) and original == True: #if the number of roi's are the same AND we are using the original file (no roi's have been romved from the edited roi_param)\n",
      "        sys.exit(\"The number of ROIs in the data file is not equal to the number of ROIs in the parameter file. That doesn't seem right, so I quit the function for you. Make sure you are loading the correct files, please.\")\n",
      "    \n",
      "    if original == False: #if it is not the original, then use the roi_loc index to filter only edited roi's.\n",
      "        data = data[roi_loc.index]\n",
      "    \n",
      "    truth = (data.columns == roi_loc.index).tolist() #a list of the bool for if the roi indexes are all the same.\n",
      "    \n",
      "    if truth.count(True) != len(data.columns): #all should be true, so check that the number of true are the same.\n",
      "        sys.exit(\"The names on data and roi_loc are not identical. This will surely break everything later, so I shut down the program. Try loading these files again.\")\n",
      "    \n",
      "    return roi_loc, roi_x, roi_y, data\n",
      "\n",
      "def get_events(data, roi_param):\n",
      "    '''\n",
      "    extract the events from the roi_parameter list. It returns them as a pair of dictionaries (x or y data, sored as floats in a list) that use the roi name as the key. \n",
      "    duplicate events are ok and expected.\n",
      "    '''\n",
      "    \n",
      "    new_index = [] #create a new, empty list\n",
      "    \n",
      "    for i in np.arange(len(roi_param.index)): #for each index in the original roi_param list, will include duplicates\n",
      "        new_index.append('Roi'+str(roi_param.index[i])) #reformat name and append it to the empty index list\n",
      "    roi_events = DataFrame(index= new_index) #make an empty data frame using the new_index as the index\n",
      "    roi_events_time = roi_param['Time(s)'].tolist() #convert time (which is the x val) to a list\n",
      "    roi_events_amp = roi_param['Amp(F/F0)'].tolist() #conver amplitude (which is the y val) to a list\n",
      "    roi_events['Time'] = roi_events_time #store it in the events dataframe\n",
      "    roi_events['Amp'] = roi_events_amp #store is in the events dataframe\n",
      "    \n",
      "    events_x = {} #empty dict\n",
      "    events_y = {} #empty dict\n",
      "    \n",
      "    for label in data.columns: #for each roi name in data, initalize the dict by making an empty list for each roi (key) \n",
      "        events_x[label] = []\n",
      "        events_y[label] = []\n",
      "\n",
      "    for i in np.arange(len(roi_events.index)): #for each event\n",
      "        key = roi_events.index[i] #get the roi name\n",
      "        events_x[key].append(roi_events.iloc[i,0]) #use the name to add the event's time data point to the dict\n",
      "        events_y[key].append(roi_events.iloc[i,1]) #use the name to add the event's amplitude data point to the dict\n",
      "        \n",
      "    return events_x, events_y #return the two dictionaries"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sima sample file\n",
      "#nit sure what i'm looking that tho\n",
      "data_temp = pd.read_csv('/Users/abigaildobyns/Downloads/signal_data/all.csv', sep= '\\t', skiprows=2,index_col = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>Unnamed: 2</th>\n",
        "      <th>Unnamed: 3</th>\n",
        "      <th>Unnamed: 4</th>\n",
        "      <th>Unnamed: 5</th>\n",
        "      <th>Unnamed: 6</th>\n",
        "      <th>Unnamed: 7</th>\n",
        "      <th>Unnamed: 8</th>\n",
        "      <th>Unnamed: 9</th>\n",
        "      <th>Unnamed: 10</th>\n",
        "      <th>Unnamed: 11</th>\n",
        "      <th>Unnamed: 12</th>\n",
        "      <th>Unnamed: 13</th>\n",
        "      <th>Unnamed: 14</th>\n",
        "      <th>Unnamed: 15</th>\n",
        "      <th>Unnamed: 16</th>\n",
        "      <th>Unnamed: 17</th>\n",
        "      <th>Unnamed: 18</th>\n",
        "      <th>Unnamed: 19</th>\n",
        "      <th>Unnamed: 20</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>tags</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.257537</td>\n",
        "      <td> 1.202656</td>\n",
        "      <td> 0.875276</td>\n",
        "      <td> 0.930304</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.910773</td>\n",
        "      <td> 1.213944</td>\n",
        "      <td> 1.869776</td>\n",
        "      <td> 0.786133</td>\n",
        "      <td> 0.679948</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.244137</td>\n",
        "      <td> 0.892062</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.467173</td>\n",
        "      <td> 0.705478</td>\n",
        "      <td> 1.310110</td>\n",
        "      <td> 1.356881</td>\n",
        "      <td> 0.937740</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.209284</td>\n",
        "      <td> 1.160281</td>\n",
        "      <td> 0.888718</td>\n",
        "      <td> 0.924845</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.986044</td>\n",
        "      <td> 1.286672</td>\n",
        "      <td> 2.013144</td>\n",
        "      <td> 0.785111</td>\n",
        "      <td> 0.646886</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.322925</td>\n",
        "      <td> 0.906960</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.438676</td>\n",
        "      <td> 0.679709</td>\n",
        "      <td> 1.372201</td>\n",
        "      <td> 1.372144</td>\n",
        "      <td> 0.938082</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.211094</td>\n",
        "      <td> 1.111101</td>\n",
        "      <td> 0.869316</td>\n",
        "      <td> 0.946763</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.915515</td>\n",
        "      <td> 1.284043</td>\n",
        "      <td> 2.037372</td>\n",
        "      <td> 0.772286</td>\n",
        "      <td> 0.768509</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.209985</td>\n",
        "      <td> 0.916695</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.512563</td>\n",
        "      <td> 0.712535</td>\n",
        "      <td> 1.368941</td>\n",
        "      <td> 1.347543</td>\n",
        "      <td> 0.933265</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.162955</td>\n",
        "      <td> 1.095824</td>\n",
        "      <td> 0.901523</td>\n",
        "      <td> 0.943744</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.953089</td>\n",
        "      <td> 1.270332</td>\n",
        "      <td> 2.152563</td>\n",
        "      <td> 0.778466</td>\n",
        "      <td> 0.768661</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.214774</td>\n",
        "      <td> 0.865378</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.503331</td>\n",
        "      <td> 0.709364</td>\n",
        "      <td> 1.285667</td>\n",
        "      <td> 1.319194</td>\n",
        "      <td> 0.947982</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.140220</td>\n",
        "      <td> 1.083488</td>\n",
        "      <td> 0.873273</td>\n",
        "      <td> 0.944194</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.925327</td>\n",
        "      <td> 1.263475</td>\n",
        "      <td> 2.050155</td>\n",
        "      <td> 0.774643</td>\n",
        "      <td> 0.676298</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.226599</td>\n",
        "      <td> 0.919253</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.474375</td>\n",
        "      <td> 0.698087</td>\n",
        "      <td> 1.264062</td>\n",
        "      <td> 1.336947</td>\n",
        "      <td> 0.927490</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.155609</td>\n",
        "      <td> 1.062018</td>\n",
        "      <td> 0.880750</td>\n",
        "      <td> 0.919496</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.943891</td>\n",
        "      <td> 1.218690</td>\n",
        "      <td> 2.063526</td>\n",
        "      <td> 0.801323</td>\n",
        "      <td> 0.710870</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.156469</td>\n",
        "      <td> 0.897673</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.521605</td>\n",
        "      <td> 0.711264</td>\n",
        "      <td> 1.294004</td>\n",
        "      <td> 1.279483</td>\n",
        "      <td> 0.934675</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.170139</td>\n",
        "      <td> 1.078257</td>\n",
        "      <td> 0.878946</td>\n",
        "      <td> 0.865752</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.943213</td>\n",
        "      <td> 1.243548</td>\n",
        "      <td> 1.965035</td>\n",
        "      <td> 0.788966</td>\n",
        "      <td> 0.735629</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.207983</td>\n",
        "      <td> 0.857581</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.511891</td>\n",
        "      <td> 0.713689</td>\n",
        "      <td> 1.308617</td>\n",
        "      <td> 1.298914</td>\n",
        "      <td> 0.930393</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.095765</td>\n",
        "      <td> 1.055215</td>\n",
        "      <td> 0.841316</td>\n",
        "      <td> 0.926448</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.953239</td>\n",
        "      <td> 1.239388</td>\n",
        "      <td> 1.909568</td>\n",
        "      <td> 0.786193</td>\n",
        "      <td> 0.962416</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.180882</td>\n",
        "      <td> 0.894560</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.522503</td>\n",
        "      <td> 0.708318</td>\n",
        "      <td> 1.315929</td>\n",
        "      <td> 1.321313</td>\n",
        "      <td> 0.945906</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.132007</td>\n",
        "      <td> 1.038625</td>\n",
        "      <td> 0.856640</td>\n",
        "      <td> 0.886891</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.967746</td>\n",
        "      <td> 1.259463</td>\n",
        "      <td> 1.987421</td>\n",
        "      <td> 0.786869</td>\n",
        "      <td> 0.794854</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.147852</td>\n",
        "      <td> 0.890188</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.456368</td>\n",
        "      <td> 0.725654</td>\n",
        "      <td> 1.316003</td>\n",
        "      <td> 1.268275</td>\n",
        "      <td> 0.946929</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.127625</td>\n",
        "      <td> 1.083734</td>\n",
        "      <td> 0.849103</td>\n",
        "      <td> 0.870105</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.914084</td>\n",
        "      <td> 1.222537</td>\n",
        "      <td> 1.931253</td>\n",
        "      <td> 0.793603</td>\n",
        "      <td> 0.840535</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.222674</td>\n",
        "      <td> 0.837438</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.475686</td>\n",
        "      <td> 0.711966</td>\n",
        "      <td> 1.374607</td>\n",
        "      <td> 1.273115</td>\n",
        "      <td> 0.953046</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.112026</td>\n",
        "      <td> 1.039772</td>\n",
        "      <td> 0.848171</td>\n",
        "      <td> 0.877791</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.950812</td>\n",
        "      <td> 1.251848</td>\n",
        "      <td> 1.976058</td>\n",
        "      <td> 0.792120</td>\n",
        "      <td> 0.698222</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.113963</td>\n",
        "      <td> 0.871786</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.503885</td>\n",
        "      <td> 0.753007</td>\n",
        "      <td> 1.323523</td>\n",
        "      <td> 1.336836</td>\n",
        "      <td> 0.945210</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.163634</td>\n",
        "      <td> 1.043313</td>\n",
        "      <td> 0.851165</td>\n",
        "      <td> 0.851306</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.893279</td>\n",
        "      <td> 1.251117</td>\n",
        "      <td> 2.025112</td>\n",
        "      <td> 0.794704</td>\n",
        "      <td> 0.779585</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.155021</td>\n",
        "      <td> 0.900293</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.492155</td>\n",
        "      <td> 0.719690</td>\n",
        "      <td> 1.363352</td>\n",
        "      <td> 1.300711</td>\n",
        "      <td> 0.927967</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.203256</td>\n",
        "      <td> 1.021462</td>\n",
        "      <td> 0.812591</td>\n",
        "      <td> 0.905103</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.934851</td>\n",
        "      <td> 1.264440</td>\n",
        "      <td> 1.936942</td>\n",
        "      <td> 0.786109</td>\n",
        "      <td> 0.729574</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.079466</td>\n",
        "      <td> 0.877030</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.471543</td>\n",
        "      <td> 0.709597</td>\n",
        "      <td> 1.300870</td>\n",
        "      <td> 1.323717</td>\n",
        "      <td> 0.929299</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.119307</td>\n",
        "      <td> 1.006211</td>\n",
        "      <td> 0.870433</td>\n",
        "      <td> 0.905106</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.924132</td>\n",
        "      <td> 1.251677</td>\n",
        "      <td> 1.964908</td>\n",
        "      <td> 0.823503</td>\n",
        "      <td> 0.735938</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.113312</td>\n",
        "      <td> 0.898143</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.457695</td>\n",
        "      <td> 0.737643</td>\n",
        "      <td> 1.335439</td>\n",
        "      <td> 1.289815</td>\n",
        "      <td> 0.936256</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.103000</td>\n",
        "      <td> 1.013275</td>\n",
        "      <td> 0.866141</td>\n",
        "      <td> 0.932373</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.988390</td>\n",
        "      <td> 1.280171</td>\n",
        "      <td> 1.902316</td>\n",
        "      <td> 0.793439</td>\n",
        "      <td> 0.779662</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.132257</td>\n",
        "      <td> 0.852844</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.426937</td>\n",
        "      <td> 0.707868</td>\n",
        "      <td> 1.335115</td>\n",
        "      <td> 1.299607</td>\n",
        "      <td> 0.914979</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.119555</td>\n",
        "      <td> 1.034389</td>\n",
        "      <td> 0.871106</td>\n",
        "      <td> 0.982366</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.024987</td>\n",
        "      <td> 1.286377</td>\n",
        "      <td> 2.057540</td>\n",
        "      <td> 0.790052</td>\n",
        "      <td> 0.660568</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.051902</td>\n",
        "      <td> 0.905680</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.400975</td>\n",
        "      <td> 0.711676</td>\n",
        "      <td> 1.279066</td>\n",
        "      <td> 1.281962</td>\n",
        "      <td> 0.922842</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.109258</td>\n",
        "      <td> 0.999319</td>\n",
        "      <td> 0.850998</td>\n",
        "      <td> 0.943363</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.054787</td>\n",
        "      <td> 1.239129</td>\n",
        "      <td> 2.025281</td>\n",
        "      <td> 0.806368</td>\n",
        "      <td> 0.699670</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.128210</td>\n",
        "      <td> 0.901389</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.447137</td>\n",
        "      <td> 0.719526</td>\n",
        "      <td> 1.319487</td>\n",
        "      <td> 1.305250</td>\n",
        "      <td> 0.924282</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.092351</td>\n",
        "      <td> 0.993627</td>\n",
        "      <td> 0.824035</td>\n",
        "      <td> 1.023164</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.057327</td>\n",
        "      <td> 1.264205</td>\n",
        "      <td> 2.075208</td>\n",
        "      <td> 0.801997</td>\n",
        "      <td> 0.704768</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.186198</td>\n",
        "      <td> 0.933890</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.392548</td>\n",
        "      <td> 0.736853</td>\n",
        "      <td> 1.280783</td>\n",
        "      <td> 1.275336</td>\n",
        "      <td> 0.937604</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.102752</td>\n",
        "      <td> 1.018125</td>\n",
        "      <td> 0.845022</td>\n",
        "      <td> 1.013899</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.014909</td>\n",
        "      <td> 1.284943</td>\n",
        "      <td> 1.974724</td>\n",
        "      <td> 0.796652</td>\n",
        "      <td> 0.789413</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.197670</td>\n",
        "      <td> 0.865297</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.398388</td>\n",
        "      <td> 0.732604</td>\n",
        "      <td> 1.369374</td>\n",
        "      <td> 1.310828</td>\n",
        "      <td> 0.919619</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.116041</td>\n",
        "      <td> 1.027563</td>\n",
        "      <td> 0.831167</td>\n",
        "      <td> 0.947503</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.999690</td>\n",
        "      <td> 1.290943</td>\n",
        "      <td> 1.869669</td>\n",
        "      <td> 0.808207</td>\n",
        "      <td> 0.795068</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.179727</td>\n",
        "      <td> 0.880790</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.352995</td>\n",
        "      <td> 0.722099</td>\n",
        "      <td> 1.299827</td>\n",
        "      <td> 1.351027</td>\n",
        "      <td> 0.910479</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.168083</td>\n",
        "      <td> 1.023046</td>\n",
        "      <td> 0.842090</td>\n",
        "      <td> 0.951294</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.965471</td>\n",
        "      <td> 1.278087</td>\n",
        "      <td> 1.762489</td>\n",
        "      <td> 0.821202</td>\n",
        "      <td> 0.773483</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.220626</td>\n",
        "      <td> 0.971945</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.359088</td>\n",
        "      <td> 0.715620</td>\n",
        "      <td> 1.311746</td>\n",
        "      <td> 1.265010</td>\n",
        "      <td> 0.914474</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.192095</td>\n",
        "      <td> 1.046784</td>\n",
        "      <td> 0.830638</td>\n",
        "      <td> 0.913431</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.968846</td>\n",
        "      <td> 1.233310</td>\n",
        "      <td> 1.920478</td>\n",
        "      <td> 0.808109</td>\n",
        "      <td> 0.885907</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.209257</td>\n",
        "      <td> 0.877150</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.334817</td>\n",
        "      <td> 0.704596</td>\n",
        "      <td> 1.312205</td>\n",
        "      <td> 1.283423</td>\n",
        "      <td> 0.936630</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.215998</td>\n",
        "      <td> 1.060101</td>\n",
        "      <td> 0.866810</td>\n",
        "      <td> 0.853002</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.978478</td>\n",
        "      <td> 1.222359</td>\n",
        "      <td> 1.824108</td>\n",
        "      <td> 0.784717</td>\n",
        "      <td> 0.821722</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.165573</td>\n",
        "      <td> 0.900278</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.345561</td>\n",
        "      <td> 0.700258</td>\n",
        "      <td> 1.330668</td>\n",
        "      <td> 1.242038</td>\n",
        "      <td> 0.935472</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.187976</td>\n",
        "      <td> 1.119804</td>\n",
        "      <td> 0.853519</td>\n",
        "      <td> 0.957855</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.981934</td>\n",
        "      <td> 1.168055</td>\n",
        "      <td> 1.753319</td>\n",
        "      <td> 0.818810</td>\n",
        "      <td> 0.861101</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.192567</td>\n",
        "      <td> 0.953677</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.350183</td>\n",
        "      <td> 0.730153</td>\n",
        "      <td> 1.339188</td>\n",
        "      <td> 1.246516</td>\n",
        "      <td> 0.931684</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.158596</td>\n",
        "      <td> 1.084051</td>\n",
        "      <td> 0.884156</td>\n",
        "      <td> 0.881060</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.949836</td>\n",
        "      <td> 1.236632</td>\n",
        "      <td> 1.812062</td>\n",
        "      <td> 0.792840</td>\n",
        "      <td> 0.798088</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.176468</td>\n",
        "      <td> 0.926053</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.315908</td>\n",
        "      <td> 0.734721</td>\n",
        "      <td> 1.339431</td>\n",
        "      <td> 1.282517</td>\n",
        "      <td> 0.921835</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.108706</td>\n",
        "      <td> 1.068601</td>\n",
        "      <td> 0.894191</td>\n",
        "      <td> 0.890311</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.946409</td>\n",
        "      <td> 1.189258</td>\n",
        "      <td> 1.733167</td>\n",
        "      <td> 0.813979</td>\n",
        "      <td> 0.782882</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.191700</td>\n",
        "      <td> 0.913509</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.404346</td>\n",
        "      <td> 0.741279</td>\n",
        "      <td> 1.301644</td>\n",
        "      <td> 1.247509</td>\n",
        "      <td> 0.928581</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.120880</td>\n",
        "      <td> 1.031616</td>\n",
        "      <td> 0.858940</td>\n",
        "      <td> 0.885554</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.949200</td>\n",
        "      <td> 1.193266</td>\n",
        "      <td> 1.832733</td>\n",
        "      <td> 0.819924</td>\n",
        "      <td> 0.796225</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.122287</td>\n",
        "      <td> 0.907617</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.425323</td>\n",
        "      <td> 0.713391</td>\n",
        "      <td> 1.333072</td>\n",
        "      <td> 1.216804</td>\n",
        "      <td> 0.929408</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.133357</td>\n",
        "      <td> 1.041951</td>\n",
        "      <td> 0.847441</td>\n",
        "      <td> 0.912218</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.927044</td>\n",
        "      <td> 1.254266</td>\n",
        "      <td> 1.722886</td>\n",
        "      <td> 0.814073</td>\n",
        "      <td> 0.620232</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.184142</td>\n",
        "      <td> 0.861668</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.420786</td>\n",
        "      <td> 0.754728</td>\n",
        "      <td> 1.274545</td>\n",
        "      <td> 1.239203</td>\n",
        "      <td> 0.913595</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.107773</td>\n",
        "      <td> 1.036369</td>\n",
        "      <td> 0.852310</td>\n",
        "      <td> 0.897757</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.916812</td>\n",
        "      <td> 1.197722</td>\n",
        "      <td> 1.720816</td>\n",
        "      <td> 0.830152</td>\n",
        "      <td> 0.879237</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.222156</td>\n",
        "      <td> 0.876637</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.476291</td>\n",
        "      <td> 0.740978</td>\n",
        "      <td> 1.313567</td>\n",
        "      <td> 1.240359</td>\n",
        "      <td> 0.923925</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.198226</td>\n",
        "      <td> 1.034039</td>\n",
        "      <td> 0.842385</td>\n",
        "      <td> 0.907633</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.929899</td>\n",
        "      <td> 1.224244</td>\n",
        "      <td> 1.833753</td>\n",
        "      <td> 0.840121</td>\n",
        "      <td> 0.755798</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.177253</td>\n",
        "      <td> 0.909863</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.482819</td>\n",
        "      <td> 0.741254</td>\n",
        "      <td> 1.334657</td>\n",
        "      <td> 1.246107</td>\n",
        "      <td> 0.905159</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.112875</td>\n",
        "      <td> 1.060384</td>\n",
        "      <td> 0.856864</td>\n",
        "      <td> 0.906753</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.943852</td>\n",
        "      <td> 1.214457</td>\n",
        "      <td> 1.767330</td>\n",
        "      <td> 0.839576</td>\n",
        "      <td> 0.756428</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.139539</td>\n",
        "      <td> 0.885290</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.415769</td>\n",
        "      <td> 0.726478</td>\n",
        "      <td> 1.284352</td>\n",
        "      <td> 1.224559</td>\n",
        "      <td> 0.920774</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.127010</td>\n",
        "      <td> 1.049415</td>\n",
        "      <td> 0.847157</td>\n",
        "      <td> 0.890563</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.911258</td>\n",
        "      <td> 1.227306</td>\n",
        "      <td> 1.626024</td>\n",
        "      <td> 0.834018</td>\n",
        "      <td> 0.901499</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.103844</td>\n",
        "      <td> 0.958418</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.499301</td>\n",
        "      <td> 0.743920</td>\n",
        "      <td> 1.326249</td>\n",
        "      <td> 1.251013</td>\n",
        "      <td> 0.917857</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.147295</td>\n",
        "      <td> 1.073873</td>\n",
        "      <td> 0.850461</td>\n",
        "      <td> 0.885675</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.914357</td>\n",
        "      <td> 1.187650</td>\n",
        "      <td> 1.623181</td>\n",
        "      <td> 0.808795</td>\n",
        "      <td> 0.782573</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.147338</td>\n",
        "      <td> 0.953121</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.451166</td>\n",
        "      <td> 0.719952</td>\n",
        "      <td> 1.337504</td>\n",
        "      <td> 1.255563</td>\n",
        "      <td> 0.929011</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.262762</td>\n",
        "      <td> 1.068583</td>\n",
        "      <td> 0.823907</td>\n",
        "      <td> 0.914684</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.913675</td>\n",
        "      <td> 1.186540</td>\n",
        "      <td> 1.683652</td>\n",
        "      <td> 0.812660</td>\n",
        "      <td> 0.894844</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.161194</td>\n",
        "      <td> 0.935735</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.380668</td>\n",
        "      <td> 0.717000</td>\n",
        "      <td> 1.338191</td>\n",
        "      <td> 1.224321</td>\n",
        "      <td> 0.922839</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.197824</td>\n",
        "      <td> 1.076328</td>\n",
        "      <td> 0.829274</td>\n",
        "      <td> 0.808940</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.917343</td>\n",
        "      <td> 1.209817</td>\n",
        "      <td> 1.678411</td>\n",
        "      <td> 0.827632</td>\n",
        "      <td> 0.676098</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.162238</td>\n",
        "      <td> 0.879686</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.409357</td>\n",
        "      <td> 0.708875</td>\n",
        "      <td> 1.359572</td>\n",
        "      <td> 1.148951</td>\n",
        "      <td> 0.920372</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.251455</td>\n",
        "      <td> 1.110959</td>\n",
        "      <td> 0.818010</td>\n",
        "      <td> 0.905060</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.939174</td>\n",
        "      <td> 1.161535</td>\n",
        "      <td> 1.645133</td>\n",
        "      <td> 0.845016</td>\n",
        "      <td> 0.670072</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.214636</td>\n",
        "      <td> 0.920171</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.372827</td>\n",
        "      <td> 0.725926</td>\n",
        "      <td> 1.352882</td>\n",
        "      <td> 1.217944</td>\n",
        "      <td> 0.911276</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.246368</td>\n",
        "      <td> 1.066258</td>\n",
        "      <td> 0.830394</td>\n",
        "      <td> 0.869350</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.902075</td>\n",
        "      <td> 1.194549</td>\n",
        "      <td> 1.555186</td>\n",
        "      <td> 0.845911</td>\n",
        "      <td> 0.726739</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.088895</td>\n",
        "      <td> 0.923347</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.354969</td>\n",
        "      <td> 0.731017</td>\n",
        "      <td> 1.312544</td>\n",
        "      <td> 1.249870</td>\n",
        "      <td> 0.902883</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.260472</td>\n",
        "      <td> 1.097727</td>\n",
        "      <td> 0.837721</td>\n",
        "      <td> 0.900227</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.925379</td>\n",
        "      <td> 1.179451</td>\n",
        "      <td> 1.595920</td>\n",
        "      <td> 0.849099</td>\n",
        "      <td> 0.724552</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.141561</td>\n",
        "      <td> 0.859173</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.353167</td>\n",
        "      <td> 0.726305</td>\n",
        "      <td> 1.285568</td>\n",
        "      <td> 1.242610</td>\n",
        "      <td> 0.935487</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.295829</td>\n",
        "      <td> 1.083867</td>\n",
        "      <td> 0.842675</td>\n",
        "      <td> 0.871548</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.908153</td>\n",
        "      <td> 1.204712</td>\n",
        "      <td> 1.649104</td>\n",
        "      <td> 0.828632</td>\n",
        "      <td> 0.788245</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.172639</td>\n",
        "      <td> 0.938209</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.345563</td>\n",
        "      <td> 0.742922</td>\n",
        "      <td> 1.308335</td>\n",
        "      <td> 1.254570</td>\n",
        "      <td> 0.908323</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.176980</td>\n",
        "      <td> 1.058150</td>\n",
        "      <td> 0.841469</td>\n",
        "      <td> 0.880084</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.901572</td>\n",
        "      <td> 1.227678</td>\n",
        "      <td> 1.528369</td>\n",
        "      <td> 0.833363</td>\n",
        "      <td> 0.743932</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.124068</td>\n",
        "      <td> 0.843041</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.361368</td>\n",
        "      <td> 0.802754</td>\n",
        "      <td> 1.299500</td>\n",
        "      <td> 1.248314</td>\n",
        "      <td> 0.927719</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.141683</td>\n",
        "      <td> 1.065408</td>\n",
        "      <td> 0.843866</td>\n",
        "      <td> 0.937743</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.894104</td>\n",
        "      <td> 1.230919</td>\n",
        "      <td> 1.512893</td>\n",
        "      <td> 0.827535</td>\n",
        "      <td> 0.643989</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.096505</td>\n",
        "      <td> 0.893690</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.323492</td>\n",
        "      <td> 0.787076</td>\n",
        "      <td> 1.242158</td>\n",
        "      <td> 1.246729</td>\n",
        "      <td> 0.897874</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.146466</td>\n",
        "      <td> 1.070257</td>\n",
        "      <td> 0.815766</td>\n",
        "      <td> 0.954481</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.924172</td>\n",
        "      <td> 1.174624</td>\n",
        "      <td> 1.551224</td>\n",
        "      <td> 0.838045</td>\n",
        "      <td> 0.732317</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.052190</td>\n",
        "      <td> 0.905464</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.333938</td>\n",
        "      <td> 0.788008</td>\n",
        "      <td> 1.273866</td>\n",
        "      <td> 1.235907</td>\n",
        "      <td> 0.913761</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>42</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.182994</td>\n",
        "      <td> 1.058728</td>\n",
        "      <td> 0.840673</td>\n",
        "      <td> 0.904794</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.896926</td>\n",
        "      <td> 1.182318</td>\n",
        "      <td> 1.522829</td>\n",
        "      <td> 0.828120</td>\n",
        "      <td> 0.839039</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.065339</td>\n",
        "      <td> 0.906503</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.286743</td>\n",
        "      <td> 0.768100</td>\n",
        "      <td> 1.272362</td>\n",
        "      <td> 1.194314</td>\n",
        "      <td> 0.943580</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.171030</td>\n",
        "      <td> 1.084509</td>\n",
        "      <td> 0.833074</td>\n",
        "      <td> 0.959364</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.968003</td>\n",
        "      <td> 1.169622</td>\n",
        "      <td> 1.545543</td>\n",
        "      <td> 0.859814</td>\n",
        "      <td> 0.824728</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.015828</td>\n",
        "      <td> 0.946893</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.285985</td>\n",
        "      <td> 0.747821</td>\n",
        "      <td> 1.250453</td>\n",
        "      <td> 1.210477</td>\n",
        "      <td> 0.907234</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.150949</td>\n",
        "      <td> 1.076763</td>\n",
        "      <td> 0.809140</td>\n",
        "      <td> 0.927448</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.949275</td>\n",
        "      <td> 1.185598</td>\n",
        "      <td> 1.623475</td>\n",
        "      <td> 0.819825</td>\n",
        "      <td> 0.821646</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.056274</td>\n",
        "      <td> 0.870963</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.237620</td>\n",
        "      <td> 0.770678</td>\n",
        "      <td> 1.239300</td>\n",
        "      <td> 1.188682</td>\n",
        "      <td> 0.941372</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>45</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.193901</td>\n",
        "      <td> 1.041982</td>\n",
        "      <td> 0.855710</td>\n",
        "      <td> 0.940043</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.001983</td>\n",
        "      <td> 1.188239</td>\n",
        "      <td> 1.528960</td>\n",
        "      <td> 0.850938</td>\n",
        "      <td> 0.693568</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.096069</td>\n",
        "      <td> 0.835806</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.223449</td>\n",
        "      <td> 0.742239</td>\n",
        "      <td> 1.274150</td>\n",
        "      <td> 1.198657</td>\n",
        "      <td> 0.931096</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>46</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.125131</td>\n",
        "      <td> 1.064386</td>\n",
        "      <td> 0.827873</td>\n",
        "      <td> 0.942410</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.977042</td>\n",
        "      <td> 1.178765</td>\n",
        "      <td> 1.504000</td>\n",
        "      <td> 0.835818</td>\n",
        "      <td> 0.831074</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.049562</td>\n",
        "      <td> 0.882395</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.227195</td>\n",
        "      <td> 0.782999</td>\n",
        "      <td> 1.248567</td>\n",
        "      <td> 1.216807</td>\n",
        "      <td> 0.914958</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>47</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.148932</td>\n",
        "      <td> 1.050605</td>\n",
        "      <td> 0.833384</td>\n",
        "      <td> 0.965211</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.966020</td>\n",
        "      <td> 1.177800</td>\n",
        "      <td> 1.472108</td>\n",
        "      <td> 0.842837</td>\n",
        "      <td> 0.794777</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.103219</td>\n",
        "      <td> 0.842688</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.268196</td>\n",
        "      <td> 0.787032</td>\n",
        "      <td> 1.278980</td>\n",
        "      <td> 1.206940</td>\n",
        "      <td> 0.917801</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.105919</td>\n",
        "      <td> 1.026582</td>\n",
        "      <td> 0.812649</td>\n",
        "      <td> 0.908718</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.930388</td>\n",
        "      <td> 1.180902</td>\n",
        "      <td> 1.464360</td>\n",
        "      <td> 0.837915</td>\n",
        "      <td> 0.707697</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.124322</td>\n",
        "      <td> 0.909057</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.233639</td>\n",
        "      <td> 0.776922</td>\n",
        "      <td> 1.223745</td>\n",
        "      <td> 1.203003</td>\n",
        "      <td> 0.927858</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>49</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.092417</td>\n",
        "      <td> 1.046825</td>\n",
        "      <td> 0.808892</td>\n",
        "      <td> 0.905709</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.951414</td>\n",
        "      <td> 1.196823</td>\n",
        "      <td> 1.472985</td>\n",
        "      <td> 0.851455</td>\n",
        "      <td> 0.719945</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.050516</td>\n",
        "      <td> 0.947845</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.237479</td>\n",
        "      <td> 0.789197</td>\n",
        "      <td> 1.238079</td>\n",
        "      <td> 1.195766</td>\n",
        "      <td> 0.907470</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.094954</td>\n",
        "      <td> 1.042596</td>\n",
        "      <td> 0.815771</td>\n",
        "      <td> 0.871148</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.916080</td>\n",
        "      <td> 1.214054</td>\n",
        "      <td> 1.473290</td>\n",
        "      <td> 0.850034</td>\n",
        "      <td> 0.745289</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.130995</td>\n",
        "      <td> 0.770273</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.246354</td>\n",
        "      <td> 0.786293</td>\n",
        "      <td> 1.249738</td>\n",
        "      <td> 1.204481</td>\n",
        "      <td> 0.903925</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>51</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.139111</td>\n",
        "      <td> 1.120253</td>\n",
        "      <td> 0.817140</td>\n",
        "      <td> 0.882456</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.929059</td>\n",
        "      <td> 1.187267</td>\n",
        "      <td> 1.463174</td>\n",
        "      <td> 0.844762</td>\n",
        "      <td> 0.732641</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.084564</td>\n",
        "      <td> 0.901644</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.218541</td>\n",
        "      <td> 0.798575</td>\n",
        "      <td> 1.224200</td>\n",
        "      <td> 1.188808</td>\n",
        "      <td> 0.927099</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>52</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.233511</td>\n",
        "      <td> 1.124378</td>\n",
        "      <td> 0.803889</td>\n",
        "      <td> 0.885395</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.889751</td>\n",
        "      <td> 1.164635</td>\n",
        "      <td> 1.464764</td>\n",
        "      <td> 0.886660</td>\n",
        "      <td> 0.857251</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.193761</td>\n",
        "      <td> 0.875667</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.228733</td>\n",
        "      <td> 0.793207</td>\n",
        "      <td> 1.248426</td>\n",
        "      <td> 1.211009</td>\n",
        "      <td> 0.920122</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>53</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.199786</td>\n",
        "      <td> 1.069022</td>\n",
        "      <td> 0.813254</td>\n",
        "      <td> 0.893515</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.894570</td>\n",
        "      <td> 1.167781</td>\n",
        "      <td> 1.426393</td>\n",
        "      <td> 0.848473</td>\n",
        "      <td> 0.865493</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.103356</td>\n",
        "      <td> 0.880377</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.218958</td>\n",
        "      <td> 0.789208</td>\n",
        "      <td> 1.236677</td>\n",
        "      <td> 1.161852</td>\n",
        "      <td> 0.910309</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>54</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.285109</td>\n",
        "      <td> 1.138679</td>\n",
        "      <td> 0.815368</td>\n",
        "      <td> 0.836093</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.872253</td>\n",
        "      <td> 1.127910</td>\n",
        "      <td> 1.464071</td>\n",
        "      <td> 0.846671</td>\n",
        "      <td> 0.834294</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.092701</td>\n",
        "      <td> 0.913510</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.164969</td>\n",
        "      <td> 0.781764</td>\n",
        "      <td> 1.227238</td>\n",
        "      <td> 1.197676</td>\n",
        "      <td> 0.899591</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>55</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.192805</td>\n",
        "      <td> 1.072235</td>\n",
        "      <td> 0.803100</td>\n",
        "      <td> 0.875685</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.915278</td>\n",
        "      <td> 1.117986</td>\n",
        "      <td> 1.410572</td>\n",
        "      <td> 0.826361</td>\n",
        "      <td> 0.863230</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.058490</td>\n",
        "      <td> 0.841762</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.205397</td>\n",
        "      <td> 0.782552</td>\n",
        "      <td> 1.221456</td>\n",
        "      <td> 1.176825</td>\n",
        "      <td> 0.905752</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>56</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.170924</td>\n",
        "      <td> 1.096228</td>\n",
        "      <td> 0.796786</td>\n",
        "      <td> 0.865518</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.907974</td>\n",
        "      <td> 1.155671</td>\n",
        "      <td> 1.395308</td>\n",
        "      <td> 0.856491</td>\n",
        "      <td> 0.755889</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.068193</td>\n",
        "      <td> 0.898282</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.192703</td>\n",
        "      <td> 0.798687</td>\n",
        "      <td> 1.239794</td>\n",
        "      <td> 1.140225</td>\n",
        "      <td> 0.916444</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>57</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.168053</td>\n",
        "      <td> 1.103499</td>\n",
        "      <td> 0.830829</td>\n",
        "      <td> 0.890700</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.899391</td>\n",
        "      <td> 1.152094</td>\n",
        "      <td> 1.480546</td>\n",
        "      <td> 0.878334</td>\n",
        "      <td> 0.868943</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.101614</td>\n",
        "      <td> 0.947986</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.176620</td>\n",
        "      <td> 0.774520</td>\n",
        "      <td> 1.229049</td>\n",
        "      <td> 1.147721</td>\n",
        "      <td> 0.911808</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>58</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.154108</td>\n",
        "      <td> 1.084108</td>\n",
        "      <td> 0.820091</td>\n",
        "      <td> 0.909542</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.893912</td>\n",
        "      <td> 1.150171</td>\n",
        "      <td> 1.465084</td>\n",
        "      <td> 0.885216</td>\n",
        "      <td> 0.849625</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.135458</td>\n",
        "      <td> 0.952802</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.190469</td>\n",
        "      <td> 0.773222</td>\n",
        "      <td> 1.239933</td>\n",
        "      <td> 1.154544</td>\n",
        "      <td> 0.898223</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>59</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1.126614</td>\n",
        "      <td> 1.072421</td>\n",
        "      <td> 0.827838</td>\n",
        "      <td> 0.926899</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0.897318</td>\n",
        "      <td> 1.163595</td>\n",
        "      <td> 1.322805</td>\n",
        "      <td> 0.858264</td>\n",
        "      <td> 0.750125</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.060593</td>\n",
        "      <td> 0.901311</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1.217061</td>\n",
        "      <td> 0.839054</td>\n",
        "      <td> 1.160617</td>\n",
        "      <td> 1.161689</td>\n",
        "      <td> 0.930556</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>300 rows \u00d7 176 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 228,
       "text": [
        "      Unnamed: 0  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  \\\n",
        "tags                                                                           \n",
        "0              0    1.257537    1.202656    0.875276    0.930304         NaN   \n",
        "1              0    1.209284    1.160281    0.888718    0.924845         NaN   \n",
        "2              0    1.211094    1.111101    0.869316    0.946763         NaN   \n",
        "3              0    1.162955    1.095824    0.901523    0.943744         NaN   \n",
        "4              0    1.140220    1.083488    0.873273    0.944194         NaN   \n",
        "5              0    1.155609    1.062018    0.880750    0.919496         NaN   \n",
        "6              0    1.170139    1.078257    0.878946    0.865752         NaN   \n",
        "7              0    1.095765    1.055215    0.841316    0.926448         NaN   \n",
        "8              0    1.132007    1.038625    0.856640    0.886891         NaN   \n",
        "9              0    1.127625    1.083734    0.849103    0.870105         NaN   \n",
        "10             0    1.112026    1.039772    0.848171    0.877791         NaN   \n",
        "11             0    1.163634    1.043313    0.851165    0.851306         NaN   \n",
        "12             0    1.203256    1.021462    0.812591    0.905103         NaN   \n",
        "13             0    1.119307    1.006211    0.870433    0.905106         NaN   \n",
        "14             0    1.103000    1.013275    0.866141    0.932373         NaN   \n",
        "15             0    1.119555    1.034389    0.871106    0.982366         NaN   \n",
        "16             0    1.109258    0.999319    0.850998    0.943363         NaN   \n",
        "17             0    1.092351    0.993627    0.824035    1.023164         NaN   \n",
        "18             0    1.102752    1.018125    0.845022    1.013899         NaN   \n",
        "19             0    1.116041    1.027563    0.831167    0.947503         NaN   \n",
        "20             0    1.168083    1.023046    0.842090    0.951294         NaN   \n",
        "21             0    1.192095    1.046784    0.830638    0.913431         NaN   \n",
        "22             0    1.215998    1.060101    0.866810    0.853002         NaN   \n",
        "23             0    1.187976    1.119804    0.853519    0.957855         NaN   \n",
        "24             0    1.158596    1.084051    0.884156    0.881060         NaN   \n",
        "25             0    1.108706    1.068601    0.894191    0.890311         NaN   \n",
        "26             0    1.120880    1.031616    0.858940    0.885554         NaN   \n",
        "27             0    1.133357    1.041951    0.847441    0.912218         NaN   \n",
        "28             0    1.107773    1.036369    0.852310    0.897757         NaN   \n",
        "29             0    1.198226    1.034039    0.842385    0.907633         NaN   \n",
        "30             0    1.112875    1.060384    0.856864    0.906753         NaN   \n",
        "31             0    1.127010    1.049415    0.847157    0.890563         NaN   \n",
        "32             0    1.147295    1.073873    0.850461    0.885675         NaN   \n",
        "33             0    1.262762    1.068583    0.823907    0.914684         NaN   \n",
        "34             0    1.197824    1.076328    0.829274    0.808940         NaN   \n",
        "35             0    1.251455    1.110959    0.818010    0.905060         NaN   \n",
        "36             0    1.246368    1.066258    0.830394    0.869350         NaN   \n",
        "37             0    1.260472    1.097727    0.837721    0.900227         NaN   \n",
        "38             0    1.295829    1.083867    0.842675    0.871548         NaN   \n",
        "39             0    1.176980    1.058150    0.841469    0.880084         NaN   \n",
        "40             0    1.141683    1.065408    0.843866    0.937743         NaN   \n",
        "41             0    1.146466    1.070257    0.815766    0.954481         NaN   \n",
        "42             0    1.182994    1.058728    0.840673    0.904794         NaN   \n",
        "43             0    1.171030    1.084509    0.833074    0.959364         NaN   \n",
        "44             0    1.150949    1.076763    0.809140    0.927448         NaN   \n",
        "45             0    1.193901    1.041982    0.855710    0.940043         NaN   \n",
        "46             0    1.125131    1.064386    0.827873    0.942410         NaN   \n",
        "47             0    1.148932    1.050605    0.833384    0.965211         NaN   \n",
        "48             0    1.105919    1.026582    0.812649    0.908718         NaN   \n",
        "49             0    1.092417    1.046825    0.808892    0.905709         NaN   \n",
        "50             0    1.094954    1.042596    0.815771    0.871148         NaN   \n",
        "51             0    1.139111    1.120253    0.817140    0.882456         NaN   \n",
        "52             0    1.233511    1.124378    0.803889    0.885395         NaN   \n",
        "53             0    1.199786    1.069022    0.813254    0.893515         NaN   \n",
        "54             0    1.285109    1.138679    0.815368    0.836093         NaN   \n",
        "55             0    1.192805    1.072235    0.803100    0.875685         NaN   \n",
        "56             0    1.170924    1.096228    0.796786    0.865518         NaN   \n",
        "57             0    1.168053    1.103499    0.830829    0.890700         NaN   \n",
        "58             0    1.154108    1.084108    0.820091    0.909542         NaN   \n",
        "59             0    1.126614    1.072421    0.827838    0.926899         NaN   \n",
        "             ...         ...         ...         ...         ...         ...   \n",
        "\n",
        "      Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10  Unnamed: 11  \\\n",
        "tags                                                                 \n",
        "0       0.910773    1.213944    1.869776     0.786133     0.679948   \n",
        "1       0.986044    1.286672    2.013144     0.785111     0.646886   \n",
        "2       0.915515    1.284043    2.037372     0.772286     0.768509   \n",
        "3       0.953089    1.270332    2.152563     0.778466     0.768661   \n",
        "4       0.925327    1.263475    2.050155     0.774643     0.676298   \n",
        "5       0.943891    1.218690    2.063526     0.801323     0.710870   \n",
        "6       0.943213    1.243548    1.965035     0.788966     0.735629   \n",
        "7       0.953239    1.239388    1.909568     0.786193     0.962416   \n",
        "8       0.967746    1.259463    1.987421     0.786869     0.794854   \n",
        "9       0.914084    1.222537    1.931253     0.793603     0.840535   \n",
        "10      0.950812    1.251848    1.976058     0.792120     0.698222   \n",
        "11      0.893279    1.251117    2.025112     0.794704     0.779585   \n",
        "12      0.934851    1.264440    1.936942     0.786109     0.729574   \n",
        "13      0.924132    1.251677    1.964908     0.823503     0.735938   \n",
        "14      0.988390    1.280171    1.902316     0.793439     0.779662   \n",
        "15      1.024987    1.286377    2.057540     0.790052     0.660568   \n",
        "16      1.054787    1.239129    2.025281     0.806368     0.699670   \n",
        "17      1.057327    1.264205    2.075208     0.801997     0.704768   \n",
        "18      1.014909    1.284943    1.974724     0.796652     0.789413   \n",
        "19      0.999690    1.290943    1.869669     0.808207     0.795068   \n",
        "20      0.965471    1.278087    1.762489     0.821202     0.773483   \n",
        "21      0.968846    1.233310    1.920478     0.808109     0.885907   \n",
        "22      0.978478    1.222359    1.824108     0.784717     0.821722   \n",
        "23      0.981934    1.168055    1.753319     0.818810     0.861101   \n",
        "24      0.949836    1.236632    1.812062     0.792840     0.798088   \n",
        "25      0.946409    1.189258    1.733167     0.813979     0.782882   \n",
        "26      0.949200    1.193266    1.832733     0.819924     0.796225   \n",
        "27      0.927044    1.254266    1.722886     0.814073     0.620232   \n",
        "28      0.916812    1.197722    1.720816     0.830152     0.879237   \n",
        "29      0.929899    1.224244    1.833753     0.840121     0.755798   \n",
        "30      0.943852    1.214457    1.767330     0.839576     0.756428   \n",
        "31      0.911258    1.227306    1.626024     0.834018     0.901499   \n",
        "32      0.914357    1.187650    1.623181     0.808795     0.782573   \n",
        "33      0.913675    1.186540    1.683652     0.812660     0.894844   \n",
        "34      0.917343    1.209817    1.678411     0.827632     0.676098   \n",
        "35      0.939174    1.161535    1.645133     0.845016     0.670072   \n",
        "36      0.902075    1.194549    1.555186     0.845911     0.726739   \n",
        "37      0.925379    1.179451    1.595920     0.849099     0.724552   \n",
        "38      0.908153    1.204712    1.649104     0.828632     0.788245   \n",
        "39      0.901572    1.227678    1.528369     0.833363     0.743932   \n",
        "40      0.894104    1.230919    1.512893     0.827535     0.643989   \n",
        "41      0.924172    1.174624    1.551224     0.838045     0.732317   \n",
        "42      0.896926    1.182318    1.522829     0.828120     0.839039   \n",
        "43      0.968003    1.169622    1.545543     0.859814     0.824728   \n",
        "44      0.949275    1.185598    1.623475     0.819825     0.821646   \n",
        "45      1.001983    1.188239    1.528960     0.850938     0.693568   \n",
        "46      0.977042    1.178765    1.504000     0.835818     0.831074   \n",
        "47      0.966020    1.177800    1.472108     0.842837     0.794777   \n",
        "48      0.930388    1.180902    1.464360     0.837915     0.707697   \n",
        "49      0.951414    1.196823    1.472985     0.851455     0.719945   \n",
        "50      0.916080    1.214054    1.473290     0.850034     0.745289   \n",
        "51      0.929059    1.187267    1.463174     0.844762     0.732641   \n",
        "52      0.889751    1.164635    1.464764     0.886660     0.857251   \n",
        "53      0.894570    1.167781    1.426393     0.848473     0.865493   \n",
        "54      0.872253    1.127910    1.464071     0.846671     0.834294   \n",
        "55      0.915278    1.117986    1.410572     0.826361     0.863230   \n",
        "56      0.907974    1.155671    1.395308     0.856491     0.755889   \n",
        "57      0.899391    1.152094    1.480546     0.878334     0.868943   \n",
        "58      0.893912    1.150171    1.465084     0.885216     0.849625   \n",
        "59      0.897318    1.163595    1.322805     0.858264     0.750125   \n",
        "             ...         ...         ...          ...          ...   \n",
        "\n",
        "      Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15  Unnamed: 16  \\\n",
        "tags                                                                    \n",
        "0             NaN     1.244137     0.892062          NaN     1.467173   \n",
        "1             NaN     1.322925     0.906960          NaN     1.438676   \n",
        "2             NaN     1.209985     0.916695          NaN     1.512563   \n",
        "3             NaN     1.214774     0.865378          NaN     1.503331   \n",
        "4             NaN     1.226599     0.919253          NaN     1.474375   \n",
        "5             NaN     1.156469     0.897673          NaN     1.521605   \n",
        "6             NaN     1.207983     0.857581          NaN     1.511891   \n",
        "7             NaN     1.180882     0.894560          NaN     1.522503   \n",
        "8             NaN     1.147852     0.890188          NaN     1.456368   \n",
        "9             NaN     1.222674     0.837438          NaN     1.475686   \n",
        "10            NaN     1.113963     0.871786          NaN     1.503885   \n",
        "11            NaN     1.155021     0.900293          NaN     1.492155   \n",
        "12            NaN     1.079466     0.877030          NaN     1.471543   \n",
        "13            NaN     1.113312     0.898143          NaN     1.457695   \n",
        "14            NaN     1.132257     0.852844          NaN     1.426937   \n",
        "15            NaN     1.051902     0.905680          NaN     1.400975   \n",
        "16            NaN     1.128210     0.901389          NaN     1.447137   \n",
        "17            NaN     1.186198     0.933890          NaN     1.392548   \n",
        "18            NaN     1.197670     0.865297          NaN     1.398388   \n",
        "19            NaN     1.179727     0.880790          NaN     1.352995   \n",
        "20            NaN     1.220626     0.971945          NaN     1.359088   \n",
        "21            NaN     1.209257     0.877150          NaN     1.334817   \n",
        "22            NaN     1.165573     0.900278          NaN     1.345561   \n",
        "23            NaN     1.192567     0.953677          NaN     1.350183   \n",
        "24            NaN     1.176468     0.926053          NaN     1.315908   \n",
        "25            NaN     1.191700     0.913509          NaN     1.404346   \n",
        "26            NaN     1.122287     0.907617          NaN     1.425323   \n",
        "27            NaN     1.184142     0.861668          NaN     1.420786   \n",
        "28            NaN     1.222156     0.876637          NaN     1.476291   \n",
        "29            NaN     1.177253     0.909863          NaN     1.482819   \n",
        "30            NaN     1.139539     0.885290          NaN     1.415769   \n",
        "31            NaN     1.103844     0.958418          NaN     1.499301   \n",
        "32            NaN     1.147338     0.953121          NaN     1.451166   \n",
        "33            NaN     1.161194     0.935735          NaN     1.380668   \n",
        "34            NaN     1.162238     0.879686          NaN     1.409357   \n",
        "35            NaN     1.214636     0.920171          NaN     1.372827   \n",
        "36            NaN     1.088895     0.923347          NaN     1.354969   \n",
        "37            NaN     1.141561     0.859173          NaN     1.353167   \n",
        "38            NaN     1.172639     0.938209          NaN     1.345563   \n",
        "39            NaN     1.124068     0.843041          NaN     1.361368   \n",
        "40            NaN     1.096505     0.893690          NaN     1.323492   \n",
        "41            NaN     1.052190     0.905464          NaN     1.333938   \n",
        "42            NaN     1.065339     0.906503          NaN     1.286743   \n",
        "43            NaN     1.015828     0.946893          NaN     1.285985   \n",
        "44            NaN     1.056274     0.870963          NaN     1.237620   \n",
        "45            NaN     1.096069     0.835806          NaN     1.223449   \n",
        "46            NaN     1.049562     0.882395          NaN     1.227195   \n",
        "47            NaN     1.103219     0.842688          NaN     1.268196   \n",
        "48            NaN     1.124322     0.909057          NaN     1.233639   \n",
        "49            NaN     1.050516     0.947845          NaN     1.237479   \n",
        "50            NaN     1.130995     0.770273          NaN     1.246354   \n",
        "51            NaN     1.084564     0.901644          NaN     1.218541   \n",
        "52            NaN     1.193761     0.875667          NaN     1.228733   \n",
        "53            NaN     1.103356     0.880377          NaN     1.218958   \n",
        "54            NaN     1.092701     0.913510          NaN     1.164969   \n",
        "55            NaN     1.058490     0.841762          NaN     1.205397   \n",
        "56            NaN     1.068193     0.898282          NaN     1.192703   \n",
        "57            NaN     1.101614     0.947986          NaN     1.176620   \n",
        "58            NaN     1.135458     0.952802          NaN     1.190469   \n",
        "59            NaN     1.060593     0.901311          NaN     1.217061   \n",
        "              ...          ...          ...          ...          ...   \n",
        "\n",
        "      Unnamed: 17  Unnamed: 18  Unnamed: 19  Unnamed: 20      \n",
        "tags                                                          \n",
        "0        0.705478     1.310110     1.356881     0.937740 ...  \n",
        "1        0.679709     1.372201     1.372144     0.938082 ...  \n",
        "2        0.712535     1.368941     1.347543     0.933265 ...  \n",
        "3        0.709364     1.285667     1.319194     0.947982 ...  \n",
        "4        0.698087     1.264062     1.336947     0.927490 ...  \n",
        "5        0.711264     1.294004     1.279483     0.934675 ...  \n",
        "6        0.713689     1.308617     1.298914     0.930393 ...  \n",
        "7        0.708318     1.315929     1.321313     0.945906 ...  \n",
        "8        0.725654     1.316003     1.268275     0.946929 ...  \n",
        "9        0.711966     1.374607     1.273115     0.953046 ...  \n",
        "10       0.753007     1.323523     1.336836     0.945210 ...  \n",
        "11       0.719690     1.363352     1.300711     0.927967 ...  \n",
        "12       0.709597     1.300870     1.323717     0.929299 ...  \n",
        "13       0.737643     1.335439     1.289815     0.936256 ...  \n",
        "14       0.707868     1.335115     1.299607     0.914979 ...  \n",
        "15       0.711676     1.279066     1.281962     0.922842 ...  \n",
        "16       0.719526     1.319487     1.305250     0.924282 ...  \n",
        "17       0.736853     1.280783     1.275336     0.937604 ...  \n",
        "18       0.732604     1.369374     1.310828     0.919619 ...  \n",
        "19       0.722099     1.299827     1.351027     0.910479 ...  \n",
        "20       0.715620     1.311746     1.265010     0.914474 ...  \n",
        "21       0.704596     1.312205     1.283423     0.936630 ...  \n",
        "22       0.700258     1.330668     1.242038     0.935472 ...  \n",
        "23       0.730153     1.339188     1.246516     0.931684 ...  \n",
        "24       0.734721     1.339431     1.282517     0.921835 ...  \n",
        "25       0.741279     1.301644     1.247509     0.928581 ...  \n",
        "26       0.713391     1.333072     1.216804     0.929408 ...  \n",
        "27       0.754728     1.274545     1.239203     0.913595 ...  \n",
        "28       0.740978     1.313567     1.240359     0.923925 ...  \n",
        "29       0.741254     1.334657     1.246107     0.905159 ...  \n",
        "30       0.726478     1.284352     1.224559     0.920774 ...  \n",
        "31       0.743920     1.326249     1.251013     0.917857 ...  \n",
        "32       0.719952     1.337504     1.255563     0.929011 ...  \n",
        "33       0.717000     1.338191     1.224321     0.922839 ...  \n",
        "34       0.708875     1.359572     1.148951     0.920372 ...  \n",
        "35       0.725926     1.352882     1.217944     0.911276 ...  \n",
        "36       0.731017     1.312544     1.249870     0.902883 ...  \n",
        "37       0.726305     1.285568     1.242610     0.935487 ...  \n",
        "38       0.742922     1.308335     1.254570     0.908323 ...  \n",
        "39       0.802754     1.299500     1.248314     0.927719 ...  \n",
        "40       0.787076     1.242158     1.246729     0.897874 ...  \n",
        "41       0.788008     1.273866     1.235907     0.913761 ...  \n",
        "42       0.768100     1.272362     1.194314     0.943580 ...  \n",
        "43       0.747821     1.250453     1.210477     0.907234 ...  \n",
        "44       0.770678     1.239300     1.188682     0.941372 ...  \n",
        "45       0.742239     1.274150     1.198657     0.931096 ...  \n",
        "46       0.782999     1.248567     1.216807     0.914958 ...  \n",
        "47       0.787032     1.278980     1.206940     0.917801 ...  \n",
        "48       0.776922     1.223745     1.203003     0.927858 ...  \n",
        "49       0.789197     1.238079     1.195766     0.907470 ...  \n",
        "50       0.786293     1.249738     1.204481     0.903925 ...  \n",
        "51       0.798575     1.224200     1.188808     0.927099 ...  \n",
        "52       0.793207     1.248426     1.211009     0.920122 ...  \n",
        "53       0.789208     1.236677     1.161852     0.910309 ...  \n",
        "54       0.781764     1.227238     1.197676     0.899591 ...  \n",
        "55       0.782552     1.221456     1.176825     0.905752 ...  \n",
        "56       0.798687     1.239794     1.140225     0.916444 ...  \n",
        "57       0.774520     1.229049     1.147721     0.911808 ...  \n",
        "58       0.773222     1.239933     1.154544     0.898223 ...  \n",
        "59       0.839054     1.160617     1.161689     0.930556 ...  \n",
        "              ...          ...          ...          ...      \n",
        "\n",
        "[300 rows x 176 columns]"
       ]
      }
     ],
     "prompt_number": 228
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Data['original']['Mean1'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "time(s)\n",
        "0.000      7355.028\n",
        "0.392      7325.294\n",
        "0.784      7338.294\n",
        "1.176      7513.576\n",
        "1.568      7199.396\n",
        "Name: Mean1, dtype: float64"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "transform + rolling baseline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Settings['Sample Rate (s/frame)'] = Data['original'].index[1] - Data['original'].index[0]\n",
      "\n",
      "print Settings['Sample Rate (s/frame)']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.392\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#transform settings\n",
      "Settings = user_input_trans(Settings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Previous Linear Fit setting: True\n",
        "Enter True or False to turn on or off the linear fit.\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Linear Fit (True/False): false\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Previous Bandpass setting: none, none, none\n",
        "Enter the butterworth bandpass settings seperated by a comma. cuts are in hertz and poly should be an interger.\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Bandpass Settings (lowcut, highcut,polynomial): none\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Previous Savitzky-Golay setting: 51, 4\n",
        "Enter the Savitzky Golay filter settings seperated by a comma. Window size must be odd.\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Savitzky Golay Settings (window, polynomial): 61, 4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Settings Saved\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#run transformation\n",
      "Data = transform_wrapper(Data, Settings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot of one ROI from transformation\n",
      "roi = 'Mean1'\n",
      "plt.plot(Data['original'].index, Data['original'][roi], 'b')\n",
      "plt.plot(Data['trans'].index, Data['trans'][roi], 'r')\n",
      "plt.title(roi+' Transformed')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot of random ROI from transformation\n",
      "\n",
      "rand_int = np.random.randint(len(Data['original'].columns))\n",
      "roi = Data['original'].columns[rand_int] \n",
      "plt.plot(Data['original'].index, Data['original'][roi], 'b')\n",
      "plt.plot(Data['trans'].index, Data['trans'][roi], 'r')\n",
      "plt.title(roi+' Transformed')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#removed later\n",
      "def transform_wrapper(Data, Settings):\n",
      "    Data['trans'] = DataFrame(index = Data['original'].index)\n",
      "    for label, column in Data['original'].iteritems():\n",
      "        data_trans = transformation(column, Settings)\n",
      "        Data['trans'][label] = data_trans\n",
      "    return Data\n",
      "def transformation(Data, Settings):\n",
      "    \n",
      "    data_trans = np.array(Data)\n",
      "    \n",
      "    if Settings['Linear Fit'] == True:\n",
      "        data_trans = linear_subtraction(data_trans)\n",
      "        \n",
      "    if Settings['Bandpass Lowcut'] != 'none':\n",
      "        data_trans = butter_bandpass_filter(data_trans, Settings['Bandpass Lowcut'], \n",
      "                                            Settings['Bandpass Highcut'], \n",
      "                                            1/Settings['Sample Rate (s/frame)'], \n",
      "                                            order= Settings['Bandpass Polynomial'])\n",
      "    \n",
      "    if Settings['Absolute Value'] == True:\n",
      "        data_trans = abs(data_trans)\n",
      "    \n",
      "    if Settings['Savitzky-Golay Window Size'] != 'none':\n",
      "        data_trans =savitzky_golay(data_trans, Settings['Savitzky-Golay Window Size'], \n",
      "                                   Settings['Savitzky-Golay Polynomial'])\n",
      "    \n",
      "    #baseline and thresholding is moved to its own call threshold()\n",
      "    #base, data_shift =baseline(data_trans,settings['Sample Rate (s/frame)']) \n",
      "    #settings['Baseline'] = base\n",
      "    \n",
      "    #data_trans = Series(data = data_trans, index = Data['original'].index)\n",
      "    #Data['trans'] = data_trans\n",
      "    #graph_trans(Data)\n",
      "    return data_trans"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#settings for baseline\n",
      "Settings = user_input_base(Settings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Previous Baseline Type: rolling\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Enter Linear or Rolling: rolling\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Previous Rolling Baseline Window: 25000.0\n",
        "Enter the window size of the rolling baseline in milliseconds.\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Window size in ms: 35000\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def baseline_wrapper(Data, Settings, Results):\n",
      "    \n",
      "    if Settings['Baseline Type'] == 'linear':\n",
      "        Data['shift'] = DataFrame(index = Data['trans'].index)\n",
      "        baseline = {}\n",
      "        \n",
      "        for label, column in Data['trans'].iteritems():\n",
      "            index = 5/Settings['Sample Rate (s/frame)'] #find the index of the first 5 seconds of data\n",
      "            baserate = np.mean(column[:index]) #average all points to obtain baserate\n",
      "            baseline[label] = abs(baserate)\n",
      "            datashift = []\n",
      "\n",
      "            #may be able to use np.subtract(data,base) instead, but this seems to work correctly.\n",
      "            for x in column:\n",
      "                foo = (x-baserate)\n",
      "                datashift.append(foo)\n",
      "            Data['shift'][label] = datashift\n",
      "        Results['Baseline'] = baseline\n",
      "        return Data, Settings, Results\n",
      "    \n",
      "    elif Settings['Baseline Type'] == 'rolling':\n",
      "        Data['rolling'] = DataFrame()\n",
      "        Results['Baseline-Rolling'] = DataFrame()\n",
      "        window = int((Settings['Rolling Baseline Window']/1000.0)/Settings['Sample Rate (s/frame)'])\n",
      "        if window %2 !=0:\n",
      "            window = window+1\n",
      "        for label, column in Data['trans'].iteritems():\n",
      "            rolling_mean, data_roll, time_roll = baseline_rolling(Data['trans'].index, \n",
      "                                                              np.array(column), \n",
      "                                                              window)\n",
      "            Data['rolling'][label] = data_roll\n",
      "            Results['Baseline-Rolling'][label] = rolling_mean\n",
      "        \n",
      "        Data['rolling'].index = time_roll\n",
      "        Results['Baseline-Rolling'].index = time_roll\n",
      "        return Data, Settings, Results    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Data, Settings, Results = baseline_wrapper(Data, Settings, Results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Data['shift'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Mean1</th>\n",
        "      <th>Mean2</th>\n",
        "      <th>Mean3</th>\n",
        "      <th>Mean4</th>\n",
        "      <th>Mean5</th>\n",
        "      <th>Mean6</th>\n",
        "      <th>Mean7</th>\n",
        "      <th>Mean8</th>\n",
        "      <th>Mean9</th>\n",
        "      <th>Mean10</th>\n",
        "      <th>Mean11</th>\n",
        "      <th>Mean12</th>\n",
        "      <th>Mean13</th>\n",
        "      <th>Mean14</th>\n",
        "      <th>Mean15</th>\n",
        "      <th>Mean16</th>\n",
        "      <th>Mean17</th>\n",
        "      <th>Mean18</th>\n",
        "      <th>Mean19</th>\n",
        "      <th>Mean20</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>time(s)</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0.000</th>\n",
        "      <td>-115.884151</td>\n",
        "      <td>-116.413135</td>\n",
        "      <td>-248.510931</td>\n",
        "      <td>-167.128080</td>\n",
        "      <td>-35.641187</td>\n",
        "      <td>-873.676064</td>\n",
        "      <td>-309.511700</td>\n",
        "      <td>-703.100310</td>\n",
        "      <td> 28.681254</td>\n",
        "      <td>-113.695131</td>\n",
        "      <td>-978.361913</td>\n",
        "      <td>-22.727756</td>\n",
        "      <td>-59.822012</td>\n",
        "      <td>-291.999856</td>\n",
        "      <td>-66.710546</td>\n",
        "      <td>-46.193604</td>\n",
        "      <td>-258.927293</td>\n",
        "      <td>-86.257738</td>\n",
        "      <td>-23.881819</td>\n",
        "      <td>-80.946212</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>0.392</th>\n",
        "      <td> -95.261776</td>\n",
        "      <td> -81.917484</td>\n",
        "      <td>-160.710578</td>\n",
        "      <td>-116.458861</td>\n",
        "      <td>-30.099577</td>\n",
        "      <td>-765.541213</td>\n",
        "      <td>-264.064983</td>\n",
        "      <td>-728.738044</td>\n",
        "      <td> 25.964611</td>\n",
        "      <td> -98.466303</td>\n",
        "      <td>-945.859415</td>\n",
        "      <td>-38.061143</td>\n",
        "      <td>-52.246118</td>\n",
        "      <td>-302.994378</td>\n",
        "      <td>-53.880631</td>\n",
        "      <td>-34.718087</td>\n",
        "      <td>-206.717872</td>\n",
        "      <td>-74.427167</td>\n",
        "      <td>  1.339361</td>\n",
        "      <td>-83.979123</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>0.784</th>\n",
        "      <td> -82.047114</td>\n",
        "      <td> -65.956917</td>\n",
        "      <td> -78.460833</td>\n",
        "      <td> -76.287846</td>\n",
        "      <td>-32.584755</td>\n",
        "      <td>-650.604961</td>\n",
        "      <td>-208.041505</td>\n",
        "      <td>-752.445369</td>\n",
        "      <td> 11.598103</td>\n",
        "      <td>-101.238705</td>\n",
        "      <td>-904.260767</td>\n",
        "      <td>-48.662986</td>\n",
        "      <td>-49.304544</td>\n",
        "      <td>-301.711462</td>\n",
        "      <td>-31.855439</td>\n",
        "      <td>-19.028699</td>\n",
        "      <td>-164.537458</td>\n",
        "      <td>-63.430806</td>\n",
        "      <td> 28.833843</td>\n",
        "      <td>-79.777259</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1.176</th>\n",
        "      <td> -63.080049</td>\n",
        "      <td> -42.641262</td>\n",
        "      <td>   0.905928</td>\n",
        "      <td> -25.479932</td>\n",
        "      <td>-24.446321</td>\n",
        "      <td>-564.942970</td>\n",
        "      <td>-149.561521</td>\n",
        "      <td>-768.145990</td>\n",
        "      <td>  2.331646</td>\n",
        "      <td> -72.809041</td>\n",
        "      <td>-856.479136</td>\n",
        "      <td>-39.778433</td>\n",
        "      <td>-42.834675</td>\n",
        "      <td>-305.717758</td>\n",
        "      <td> -9.221557</td>\n",
        "      <td>-14.327804</td>\n",
        "      <td>-119.314171</td>\n",
        "      <td>-52.766930</td>\n",
        "      <td> 24.441564</td>\n",
        "      <td>-68.919945</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1.568</th>\n",
        "      <td> -52.054639</td>\n",
        "      <td>  -7.546478</td>\n",
        "      <td>  74.840870</td>\n",
        "      <td>  24.185097</td>\n",
        "      <td>-29.714786</td>\n",
        "      <td>-464.915287</td>\n",
        "      <td>-106.362699</td>\n",
        "      <td>-763.478078</td>\n",
        "      <td> 14.307908</td>\n",
        "      <td> -68.926137</td>\n",
        "      <td>-811.849868</td>\n",
        "      <td>-19.793742</td>\n",
        "      <td>-34.508121</td>\n",
        "      <td>-299.654268</td>\n",
        "      <td>  5.897829</td>\n",
        "      <td> -1.920955</td>\n",
        "      <td> -58.617491</td>\n",
        "      <td>-43.054575</td>\n",
        "      <td> 33.355441</td>\n",
        "      <td>-52.664126</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 59 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "              Mean1       Mean2       Mean3       Mean4      Mean5  \\\n",
        "time(s)                                                              \n",
        "0.000   -115.884151 -116.413135 -248.510931 -167.128080 -35.641187   \n",
        "0.392    -95.261776  -81.917484 -160.710578 -116.458861 -30.099577   \n",
        "0.784    -82.047114  -65.956917  -78.460833  -76.287846 -32.584755   \n",
        "1.176    -63.080049  -42.641262    0.905928  -25.479932 -24.446321   \n",
        "1.568    -52.054639   -7.546478   74.840870   24.185097 -29.714786   \n",
        "\n",
        "              Mean6       Mean7       Mean8      Mean9      Mean10  \\\n",
        "time(s)                                                              \n",
        "0.000   -873.676064 -309.511700 -703.100310  28.681254 -113.695131   \n",
        "0.392   -765.541213 -264.064983 -728.738044  25.964611  -98.466303   \n",
        "0.784   -650.604961 -208.041505 -752.445369  11.598103 -101.238705   \n",
        "1.176   -564.942970 -149.561521 -768.145990   2.331646  -72.809041   \n",
        "1.568   -464.915287 -106.362699 -763.478078  14.307908  -68.926137   \n",
        "\n",
        "             Mean11     Mean12     Mean13      Mean14     Mean15     Mean16  \\\n",
        "time(s)                                                                       \n",
        "0.000   -978.361913 -22.727756 -59.822012 -291.999856 -66.710546 -46.193604   \n",
        "0.392   -945.859415 -38.061143 -52.246118 -302.994378 -53.880631 -34.718087   \n",
        "0.784   -904.260767 -48.662986 -49.304544 -301.711462 -31.855439 -19.028699   \n",
        "1.176   -856.479136 -39.778433 -42.834675 -305.717758  -9.221557 -14.327804   \n",
        "1.568   -811.849868 -19.793742 -34.508121 -299.654268   5.897829  -1.920955   \n",
        "\n",
        "             Mean17     Mean18     Mean19     Mean20      \n",
        "time(s)                                                   \n",
        "0.000   -258.927293 -86.257738 -23.881819 -80.946212 ...  \n",
        "0.392   -206.717872 -74.427167   1.339361 -83.979123 ...  \n",
        "0.784   -164.537458 -63.430806  28.833843 -79.777259 ...  \n",
        "1.176   -119.314171 -52.766930  24.441564 -68.919945 ...  \n",
        "1.568    -58.617491 -43.054575  33.355441 -52.664126 ...  \n",
        "\n",
        "[5 rows x 59 columns]"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot of random ROI from baseline rolling\n",
      "\n",
      "rand_int = np.random.randint(len(Data['original'].columns))\n",
      "roi = Data['original'].columns[rand_int] \n",
      "plt.plot(Data['original'].index, Data['original'][roi], marker = '.', color = 'k')\n",
      "#plt.plot(Data['trans'].index, Data['trans'][roi], 'r')\n",
      "plt.plot(Data['rolling'].index, Data['rolling'][roi], marker = '.',color = 'g')\n",
      "plt.plot(Results['Baseline-Rolling'].index, Results['Baseline-Rolling'][roi],marker = '.', color = 'b')\n",
      "plt.title(roi+' Transformed')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quickplot of random ROI from baseline linear\n",
      "rand_int = np.random.randint(len(Data['original'].columns))\n",
      "roi = Data['original'].columns[rand_int] \n",
      "plt.plot(Data['original'].index, Data['original'][roi], 'k')\n",
      "plt.plot(Data['trans'].index, Data['trans'][roi], 'r')\n",
      "plt.plot(Data['shift'].index, Data['shift'][roi], 'g')\n",
      "plt.hlines(0, Data['shift'].index[0], Data['shift'].index[-1], 'b')\n",
      "plt.title(roi+' Transformed')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "peak det"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max(Data['trans'].max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "21427.15762669202"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def event_peakdet_settings(Settings):\n",
      "    if 'Delta' in Settings.keys():\n",
      "        print \"Previous delta value: %s\" %Settings['Delta']\n",
      "    delta = raw_input(\"Enter delta value between 0 and %s: \" %round(max(Data['trans'].max()),4))\n",
      "    delta = float(delta)\n",
      "    Settings['Delta'] = delta\n",
      "    return Settings\n",
      "\n",
      "def event_peakdet(Data, Settings, Results, roi):\n",
      "    \n",
      "    if Settings['Baseline Type'] == 'linear':\n",
      "        maxtab, mintab = peakdet(np.array(Data), Settings['Delta'], None)\n",
      "        \n",
      "        if maxtab.size == 0:\n",
      "            maxptime = []\n",
      "            maxpeaks = []\n",
      "        else:\n",
      "            maxtab = np.array(maxtab)\n",
      "            maxptime = maxtab[:,0] #all of the rows and only the first column are time\n",
      "            maxptime_true = (np.multiply(maxptime, Settings['Sample Rate (s/frame)'])\n",
      "                             + Data.index[0]) #get the real time for each peak\n",
      "            maxpeaks = maxtab[:,1]\n",
      "            maxpeaks = (np.subtract(maxpeaks,Results['Baseline'][roi]))\n",
      "            \n",
      "        if mintab.size == 0:\n",
      "            valleytime =[]\n",
      "            valleys = []\n",
      "        else:\n",
      "            mintab = np.array(mintab)\n",
      "            valleytime = mintab[:,0]\n",
      "            valleytime = (np.multiply(valleytime, Settings['Sample Rate (s/frame)'])\n",
      "                             + Data.index[0]) #get the real time for each peak\n",
      "            valleys = mintab[:,1]\n",
      "            valleys = (np.subtract(valleys,Results['Baseline'][roi]))\n",
      "\n",
      "    elif Settings['Baseline Type'] == 'rolling':\n",
      "        \n",
      "        maxtab, mintab = peakdet(np.array(Data), Settings['Delta'], None)\n",
      "        if maxtab.size == 0:\n",
      "            maxptime = []\n",
      "            maxpeaks = []\n",
      "        else:\n",
      "            maxtab = np.array(maxtab)\n",
      "            maxptime = maxtab[:,0] #all of the rows and only the first column are time\n",
      "            maxptime_true = (np.multiply(maxptime, Settings['Sample Rate (s/frame)'])\n",
      "                             + Data.index[0]) #get the real time for each peak\n",
      "            maxpeaks = maxtab[:,1]\n",
      "        if mintab.size == 0:\n",
      "            valleytime =[]\n",
      "            valleys = []\n",
      "        else:\n",
      "\n",
      "            mintab = np.array(mintab)\n",
      "            valleytime = mintab[:,0]\n",
      "            valleytime = (np.multiply(valleytime, Settings['Sample Rate (s/frame)'])\n",
      "                             + Data.index[0]) #get the real time for each peak\n",
      "            valleys = mintab[:,1]\n",
      "\n",
      "    RR = rrinterval(maxptime_true)\n",
      "    RR.append(NaN)\n",
      "    results_peaks = DataFrame({'Peaks Amplitude':maxpeaks}, index=maxptime_true)\n",
      "    results_peaks['Intervals'] = RR\n",
      "    #Results['Peaks'] = results_peaks\n",
      "    \n",
      "    peak_sum = results_peaks['Peaks Amplitude'].describe()\n",
      "    #peak_plot(Data, Settings, Results)\n",
      "    \n",
      "    results_valleys = DataFrame({'Valley Amplitude':valleys}, index = valleytime)\n",
      "    return results_peaks, peak_sum, results_valleys\n",
      "\n",
      "def event_peakdet_wrapper(Data, Settings, Results):\n",
      "    '''\n",
      "    The wrapper than handles applying peak detection on an entire dataframe\n",
      "    '''\n",
      "    \n",
      "    peaks_dict = {}\n",
      "    peaks_sum = DataFrame()\n",
      "    valleys_dict = {}\n",
      "    \n",
      "    if Settings['Baseline Type'] == 'linear':\n",
      "        data_temp = Data['trans']\n",
      "    elif Settings['Baseline Type'] == 'rolling':\n",
      "        data_temp = Data['rolling']\n",
      "    \n",
      "    for label, col in data_temp.iteritems():\n",
      "        results_peaks, peak_sum, results_valleys = event_peakdet(col, Settings, Results, label)\n",
      "        peaks_dict[label] = results_peaks\n",
      "        valleys_dict[label] = results_valleys\n",
      "        peaks_sum[label] = peak_sum\n",
      "    Results['Peaks'] = peaks_dict\n",
      "    Results['Valleys'] = valleys_dict\n",
      "    Results['Peaks Summary'] = peaks_sum\n",
      "    \n",
      "    return Results\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Settings = event_peakdet_settings(Settings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Previous delta value: 300.0\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Enter delta value between 0 and 21427.1576: 1000\n"
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Results = event_peakdet_wrapper(Data, Settings, Results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot of random ROI from baseline rolling\n",
      "\n",
      "rand_int = np.random.randint(len(Data['original'].columns))\n",
      "roi = Data['original'].columns[rand_int] \n",
      "#plt.plot(Data['original'].index, Data['original'][roi], color = 'k')\n",
      "#plt.plot(Data['trans'].index, Data['trans'][roi], 'r')\n",
      "plt.plot(Data['rolling'].index, Data['rolling'][roi], color = 'k')\n",
      "plt.plot(Results['Baseline-Rolling'].index, Results['Baseline-Rolling'][roi], color = 'b')\n",
      "plt.plot(Results['Peaks'][roi].index, Results['Peaks'][roi]['Peaks Amplitude'], marker = '^', color = 'g', linestyle = 'None')\n",
      "plt.plot(Results['Valleys'][roi].index, Results['Valleys'][roi]['Valley Amplitude'], marker = 'v', color = 'r', linestyle = 'None')\n",
      "\n",
      "plt.title(roi+' Events')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick tri-plot of random ROIs from baseline rolling\n",
      "rand_int = np.random.randint(len(Data['original'].columns))\n",
      "roi0 = Data['original'].columns[rand_int] \n",
      "rand_int = np.random.randint(len(Data['original'].columns))\n",
      "roi1 = Data['original'].columns[rand_int] \n",
      "rand_int = np.random.randint(len(Data['original'].columns))\n",
      "roi2 = Data['original'].columns[rand_int] \n",
      "\n",
      "fig, ax = plt.subplots(3, 1, sharex= True)\n",
      "\n",
      "ax[0].plot(Data['rolling'].index, Data['rolling'][roi0], color = 'k')\n",
      "ax[0].plot(Results['Baseline-Rolling'].index, Results['Baseline-Rolling'][roi0], color = 'b')\n",
      "ax[0].plot(Results['Peaks'][roi0].index, Results['Peaks'][roi0]['Peaks Amplitude'], \n",
      "           marker = '^', color = 'g', linestyle = 'None')\n",
      "ax[0].plot(Results['Valleys'][roi0].index, Results['Valleys'][roi0]['Valley Amplitude'], \n",
      "           marker = 'v', color = 'r', linestyle = 'None')\n",
      "ax[0].set_title(roi0+' Events')\n",
      "\n",
      "ax[1].plot(Data['rolling'].index, Data['rolling'][roi1], color = 'k')\n",
      "ax[1].plot(Results['Baseline-Rolling'].index, Results['Baseline-Rolling'][roi1], color = 'b')\n",
      "ax[1].plot(Results['Peaks'][roi1].index, Results['Peaks'][roi1]['Peaks Amplitude'], \n",
      "           marker = '^', color = 'g', linestyle = 'None')\n",
      "ax[1].plot(Results['Valleys'][roi1].index, Results['Valleys'][roi1]['Valley Amplitude'], \n",
      "           marker = 'v', color = 'r', linestyle = 'None')\n",
      "ax[1].set_title(roi1+' Events')\n",
      "\n",
      "ax[2].plot(Data['rolling'].index, Data['rolling'][roi2], color = 'k')\n",
      "ax[2].plot(Results['Baseline-Rolling'].index, Results['Baseline-Rolling'][roi2], color = 'b')\n",
      "ax[2].plot(Results['Peaks'][roi2].index, Results['Peaks'][roi2]['Peaks Amplitude'], \n",
      "           marker = '^', color = 'g', linestyle = 'None')\n",
      "ax[2].plot(Results['Valleys'][roi2].index, Results['Valleys'][roi2]['Valley Amplitude'], \n",
      "           marker = 'v', color = 'r', linestyle = 'None')\n",
      "ax[2].set_title(roi2+' Events')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "roi1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 202,
       "text": [
        "'Mean5'"
       ]
      }
     ],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot of ROI from baseline rolling\n",
      "\n",
      "roi = 'Mean1'\n",
      "#plt.plot(Data['original'].index, Data['original'][roi], color = 'k')\n",
      "#plt.plot(Data['trans'].index, Data['trans'][roi], 'r')\n",
      "plt.plot(Data['rolling'].index, Data['rolling'][roi], color = 'k')\n",
      "plt.plot(Results['Baseline-Rolling'].index, Results['Baseline-Rolling'][roi], color = 'b')\n",
      "plt.plot(Results['Peaks'][roi].index, Results['Peaks'][roi]['Peaks Amplitude'], marker = '^', color = 'g', linestyle = 'None')\n",
      "plt.plot(Results['Valleys'][roi].index, Results['Valleys'][roi]['Valley Amplitude'], marker = 'v', color = 'r', linestyle = 'None')\n",
      "\n",
      "plt.title(roi+' Events')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick results summary\n",
      "#average results across rows\n",
      "Results['Peaks Summary'].mean(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 200,
       "text": [
        "count        4.762712\n",
        "mean      8599.612889\n",
        "std       2079.458722\n",
        "min       6816.355156\n",
        "25%       7561.885692\n",
        "50%       8289.443260\n",
        "75%       9485.793599\n",
        "max      10898.005151\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Results['Valleys']['Mean1']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Valley Amplitude</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>45.472 </th>\n",
        "      <td>  7438.751894</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>88.592 </th>\n",
        "      <td>  6443.575462</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>110.152</th>\n",
        "      <td> 12610.629067</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>169.344</th>\n",
        "      <td>  6393.173200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>251.272</th>\n",
        "      <td>  6498.261620</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>277.536</th>\n",
        "      <td>  7144.533623</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>304.584</th>\n",
        "      <td>  6124.624149</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>343.000</th>\n",
        "      <td>  6398.596285</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>397.880</th>\n",
        "      <td>  6255.230926</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>426.104</th>\n",
        "      <td>  6203.625538</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>487.256</th>\n",
        "      <td>  5989.856968</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>813.792</th>\n",
        "      <td>  4910.448468</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>12 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 177,
       "text": [
        "         Valley Amplitude\n",
        "45.472        7438.751894\n",
        "88.592        6443.575462\n",
        "110.152      12610.629067\n",
        "169.344       6393.173200\n",
        "251.272       6498.261620\n",
        "277.536       7144.533623\n",
        "304.584       6124.624149\n",
        "343.000       6398.596285\n",
        "397.880       6255.230926\n",
        "426.104       6203.625538\n",
        "487.256       5989.856968\n",
        "813.792       4910.448468\n",
        "\n",
        "[12 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(Data['rolling'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 162,
       "text": [
        "pandas.core.frame.DataFrame"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(Results['Baseline-Rolling'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "pandas.core.frame.DataFrame"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Data.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 153,
       "text": [
        "['rolling', 'shift', 'trans', 'original']"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "burst"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "if (x,y) avai, then xcor and friends/neighbors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "all line plots"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}