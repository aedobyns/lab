{
 "metadata": {
  "name": "",
  "signature": "sha256:b350ac34783eb86d942f5f588d862b5caf72f7a5356f9c3366f74150c42ceaf8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Support code below"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "from scipy import spatial, signal, fft, arange\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from pandas import Series, DataFrame\n",
      "import time as t\n",
      "from PIL import Image\n",
      "import sys\n",
      "import os, errno\n",
      "import matplotlib.patches as patches\n",
      "from pandas.tools.plotting import autocorrelation_plot\n",
      "from pyeeg import * \n",
      "from numpy import NaN, Inf, arange, isscalar, asarray, array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "File_path = \" \"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_files(folder):\n",
      "    '''\n",
      "    this function takes a path to where all of the LC_pro saved files are. There should be 3 files:\n",
      "    'ROI normailed.text' - the ROI intensity time series data. Units should be in time (not frame) and relative intensity\n",
      "    'Parameter List_edit.txt' - this is the events' information file. Duplicate ROIs are expected (since an ROI can have multipule events). The orignal LC_pro file can be loaded, as long as the name is changed to match. \n",
      "    'rbg.png' - A still of the video, must be .png. If it is a .tif, it will load, but it will be pseudo colored. it can be just a frame or some averaged measures.\n",
      "    \n",
      "    if the files are not named properly or the path is wrong, it will throw a file not found error.\n",
      "    '''\n",
      "    data = pd.read_csv(r'%s/ROI normalized.txt' %(folder), index_col= 'time(s)', sep='\\t') #load the intensity time series for each roi. should be a text file named exactly 'ROI normalized.txt'\n",
      "    print \"Loaded 'ROI normalized.txt'\"\n",
      "    \n",
      "    roi_param = pd.read_csv(r'%s/Parameter List_edit.txt' %(folder), index_col='ROI', sep='\\t')#load the parameter list.\n",
      "    print \"Loaded 'Parameter List_edit.txt'\"\n",
      "    \n",
      "    im = Image.open(r'%s/rbg.png' %(folder)) #MUST BE RBG and .png. seriously, I'm not kidding.\n",
      "    print \"Loaded 'rbg.png'\"\n",
      "    \n",
      "    del data['Unnamed: 0'] #lc_pro outputs a weird blank column named this everytime. I don't know why, but it does. this line deletes it safely.\n",
      "    roi_loc, roi_x, roi_y, data = lcpro_param_parse(roi_param, data , original=True) #use the parameter list to get the x and y location for each ROI\n",
      "    print \"Configured Data\"\n",
      "    \n",
      "    events_x, events_y = get_events(data = data, roi_param = roi_param) #use the parameter list to get the location and amplitude of each event for every ROI\n",
      "    print \"LCPro events extracted\"\n",
      "    \n",
      "    path = folder +\"/plots\"\n",
      "    mkdir_p(path) #makes a plots folder inside the path where the data was loaded from\n",
      "    print \"Made plots folder\"\n",
      "    \n",
      "    return data, roi_param, im, roi_loc, roi_x, roi_y, events_x, events_y\n",
      "    \n",
      "def lcpro_param_parse(roi_param, data , original = True):\n",
      "    '''\n",
      "    This function takes the Dataframe created by opening the 'Parameter List.txt' from LC_Pro.\n",
      "    It returns the location data as both a concise list datafram of only locations (roi_loc), an x and y list (roi_x, roi_y). \n",
      "    It also changes the names in the roi_loc file to be the same as they are in the data dataframe, which is \n",
      "    '''\n",
      "    roi_loc = roi_param[['X', 'Y']] #make a new dataframe that contains only the x and y coordinates\n",
      "    roi_loc.drop_duplicates(inplace= True) #roi_param has duplicate keys (rois) because the parameters are based on events, which lc_pro detects. a single roi can have many events. doing it in place like this does cause an error, but don't let it both you none.\n",
      "    roi_x = roi_loc['X'].tolist() #extract the x column as an array and store it as a value. this is handy for later calculations\n",
      "    roi_y = roi_loc['Y'].tolist() #extract the y column as an array and store it as a value. this is handy for later calculations\n",
      "    new_index = [] #make an empty temp list\n",
      "    for i in np.arange(len(roi_loc.index)): #for each index in roi_loc\n",
      "        new_index.append('Roi'+str(roi_loc.index[i])) #make a string from the index name in the same format as the data\n",
      "    roi_loc = DataFrame({'x':roi_x, 'y':roi_y}, index= new_index) #reassign roi_loc to a dataframe with the properly named index. this means that we can use the same roi name to call from either the data or location dataframes\n",
      "    \n",
      "    if len(data.columns) != len(new_index) and original == True: #if the number of roi's are the same AND we are using the original file (no roi's have been romved from the edited roi_param)\n",
      "        sys.exit(\"The number of ROIs in the data file is not equal to the number of ROIs in the parameter file. That doesn't seem right, so I quit the function for you. Make sure you are loading the correct files, please.\")\n",
      "    \n",
      "    if original == False: #if it is not the original, then use the roi_loc index to filter only edited roi's.\n",
      "        data = data[roi_loc.index]\n",
      "    \n",
      "    truth = (data.columns == roi_loc.index).tolist() #a list of the bool for if the roi indexes are all the same.\n",
      "    \n",
      "    if truth.count(True) != len(data.columns): #all should be true, so check that the number of true are the same.\n",
      "        sys.exit(\"The names on data and roi_loc are not identical. This will surely break everything later, so I shut down the program. Try loading these files again.\")\n",
      "    \n",
      "    return roi_loc, roi_x, roi_y, data\n",
      "\n",
      "def get_events(data, roi_param):\n",
      "    '''\n",
      "    extract the events from the roi_parameter list. It returns them as a pair of dictionaries (x or y data, sored as floats in a list) that use the roi name as the key. \n",
      "    duplicate events are ok and expected.\n",
      "    '''\n",
      "    \n",
      "    new_index = [] #create a new, empty list\n",
      "    \n",
      "    for i in np.arange(len(roi_param.index)): #for each index in the original roi_param list, will include duplicates\n",
      "        new_index.append('Roi'+str(roi_param.index[i])) #reformat name and append it to the empty index list\n",
      "    roi_events = DataFrame(index= new_index) #make an empty data frame using the new_index as the index\n",
      "    roi_events_time = roi_param['Time(s)'].tolist() #convert time (which is the x val) to a list\n",
      "    roi_events_amp = roi_param['Amp(F/F0)'].tolist() #conver amplitude (which is the y val) to a list\n",
      "    roi_events['Time'] = roi_events_time #store it in the events dataframe\n",
      "    roi_events['Amp'] = roi_events_amp #store is in the events dataframe\n",
      "    \n",
      "    events_x = {} #empty dict\n",
      "    events_y = {} #empty dict\n",
      "    \n",
      "    for label in data.columns: #for each roi name in data, initalize the dict by making an empty list for each roi (key) \n",
      "        events_x[label] = []\n",
      "        events_y[label] = []\n",
      "\n",
      "    for i in np.arange(len(roi_events.index)): #for each event\n",
      "        key = roi_events.index[i] #get the roi name\n",
      "        events_x[key].append(roi_events.iloc[i,0]) #use the name to add the event's time data point to the dict\n",
      "        events_y[key].append(roi_events.iloc[i,1]) #use the name to add the event's amplitude data point to the dict\n",
      "        \n",
      "    return events_x, events_y #return the two dictionaries\n",
      "\n",
      "def mkdir_p(path):\n",
      "    '''\n",
      "    This function creates a folder at the end of the specified path, unless the folder already exsists. \n",
      "    '''\n",
      "    try:\n",
      "        os.makedirs(path)\n",
      "    except OSError as exc: # Python >2.5\n",
      "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
      "            pass\n",
      "        else: raise"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this is the settings box\n",
      "rate = \n",
      "\n",
      "#True or False\n",
      "linear_subtraction = True \n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load(roi parameters-original)\n",
      "load(roi parameters-select)\n",
      "load(time series-original)\n",
      "load(time series-select) #use data = data[roi_loc.index] to filter the full time series to obtain the select list\n",
      "\n",
      "def delta_tuner(dataframe, epsilon): #choose which data to use to tune. can be either selected list or full ist. AD reccoments full list.\n",
      "    '''\n",
      "    this function takes a dataframe of time series data and runs peak detection iteritvely. \n",
      "    since peak detection always has the the range of delta values of 0 to the max of stack,\n",
      "    epsiolon is used to be the number of divisions of that range to test. 1 being the minimum for epsilon, which is the exact middle of the range.\n",
      "    the function will return a results table (average # of events) and (# ROIs with events>1) on their own axis.\n",
      "    the graph will be click able, as to obtain the delta value that generated that point.\n",
      "    data results are not saved.\n",
      "    '''\n",
      "    \n",
      "    range_array = np.linspace(0, max(dataframe), num = epsilon)\n",
      "    results = DataFrame(index=range_array, col = ['Average events', 'Average # ROIs']) #dataframe with an index for each of the delta values. the columns will be (average # of events) and (# ROIs with events>1)\n",
      "    \n",
      "    for delta in range_array:\n",
      "        \n",
      "        peak_amp_sum = event_detection(data,delta) #perform event detection\n",
      "\n",
      "        event_counts = peak_amp_sum.loc['count']\n",
      "        average_num_events = event_counts.mean()\n",
      "        percent_roi = events_counts[events_counts>0].count()/events_counts.count()\n",
      "\n",
      "        results[delta, 'average events'] = average_num_events\n",
      "        results[delta, 'percentage ROIS'] = percent_roi\n",
      "    return results\n",
      "\n",
      "def delta_tuner_graph(results):\n",
      "    '''\n",
      "    plot results in two tandem graphs\n",
      "    '''\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def all_roi_line_events(data_shift, baseline, peak_sets_x, peak_sets_y, burst_e_sets, burst_s_sets, threshperc, folder):\n",
      "    '''\n",
      "    Use all_roi_line_pdfs to plot each ROI as its own pdf. specify the folder where each plot will be saved.\n",
      "    Each plot is randomly assigned a color. You cannot disable this feature.\n",
      "    you can easily consolidate all of these into a single pdf using adobe or another preview program.\n",
      "    includes overlay of LC_pro events\n",
      "    '''\n",
      "    time = data_shift.index.tolist()\n",
      "    for label,column in data_shift.iteritems():\n",
      "        \n",
      "        threshold = baseline[label] * threshperc #calculate the point at which a event is considered a peak\n",
      "\n",
      "        plt.figure()\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Intensity')\n",
      "        plt.title(label)\n",
      "        plt.ylim(ymin = min(data_shift.min()), ymax = max(data_shift.max()))\n",
      "        plt.xlim(xmin = data_shift.index[0], xmax = data_shift.index[-1])\n",
      "\n",
      "        plt.plot(data_shift.index, data_shift[label], label = 'shift', color = 'k')\n",
      "        plt.hlines((data_shift[label][:14].mean()),time[0],time[-1], label = 'baseline', color = 'b')\n",
      "        plt.hlines((threshold),time[0],time[-1], label = 'threshold', color = 'r')\n",
      "\n",
      "        plt.vlines(x = 600, ymin = min(data_shift.min()), ymax = max(data_shift.max()), color = 'r')\n",
      "        plt.vlines(x= 1200, ymin = min(data_shift.min()), ymax = max(data_shift.max()), color = 'r')\n",
      "\n",
      "        for key in data_sets:\n",
      "            plt.plot(peak_sets_x[key][label], peak_sets_y[key][label] + abs(baseline[label]), marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "            bendy = []\n",
      "            bstarty = []\n",
      "            for point in burst_s_sets[key][label]:\n",
      "                bstarty.append(threshold)\n",
      "            plt.plot(burst_s_sets[key][label], bstarty, marker = \"v\", color=\"y\", linestyle= \"None\")\n",
      "            for point in burst_e_sets[key][label]:\n",
      "                bendy.append(threshold)\n",
      "            plt.plot(burst_e_sets[key][label], bendy, marker = \"v\", color=\"m\", linestyle= \"None\")\n",
      "        plt.savefig(r'%s/plots/%s.pdf' %(folder,label))\n",
      "        plt.close()\n",
      "    print \"done, asshat\"\n",
      "    \n",
      "def get_events(data, roi_param):\n",
      "    '''\n",
      "    extract the events from the roi_parameter list. It returns them as a pair of dictionaries (x or y data, sored as floats in a list) that use the roi name as the key. \n",
      "    duplicate events are ok and expected.\n",
      "    '''\n",
      "    \n",
      "    new_index = [] #create a new, empty list\n",
      "    \n",
      "    for i in np.arange(len(roi_param.index)): #for each index in the original roi_param list, will include duplicates\n",
      "        new_index.append('Roi'+str(roi_param.index[i])) #reformat name and append it to the empty index list\n",
      "    roi_events = DataFrame(index= new_index) #make an empty data frame using the new_index as the index\n",
      "    roi_events_time = roi_param['Time(s)'].tolist() #convert time (which is the x val) to a list\n",
      "    roi_events_amp = roi_param['Amp(F/F0)'].tolist() #conver amplitude (which is the y val) to a list\n",
      "    roi_events['Time'] = roi_events_time #store it in the events dataframe\n",
      "    roi_events['Amp'] = roi_events_amp #store is in the events dataframe\n",
      "    \n",
      "    events_x = {} #empty dict\n",
      "    events_y = {} #empty dict\n",
      "    \n",
      "    for label in data.columns: #for each roi name in data, initalize the dict by making an empty list for each roi (key) \n",
      "        events_x[label] = []\n",
      "        events_y[label] = []\n",
      "\n",
      "    for i in np.arange(len(roi_events.index)): #for each event\n",
      "        key = roi_events.index[i] #get the roi name\n",
      "        events_x[key].append(roi_events.iloc[i,0]) #use the name to add the event's time data point to the dict\n",
      "        events_y[key].append(roi_events.iloc[i,1]) #use the name to add the event's amplitude data point to the dict\n",
      "        \n",
      "    return events_x, events_y #return the two dictionaries\n",
      "\n",
      "def all_roi_line_pdfs(dataframe, num_rois, ymin, ymax, events_x, events_y, folder):\n",
      "    '''\n",
      "    Use all_roi_line_pdfs to plot each ROI as its own pdf. specify the folder where each plot will be saved.\n",
      "    Each plot is randomly assigned a color. You cannot disable this feature.\n",
      "    you can easily consolidate all of these into a single pdf using adobe or another preview program.\n",
      "    includes overlay of LC_pro events\n",
      "    '''\n",
      "    \n",
      "    for r in np.arange(num_rois):\n",
      "        \n",
      "        plt.figure()\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Intensity')\n",
      "        plt.title(dataframe.columns[r])\n",
      "        plt.ylim(ymin = ymin, ymax = ymax)\n",
      "        plt.xlim(xmin= dataframe.index[0], xmax = dataframe.index[-1])\n",
      "        plt.plot(dataframe.index, dataframe.ix[:,r], color = [np.random.random(), np.random.random(), np.random.random()])\n",
      "        plt.plot(events_x[dataframe.columns[r]], events_y[dataframe.columns[r]],  marker = \"^\", color=\"y\", linestyle= \"None\")\n",
      "        \n",
      "        plt.savefig(r'%s/plots/%s.pdf' %(folder,dataframe.columns[r]))\n",
      "        plt.close()\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}