{
 "metadata": {
  "name": "",
  "signature": "sha256:9700b6b3400994a0f416b3d44278a1edd4f457f6c578f186889f1d66d58fc562"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Support code below"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "from scipy import spatial, signal, fft, arange\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from pandas import Series, DataFrame\n",
      "import time as t\n",
      "from PIL import Image\n",
      "import sys\n",
      "import os, errno\n",
      "import matplotlib.patches as patches\n",
      "from pandas.tools.plotting import autocorrelation_plot\n",
      "from pyeeg import * \n",
      "from numpy import NaN, Inf, arange, isscalar, asarray, array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "File_path = \"/Users/abigaildobyns/Desktop/SW lcpro vs rain/c-d-r-081312_pul_AH_Ctrl_2012_08_13__12_37_50\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_files(folder):\n",
      "    '''\n",
      "    this function takes a path to where all of the LC_pro saved files are. There should be 3 files:\n",
      "    'ROI normailed.text' - the ROI intensity time series data. Units should be in time (not frame) and relative intensity\n",
      "    'Parameter List_edit.txt' - this is the events' information file. Duplicate ROIs are expected (since an ROI can have multipule events). The orignal LC_pro file can be loaded, as long as the name is changed to match. \n",
      "    'rbg.png' - A still of the video, must be .png. If it is a .tif, it will load, but it will be pseudo colored. it can be just a frame or some averaged measures.\n",
      "    \n",
      "    if the files are not named properly or the path is wrong, it will throw a file not found error.\n",
      "    '''\n",
      "    data = pd.read_csv(r'%s/ROI normalized.txt' %(folder), index_col= 'time(s)', sep='\\t') #load the intensity time series for each roi. should be a text file named exactly 'ROI normalized.txt'\n",
      "    print \"Loaded 'ROI normalized.txt'\"\n",
      "    \n",
      "    roi_param_edit = pd.read_csv(r'%s/Parameter List_edit.txt' %(folder), index_col='ROI', sep='\\t')#load the parameter list.\n",
      "    print \"Loaded 'Parameter List_edit.txt'\"\n",
      "\n",
      "    roi_param_original = pd.read_csv(r'%s/Parameter List.txt' %(folder), index_col='ROI', sep='\\t')#load the full parameter list.\n",
      "    print \"Loaded 'Parameter List_edit.txt'\"\n",
      "    \n",
      "    im = Image.open(r'%s/rgb.png' %(folder)) #MUST BE RBG and .png. seriously, I'm not kidding.\n",
      "    print \"Loaded 'rgb.png'\"\n",
      "    \n",
      "    del data['Unnamed: 0'] #lc_pro outputs a weird blank column named this everytime. I don't know why, but it does. this line deletes it safely.\n",
      "    roi_loc_lcpro, roi_x_lcpro, roi_y_lcpro, data_edit = lcpro_param_parse(roi_param_edit, data , original=False) #use the parameter list to get the x and y location for each ROI\n",
      "\n",
      "    roi_loc_orignal, roi_x_orignal, roi_y_orignal, data_orignal  = lcpro_param_parse(roi_param_original, data , original=True) #use the parameter list to get the x and y location for each ROI\n",
      "    \n",
      "    print \"Configured Data\"\n",
      "    \n",
      "    events_x, events_y = get_events(data = data_orignal, roi_param = roi_param_original) #use the parameter list to get the location and amplitude of each event for every ROI\n",
      "    print \"LCPro events extracted\"\n",
      "    \n",
      "    path = folder +\"/plots\"\n",
      "    mkdir_p(path) #makes a plots folder inside the path where the data was loaded from\n",
      "    print \"Made plots folder\"\n",
      "    \n",
      "    return data_orignal, data_edit, roi_param_original, roi_param_edit, im, roi_loc_lcpro, roi_x_lcpro, roi_y_lcpro , roi_loc_orignal, roi_x_orignal, roi_y_orignal, events_x, events_y\n",
      "    \n",
      "def lcpro_param_parse(roi_param, data , original = True):\n",
      "    '''\n",
      "    This function takes the Dataframe created by opening the 'Parameter List.txt' from LC_Pro.\n",
      "    It returns the location data as both a concise list datafram of only locations (roi_loc), an x and y list (roi_x, roi_y). \n",
      "    It also changes the names in the roi_loc file to be the same as they are in the data dataframe, which is \n",
      "    '''\n",
      "    roi_loc = roi_param[['X', 'Y']] #make a new dataframe that contains only the x and y coordinates\n",
      "    roi_loc.drop_duplicates(inplace= True) #roi_param has duplicate keys (rois) because the parameters are based on events, which lc_pro detects. a single roi can have many events. doing it in place like this does cause an error, but don't let it both you none.\n",
      "    roi_x = roi_loc['X'].tolist() #extract the x column as an array and store it as a value. this is handy for later calculations\n",
      "    roi_y = roi_loc['Y'].tolist() #extract the y column as an array and store it as a value. this is handy for later calculations\n",
      "    new_index = [] #make an empty temp list\n",
      "    for i in np.arange(len(roi_loc.index)): #for each index in roi_loc\n",
      "        new_index.append('Roi'+str(roi_loc.index[i])) #make a string from the index name in the same format as the data\n",
      "    roi_loc = DataFrame({'x':roi_x, 'y':roi_y}, index= new_index) #reassign roi_loc to a dataframe with the properly named index. this means that we can use the same roi name to call from either the data or location dataframes\n",
      "    \n",
      "    if len(data.columns) != len(new_index) and original == True: #if the number of roi's are the same AND we are using the original file (no roi's have been romved from the edited roi_param)\n",
      "        sys.exit(\"The number of ROIs in the data file is not equal to the number of ROIs in the parameter file. That doesn't seem right, so I quit the function for you. Make sure you are loading the correct files, please.\")\n",
      "    \n",
      "    if original == False: #if it is not the original, then use the roi_loc index to filter only edited roi's.\n",
      "        data = data[roi_loc.index]\n",
      "    \n",
      "    truth = (data.columns == roi_loc.index).tolist() #a list of the bool for if the roi indexes are all the same.\n",
      "    \n",
      "    if truth.count(True) != len(data.columns): #all should be true, so check that the number of true are the same.\n",
      "        sys.exit(\"The names on data and roi_loc are not identical. This will surely break everything later, so I shut down the program. Try loading these files again.\")\n",
      "    \n",
      "    return roi_loc, roi_x, roi_y, data\n",
      "\n",
      "def get_events(data, roi_param):\n",
      "    '''\n",
      "    extract the events from the roi_parameter list. It returns them as a pair of dictionaries (x or y data, sored as floats in a list) that use the roi name as the key. \n",
      "    duplicate events are ok and expected.\n",
      "    '''\n",
      "    \n",
      "    new_index = [] #create a new, empty list\n",
      "    \n",
      "    for i in np.arange(len(roi_param.index)): #for each index in the original roi_param list, will include duplicates\n",
      "        new_index.append('Roi'+str(roi_param.index[i])) #reformat name and append it to the empty index list\n",
      "    roi_events = DataFrame(index= new_index) #make an empty data frame using the new_index as the index\n",
      "    roi_events_time = roi_param['Time(s)'].tolist() #convert time (which is the x val) to a list\n",
      "    roi_events_amp = roi_param['Amp(F/F0)'].tolist() #conver amplitude (which is the y val) to a list\n",
      "    roi_events['Time'] = roi_events_time #store it in the events dataframe\n",
      "    roi_events['Amp'] = roi_events_amp #store is in the events dataframe\n",
      "    \n",
      "    events_x = {} #empty dict\n",
      "    events_y = {} #empty dict\n",
      "    \n",
      "    for label in data.columns: #for each roi name in data, initalize the dict by making an empty list for each roi (key) \n",
      "        events_x[label] = []\n",
      "        events_y[label] = []\n",
      "\n",
      "    for i in np.arange(len(roi_events.index)): #for each event\n",
      "        key = roi_events.index[i] #get the roi name\n",
      "        events_x[key].append(roi_events.iloc[i,0]) #use the name to add the event's time data point to the dict\n",
      "        events_y[key].append(roi_events.iloc[i,1]) #use the name to add the event's amplitude data point to the dict\n",
      "        \n",
      "    return events_x, events_y #return the two dictionaries\n",
      "\n",
      "def mkdir_p(path):\n",
      "    '''\n",
      "    This function creates a folder at the end of the specified path, unless the folder already exsists. \n",
      "    '''\n",
      "    try:\n",
      "        os.makedirs(path)\n",
      "    except OSError as exc: # Python >2.5\n",
      "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
      "            pass\n",
      "        else: raise"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_orignal, data_edit, roi_param_original, roi_param_edit, im, roi_loc_lcpro, roi_x_lcpro, roi_y_lcpro , roi_loc_orignal, roi_x_orignal, roi_y_orignal, events_x, events_y = load_files(File_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loaded 'ROI normalized.txt'\n",
        "Loaded 'Parameter List_edit.txt'\n",
        "Loaded 'Parameter List_edit.txt'\n",
        "Loaded 'rgb.png'\n",
        "Configured Data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LCPro events extracted"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Made plots folder\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:45: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_orignal.index[1]-data_orignal.index[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "0.78125"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this is the settings box\n",
      "rate = 0.78125\n",
      "\n",
      "#True or False\n",
      "linear_subtraction = True \n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
      "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
      "    The Savitzky-Golay filter removes high frequency noise from data.\n",
      "    It has the advantage of preserving the original shape and\n",
      "    features of the signal better than other types of filtering\n",
      "    approaches, such as moving averages techniques.\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array_like, shape (N,)\n",
      "        the values of the time history of the signal.\n",
      "    window_size : int\n",
      "        the length of the window. Must be an odd integer number.\n",
      "    order : int\n",
      "        the order of the polynomial used in the filtering.\n",
      "        Must be less then `window_size` - 1.\n",
      "    deriv: int\n",
      "        the order of the derivative to compute (default = 0 means only smoothing)\n",
      "    Returns\n",
      "    -------\n",
      "    ys : ndarray, shape (N)\n",
      "        the smoothed signal (or it's n-th derivative).\n",
      "    Notes\n",
      "    -----\n",
      "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
      "    suited for smoothing noisy data. The main idea behind this\n",
      "    approach is to make for each point a least-square fit with a\n",
      "    polynomial of high order over a odd-sized window centered at\n",
      "    the point.\n",
      "    Examples\n",
      "    --------\n",
      "    t = np.linspace(-4, 4, 500)\n",
      "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
      "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.plot(t, y, label='Noisy signal')\n",
      "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
      "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
      "       Data by Simplified Least Squares Procedures. Analytical\n",
      "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
      "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
      "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
      "       Cambridge University Press ISBN-13: 9780521880688\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from math import factorial\n",
      "\n",
      "    try:\n",
      "        window_size = np.abs(np.int(window_size))\n",
      "        order = np.abs(np.int(order))\n",
      "    except ValueError, msg:\n",
      "        raise ValueError(\"window_size and order have to be of type int\")\n",
      "    if window_size % 2 != 1 or window_size < 1:\n",
      "        raise TypeError(\"window_size size must be a positive odd number\")\n",
      "    if window_size < order + 2:\n",
      "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
      "    order_range = range(order+1)\n",
      "    half_window = (window_size -1) // 2\n",
      "    # precompute coefficients\n",
      "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
      "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
      "    # pad the signal at the extremes with\n",
      "    # values taken from the signal itself\n",
      "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
      "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
      "    y = np.concatenate((firstvals, y, lastvals))\n",
      "    return np.convolve( m[::-1], y, mode='valid')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sg_setting = 15\n",
      "data_smooth = DataFrame(index = data_orignal.index)\n",
      "for label, column in data_orignal.iteritems():\n",
      "    temp_list = column.tolist()\n",
      "    temp_list_smooth = savitzky_golay(temp_list, sg_setting, 4)\n",
      "    data_smooth[label] = temp_list_smooth"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_edit.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "Index([u'Roi7', u'Roi9', u'Roi34', u'Roi70', u'Roi71', u'Roi75', u'Roi76', u'Roi77', u'Roi78', u'Roi79', u'Roi80', u'Roi81', u'Roi82', u'Roi85', u'Roi87', u'Roi88', u'Roi89', u'Roi90', u'Roi93', u'Roi95', u'Roi102', u'Roi106', u'Roi116', u'Roi119', u'Roi138', u'Roi139', u'Roi142', u'Roi143', u'Roi150', u'Roi151', u'Roi152', u'Roi154', u'Roi155', u'Roi156', u'Roi158', u'Roi162', u'Roi163', u'Roi165', u'Roi171'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label = 'Roi138'\n",
      "plt.plot(data_edit.index, data_edit[label], label = 'original', color = 'r')\n",
      "plt.plot(data_orignal.index, data_smooth[label], label = 'smooth', color = 'b')\n",
      "plt.plot(events_x[label], events_y[label], marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def delta_tuner(dataframe, epsilon): #choose which data to use to tune. can be either selected list or full ist. AD reccoments full list.\n",
      "    '''\n",
      "    this function takes a dataframe of time series data and runs peak detection iteritvely. \n",
      "    since peak detection always has the the range of delta values of 0 to the max of stack,\n",
      "    epsiolon is used to be the number of divisions of that range to test. 1 being the minimum for epsilon, which is the exact middle of the range.\n",
      "    the function will return a results table (average # of events) and (# ROIs with events>1) on their own axis.\n",
      "    the graph will be click able, as to obtain the delta value that generated that point.\n",
      "    data results are not saved.\n",
      "    '''\n",
      "    \n",
      "    range_array = np.linspace(0, max(dataframe.max())/2, num = epsilon)\n",
      "    results_average = Series(index = range_array)\n",
      "    results_num = Series (index = range_array)\n",
      "    results_perc = Series (index = range_array)\n",
      "    for delta in range_array[1:]:\n",
      "        \n",
      "        peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y = event_detection(dataframe,delta, rate) #perform event detection\n",
      "\n",
      "        event_counts = peak_amp_temp.loc['count']\n",
      "        average_num_events = event_counts.mean()\n",
      "        num_roi = event_counts[event_counts>=1].count()\n",
      "        \n",
      "        perc_roi = num_roi/len(data_smooth.columns)\n",
      "\n",
      "        results_average[delta] = average_num_events\n",
      "        results_num[delta] = num_roi\n",
      "        results_perc[delta]= perc_roi\n",
      "    return results_average, results_num, results_perc\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_average, results_num, results_perc = delta_tuner(data_smooth, 50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_num"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 123,
       "text": [
        "0.000000    NaN\n",
        "0.028831    114\n",
        "0.057662    112\n",
        "0.086493    104\n",
        "0.115324    102\n",
        "0.144155    102\n",
        "0.172986    101\n",
        "0.201817    100\n",
        "0.230648    100\n",
        "0.259479    100\n",
        "0.288310     99\n",
        "0.317141     97\n",
        "0.345972     97\n",
        "0.374803     97\n",
        "0.403634     93\n",
        "0.432465     92\n",
        "0.461296     92\n",
        "0.490127     86\n",
        "0.518958     80\n",
        "0.547788     74\n",
        "0.576619     70\n",
        "0.605450     62\n",
        "0.634281     57\n",
        "0.663112     53\n",
        "0.691943     51\n",
        "0.720774     42\n",
        "0.749605     39\n",
        "0.778436     34\n",
        "0.807267     33\n",
        "0.836098     31\n",
        "0.864929     27\n",
        "0.893760     21\n",
        "0.922591     19\n",
        "0.951422     16\n",
        "0.980253     16\n",
        "1.009084     15\n",
        "1.037915     14\n",
        "1.066746     13\n",
        "1.095577     13\n",
        "1.124408     13\n",
        "1.153239     13\n",
        "1.182070     11\n",
        "1.210901     10\n",
        "1.239732      9\n",
        "1.268563      8\n",
        "1.297394      7\n",
        "1.326225      5\n",
        "1.355056      5\n",
        "1.383887      5\n",
        "1.412718      4\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure, axarr = plt.subplots(2)\n",
      "axarr[0].plot(results_average.index, results_average)\n",
      "axarr[0].set_title('average number of events')\n",
      "\n",
      "axarr[1].plot(results_average.index, results_num)\n",
      "axarr[1].set_title('number of rois')\n",
      "#DataCursor(figure)\n",
      "plt.show(figure)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(roi_loc_lcpro.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "39"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def peakdet(v, delta, x = None):\n",
      "    \"\"\"\n",
      "    Converted from MATLAB script at http://billauer.co.il/peakdet.html\n",
      "    \n",
      "    Returns two arrays\n",
      "    \n",
      "    function [maxtab, mintab]=peakdet(v, delta, x)\n",
      "    %PEAKDET Detect peaks in a vector\n",
      "    %        [MAXTAB, MINTAB] = PEAKDET(V, DELTA) finds the local\n",
      "    %        maxima and minima (\"peaks\") in the vector V.\n",
      "    %        MAXTAB and MINTAB consists of two columns. Column 1\n",
      "    %        contains indices in V, and column 2 the found values.\n",
      "    %      \n",
      "    %        With [MAXTAB, MINTAB] = PEAKDET(V, DELTA, X) the indices\n",
      "    %        in MAXTAB and MINTAB are replaced with the corresponding\n",
      "    %        X-values.\n",
      "    %\n",
      "    %        A point is considered a maximum peak if it has the maximal\n",
      "    %        value, and was preceded (to the left) by a value lower by\n",
      "    %        DELTA.\n",
      "    \n",
      "    % Eli Billauer, 3.4.05 (Explicitly not copyrighted).\n",
      "    % This function is released to the public domain; Any use is allowed.\n",
      "    \n",
      "    \"\"\"\n",
      "    maxtab = []\n",
      "    #mintab = []\n",
      "       \n",
      "    if x is None:\n",
      "        x = arange(len(v))\n",
      "    \n",
      "    v = asarray(v)\n",
      "    \n",
      "    if len(v) != len(x):\n",
      "        sys.exit('Input vectors v and x must have same length')\n",
      "    \n",
      "    if not isscalar(delta):\n",
      "        sys.exit('Input argument delta must be a scalar')\n",
      "    \n",
      "    if delta <= 0:\n",
      "        sys.exit('Input argument delta must be positive')\n",
      "    \n",
      "    mn, mx = Inf, -Inf\n",
      "    mnpos, mxpos = NaN, NaN\n",
      "    \n",
      "    lookformax = True\n",
      "    \n",
      "    for i in arange(len(v)):\n",
      "        this = v[i]\n",
      "        if this > mx:\n",
      "            mx = this\n",
      "            mxpos = x[i]\n",
      "        if this < mn:\n",
      "            mn = this\n",
      "            mnpos = x[i]\n",
      "        \n",
      "        if lookformax:\n",
      "            if this < mx-delta:\n",
      "                maxtab.append((mxpos, mx))\n",
      "                mn = this\n",
      "                mnpos = x[i]\n",
      "                lookformax = False\n",
      "        else:\n",
      "            if this > mn+delta:\n",
      "                #mintab.append((mnpos, mn))\n",
      "                mx = this\n",
      "                mxpos = x[i]\n",
      "                lookformax = True\n",
      " \n",
      "    return array(maxtab)#, array(mintab)\n",
      "\n",
      "\n",
      "def event_detection(data, delta, rate):\n",
      "    '''\n",
      "    do peak detect on a dataframe.\n",
      "    '''\n",
      "\n",
      "    peak_amp_temp = DataFrame()\n",
      "    rr_int_temp = DataFrame()\n",
      "    peak_sets_temp_x = {}\n",
      "    peak_sets_temp_y = {}\n",
      "\n",
      "    for label, column in data.iteritems():\n",
      "        time = column.index.tolist()\n",
      "        col = column.tolist()\n",
      "\n",
      "        #peakdet\n",
      "        maxtab = peakdet(col, delta,None)\n",
      "\n",
      "        maxtab = np.array(maxtab)\n",
      "\n",
      "        if maxtab.size == 0:\n",
      "            maxptime = []\n",
      "            maxpeaks = []\n",
      "\n",
      "        else:\n",
      "            maxptime = maxtab[:,0] #all of the rows and only the first column are time\n",
      "            maxpeaks = maxtab[:,1]\n",
      "\n",
      "        maxptime_true = (np.multiply(maxptime,rate) + time[0]) #get the real time for each R peak\n",
      "        peak_sets_temp_x[label] = maxptime_true\n",
      "\n",
      "        peak_sets_temp_y[label] = maxpeaks\n",
      "\n",
      "        #RR = rrinterval(maxptime_true)\n",
      "        peak_amp_temp[label] = Series(data = maxpeaks, index=maxptime_true).describe()\n",
      "        #rr_int_temp[label] = Series(data = RR, index=maxptime_true[:-1]).describe()\n",
      "\n",
      "    return peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max(data_smooth.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "2.8254353773993883"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "peak_amp_temp, rr_int_temp, peak_sets_temp_x, peak_sets_temp_y = event_detection(data_smooth, 0.3, rate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "need more than 3 values to unpack",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-134-ac764118f03f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpeak_amp_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrr_int_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeak_sets_temp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeak_sets_temp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_smooth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mValueError\u001b[0m: need more than 3 values to unpack"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts_temp = peak_amp_temp.loc['count']\n",
      "count_thresh = counts_temp.count()\n",
      "count_thresh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "114"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label = 'Roi138'\n",
      "plt.plot(data_edit.index, data_edit[label], label = 'original', color = 'r')\n",
      "plt.plot(data_orignal.index, data_smooth[label], label = 'smooth', color = 'b')\n",
      "plt.plot(events_x[label], events_y[label], marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "plt.plot(peak_sets_temp_x[label], peak_sets_temp_y[label], marker = \"^\", color=\"y\", linestyle= \"None\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def all_roi_line_events(data_shift, baseline, peak_sets_x, peak_sets_y, burst_e_sets, burst_s_sets, threshperc, folder):\n",
      "    '''\n",
      "    Use all_roi_line_pdfs to plot each ROI as its own pdf. specify the folder where each plot will be saved.\n",
      "    Each plot is randomly assigned a color. You cannot disable this feature.\n",
      "    you can easily consolidate all of these into a single pdf using adobe or another preview program.\n",
      "    includes overlay of LC_pro events\n",
      "    '''\n",
      "    time = data_shift.index.tolist()\n",
      "    for label,column in data_shift.iteritems():\n",
      "        \n",
      "        threshold = baseline[label] * threshperc #calculate the point at which a event is considered a peak\n",
      "\n",
      "        plt.figure()\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Intensity')\n",
      "        plt.title(label)\n",
      "        plt.ylim(ymin = min(data_shift.min()), ymax = max(data_shift.max()))\n",
      "        plt.xlim(xmin = data_shift.index[0], xmax = data_shift.index[-1])\n",
      "\n",
      "        plt.plot(data_shift.index, data_shift[label], label = 'shift', color = 'k')\n",
      "        plt.hlines((data_shift[label][:14].mean()),time[0],time[-1], label = 'baseline', color = 'b')\n",
      "        plt.hlines((threshold),time[0],time[-1], label = 'threshold', color = 'r')\n",
      "\n",
      "        plt.vlines(x = 600, ymin = min(data_shift.min()), ymax = max(data_shift.max()), color = 'r')\n",
      "        plt.vlines(x= 1200, ymin = min(data_shift.min()), ymax = max(data_shift.max()), color = 'r')\n",
      "\n",
      "        for key in data_sets:\n",
      "            plt.plot(peak_sets_x[key][label], peak_sets_y[key][label] + abs(baseline[label]), marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "            bendy = []\n",
      "            bstarty = []\n",
      "            for point in burst_s_sets[key][label]:\n",
      "                bstarty.append(threshold)\n",
      "            plt.plot(burst_s_sets[key][label], bstarty, marker = \"v\", color=\"y\", linestyle= \"None\")\n",
      "            for point in burst_e_sets[key][label]:\n",
      "                bendy.append(threshold)\n",
      "            plt.plot(burst_e_sets[key][label], bendy, marker = \"v\", color=\"m\", linestyle= \"None\")\n",
      "        plt.savefig(r'%s/plots/%s.pdf' %(folder,label))\n",
      "        plt.close()\n",
      "    print \"done, asshat\"\n",
      "    \n",
      "def all_roi_line_pdfs(dataframe, num_rois, ymin, ymax, events_x, events_y, folder):\n",
      "    '''\n",
      "    Use all_roi_line_pdfs to plot each ROI as its own pdf. specify the folder where each plot will be saved.\n",
      "    Each plot is randomly assigned a color. You cannot disable this feature.\n",
      "    you can easily consolidate all of these into a single pdf using adobe or another preview program.\n",
      "    includes overlay of LC_pro events\n",
      "    '''\n",
      "    \n",
      "    for r in np.arange(num_rois):\n",
      "        \n",
      "        plt.figure()\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Intensity')\n",
      "        plt.title(dataframe.columns[r])\n",
      "        plt.ylim(ymin = ymin, ymax = ymax)\n",
      "        plt.xlim(xmin= dataframe.index[0], xmax = dataframe.index[-1])\n",
      "        plt.plot(dataframe.index, dataframe.ix[:,r], color = [np.random.random(), np.random.random(), np.random.random()])\n",
      "        plt.plot(events_x[dataframe.columns[r]], events_y[dataframe.columns[r]],  marker = \"^\", color=\"y\", linestyle= \"None\")\n",
      "        \n",
      "        plt.savefig(r'%s/plots/%s.pdf' %(folder,dataframe.columns[r]))\n",
      "        plt.close()\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import cbook\n",
      "class DataCursor(object):\n",
      "    \"\"\"A simple data cursor widget that displays the x,y location of a\n",
      "    matplotlib artist when it is selected.\"\"\"\n",
      "    def __init__(self, artists, tolerance=5, offsets=(-20, 20), \n",
      "                 template='x: %0.2f\\ny: %0.2f', display_all=False):\n",
      "        \"\"\"Create the data cursor and connect it to the relevant figure.\n",
      "        \"artists\" is the matplotlib artist or sequence of artists that will be \n",
      "            selected. \n",
      "        \"tolerance\" is the radius (in points) that the mouse click must be\n",
      "            within to select the artist.\n",
      "        \"offsets\" is a tuple of (x,y) offsets in points from the selected\n",
      "            point to the displayed annotation box\n",
      "        \"template\" is the format string to be used. Note: For compatibility\n",
      "            with older versions of python, this uses the old-style (%) \n",
      "            formatting specification.\n",
      "        \"display_all\" controls whether more than one annotation box will\n",
      "            be shown if there are multiple axes.  Only one will be shown\n",
      "            per-axis, regardless. \n",
      "        \"\"\"\n",
      "        self.template = template\n",
      "        self.offsets = offsets\n",
      "        self.display_all = display_all\n",
      "        if not cbook.iterable(artists):\n",
      "            artists = [artists]\n",
      "        self.artists = artists\n",
      "        self.axes = tuple(set(art.axes for art in self.artists))\n",
      "        self.figures = tuple(set(ax.figure for ax in self.axes))\n",
      "\n",
      "        self.annotations = {}\n",
      "        for ax in self.axes:\n",
      "            self.annotations[ax] = self.annotate(ax)\n",
      "\n",
      "        for artist in self.artists:\n",
      "            artist.set_picker(tolerance)\n",
      "        for fig in self.figures:\n",
      "            fig.canvas.mpl_connect('pick_event', self)\n",
      "\n",
      "    def annotate(self, ax):\n",
      "        \"\"\"Draws and hides the annotation box for the given axis \"ax\".\"\"\"\n",
      "        annotation = ax.annotate(self.template, xy=(0, 0), ha='right',\n",
      "                xytext=self.offsets, textcoords='offset points', va='bottom',\n",
      "                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
      "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0')\n",
      "                )\n",
      "        annotation.set_visible(False)\n",
      "        return annotation\n",
      "\n",
      "    def __call__(self, event):\n",
      "        \"\"\"Intended to be called through \"mpl_connect\".\"\"\"\n",
      "        # Rather than trying to interpolate, just display the clicked coords\n",
      "        # This will only be called if it's within \"tolerance\", anyway.\n",
      "        x, y = event.mouseevent.xdata, event.mouseevent.ydata\n",
      "        annotation = self.annotations[event.artist.axes]\n",
      "        if x is not None:\n",
      "            if not self.display_all:\n",
      "                # Hide any other annotation boxes...\n",
      "                for ann in self.annotations.values():\n",
      "                    ann.set_visible(False)\n",
      "            # Update the annotation in the current axis..\n",
      "            annotation.xy = x, y\n",
      "            annotation.set_text(self.template % (x, y))\n",
      "            annotation.set_visible(True)\n",
      "            event.canvas.draw()\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}