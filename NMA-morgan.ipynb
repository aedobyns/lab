{
 "metadata": {
  "name": "",
  "signature": "sha256:6c6092f1acbde715d665f0e9e92f6d8d3148c4c4b83b24b571f5e9297f3077c1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Neuron Modeling Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "from scipy import spatial, signal, fft, arange\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from pandas import Series, DataFrame\n",
      "import time as t\n",
      "from PIL import Image\n",
      "import sys\n",
      "import os, errno\n",
      "import matplotlib.patches as patches\n",
      "from pandas.tools.plotting import autocorrelation_plot\n",
      "#from pyeeg import * \n",
      "from numpy import NaN, Inf, arange, isscalar, asarray, array\n",
      "from matplotlib.backends.backend_pdf import PdfPages\n",
      "import utility\n",
      "import NMResources\n",
      "\n",
      "def mkdir_p(path):\n",
      "    '''\n",
      "    This function creates a folder at the end of the specified path, unless the folder already exsists. \n",
      "    '''\n",
      "    try:\n",
      "        os.makedirs(path)\n",
      "    except OSError as exc: # Python >2.5\n",
      "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
      "            pass #do nothing if the error occurs because the path already exists\n",
      "        else: raise #re-raises the error\n",
      "    \n",
      "def delta_tuner(dataframe, epsilon, rate): #choose which data to use to tune. can be either selected list or full ist. AD reccoments full list.\n",
      "    '''\n",
      "    this function takes a dataframe of time series data and runs peak detection iteritvely. \n",
      "    since peak detection always has the the range of delta values of 0 to the max of stack,\n",
      "    epsiolon is used to be the number of divisions of that range to test. 1 being the minimum for epsilon, which is the exact middle of the range.\n",
      "    the function will return a results table (average # of events) and (# ROIs with events>1) on their own axis.\n",
      "    the graph will be click able, as to obtain the delta value that generated that point.\n",
      "    data results are not saved.\n",
      "    '''\n",
      "    \n",
      "    range_array = np.linspace(0, max(dataframe.max())/2, num = epsilon) #create the array of which delta values to test. the range is from zero (although zero is not used) to half of the max value from the entire data frame. epsilon is used to determine the number of slices to make\n",
      "    \n",
      "    results_average = Series(index = range_array) #the empty series to store results\n",
      "    results_num = Series (index = range_array) #an empty series to store results\n",
      "    #results_perc = Series (index = range_array)\n",
      "    \n",
      "    for delta in range_array[1:]: #for each delta value in the array\n",
      "        \n",
      "        peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y = event_detection(dataframe,delta, rate) #perform event detection with the delta\n",
      "\n",
      "        event_counts = peak_amp_temp.loc['count'] #count the number of events, which is a row in the peak_amp_temp array\n",
      "        average_num_events = event_counts.mean() #average the counts, to obtain (average # events/roi)\n",
      "        num_roi = event_counts[event_counts>=1].count() #count the number of ROIs with more than one event\n",
      "        \n",
      "        #perc_roi = num_roi/len(data_smooth.columns)\n",
      "\n",
      "        results_average[delta] = average_num_events \n",
      "        results_num[delta] = num_roi\n",
      "        #results_perc[delta]= perc_roi\n",
      "    return results_average, results_num\n",
      "\n",
      "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
      "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
      "    The Savitzky-Golay filter removes high frequency noise from data.\n",
      "    It has the advantage of preserving the original shape and\n",
      "    features of the signal better than other types of filtering\n",
      "    approaches, such as moving averages techniques.\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array_like, shape (N,)\n",
      "        the values of the time history of the signal.\n",
      "    window_size : int\n",
      "        the length of the window. Must be an odd integer number.\n",
      "    order : int\n",
      "        the order of the polynomial used in the filtering.\n",
      "        Must be less then `window_size` - 1.\n",
      "    deriv: int\n",
      "        the order of the derivative to compute (default = 0 means only smoothing)\n",
      "    Returns\n",
      "    -------\n",
      "    ys : ndarray, shape (N)\n",
      "        the smoothed signal (or it's n-th derivative).\n",
      "    Notes\n",
      "    -----\n",
      "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
      "    suited for smoothing noisy data. The main idea behind this\n",
      "    approach is to make for each point a least-square fit with a\n",
      "    polynomial of high order over a odd-sized window centered at\n",
      "    the point.\n",
      "    Examples\n",
      "    --------\n",
      "    t = np.linspace(-4, 4, 500)\n",
      "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
      "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.plot(t, y, label='Noisy signal')\n",
      "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
      "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
      "    plt.legend()\n",
      "    plt.show()\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
      "       Data by Simplified Least Squares Procedures. Analytical\n",
      "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
      "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
      "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
      "       Cambridge University Press ISBN-13: 9780521880688\n",
      "    \"\"\"\n",
      "    import numpy as np\n",
      "    from math import factorial\n",
      "\n",
      "    try:\n",
      "        window_size = np.abs(np.int(window_size))\n",
      "        order = np.abs(np.int(order))\n",
      "    except ValueError, msg:\n",
      "        raise ValueError(\"window_size and order have to be of type int\")\n",
      "    if window_size % 2 != 1 or window_size < 1:\n",
      "        raise TypeError(\"window_size size must be a positive odd number\")\n",
      "    if window_size < order + 2:\n",
      "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
      "    order_range = range(order+1)\n",
      "    half_window = (window_size -1) // 2\n",
      "    # precompute coefficients\n",
      "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
      "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
      "    # pad the signal at the extremes with\n",
      "    # values taken from the signal itself\n",
      "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
      "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
      "    y = np.concatenate((firstvals, y, lastvals))\n",
      "    return np.convolve( m[::-1], y, mode='valid')\n",
      "\n",
      "def peakdet(v, delta, x = None):\n",
      "    \"\"\"\n",
      "    Converted from MATLAB script at http://billauer.co.il/peakdet.html\n",
      "    \n",
      "    Returns two arrays\n",
      "    \n",
      "    function [maxtab, mintab]=peakdet(v, delta, x)\n",
      "    %PEAKDET Detect peaks in a vector\n",
      "    %        [MAXTAB, MINTAB] = PEAKDET(V, DELTA) finds the local\n",
      "    %        maxima and minima (\"peaks\") in the vector V.\n",
      "    %        MAXTAB and MINTAB consists of two columns. Column 1\n",
      "    %        contains indices in V, and column 2 the found values.\n",
      "    %      \n",
      "    %        With [MAXTAB, MINTAB] = PEAKDET(V, DELTA, X) the indices\n",
      "    %        in MAXTAB and MINTAB are replaced with the corresponding\n",
      "    %        X-values.\n",
      "    %\n",
      "    %        A point is considered a maximum peak if it has the maximal\n",
      "    %        value, and was preceded (to the left) by a value lower by\n",
      "    %        DELTA.\n",
      "    \n",
      "    % Eli Billauer, 3.4.05 (Explicitly not copyrighted).\n",
      "    % This function is released to the public domain; Any use is allowed.\n",
      "    \n",
      "    \"\"\"\n",
      "    maxtab = []\n",
      "    #mintab = []\n",
      "       \n",
      "    if x is None:\n",
      "        x = arange(len(v))\n",
      "    \n",
      "    v = asarray(v)\n",
      "    \n",
      "    if len(v) != len(x):\n",
      "        sys.exit('Input vectors v and x must have same length')\n",
      "    \n",
      "    if not isscalar(delta):\n",
      "        sys.exit('Input argument delta must be a scalar')\n",
      "    \n",
      "    if delta <= 0:\n",
      "        sys.exit('Input argument delta must be positive')\n",
      "    \n",
      "    mn, mx = Inf, -Inf\n",
      "    mnpos, mxpos = NaN, NaN\n",
      "    \n",
      "    lookformax = True\n",
      "    \n",
      "    for i in arange(len(v)):\n",
      "        this = v[i]\n",
      "        if this > mx:\n",
      "            mx = this\n",
      "            mxpos = x[i]\n",
      "        if this < mn:\n",
      "            mn = this\n",
      "            mnpos = x[i]\n",
      "        \n",
      "        if lookformax:\n",
      "            if this < mx-delta:\n",
      "                maxtab.append((mxpos, mx))\n",
      "                mn = this\n",
      "                mnpos = x[i]\n",
      "                lookformax = False\n",
      "        else:\n",
      "            if this > mn+delta:\n",
      "                #mintab.append((mnpos, mn))\n",
      "                mx = this\n",
      "                mxpos = x[i]\n",
      "                lookformax = True\n",
      " \n",
      "    return array(maxtab)#, array(mintab)\n",
      "\n",
      "\n",
      "def event_detection(data, delta, rate):\n",
      "    '''\n",
      "    do peak detect on a dataframe. takes a delta value and the rate.\n",
      "    A point is considered a maximum peak if it has the maximal value, and was preceded (to the left) by a value lower by DELTA.\n",
      "    '''\n",
      "    \n",
      "    #results storage\n",
      "    peak_amp_temp = DataFrame()\n",
      "    rr_int_temp = DataFrame()\n",
      "    peak_sets_temp_x = {} #time\n",
      "    peak_sets_temp_y = {} #amplitude\n",
      "\n",
      "    for label, column in data.iteritems(): #for each column in the data frame\n",
      "        start_time = t.clock()\n",
      "        time = column.index.tolist() #time array\n",
      "        col = column.tolist() #amplitude array\n",
      "\n",
      "        #peakdet\n",
      "        maxtab = peakdet(col, delta,None)\n",
      "\n",
      "        maxtab = np.array(maxtab)\n",
      "\n",
      "        if maxtab.size == 0: #how to handle empty np array, which occurs if no events are detected\n",
      "            maxptime = []\n",
      "            maxpeaks = []\n",
      "        \n",
      "        else:\n",
      "            maxptime = maxtab[:,0] #all of the rows and only the first column are time\n",
      "            maxpeaks = maxtab[:,1] #all of the rows and only the second column are amp.\n",
      "\n",
      "        maxptime_true = (np.multiply(maxptime,rate) + time[0]) #get the real time for each peak, since the peak is given in index not time\n",
      "        peak_sets_temp_x[label] = maxptime_true #store array of event time in the dictionary with the ROI name as the key\n",
      "\n",
      "        peak_sets_temp_y[label] = np.array(maxpeaks) #store array of events in the dictionary with the ROI name as the key\n",
      "        #RR = rrinterval(maxptime_true)\n",
      "        peak_amp_temp[label] = Series(data = maxpeaks, index=maxptime_true).describe() #store summary data series in the summary dataframe\n",
      "        #rr_int_temp[label] = Series(data = RR, index=maxptime_true[:-1]).describe()\n",
      "        end_time = t.clock()\n",
      "        print label, 'took', (end_time - start_time), 'seconds to run'\n",
      "    return peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y\n",
      "\n",
      "def line_plots(data_orignal, data_smooth, events_x, events_y, peak_sets_temp_x, peak_sets_temp_y, event_summary,folder):\n",
      "    '''\n",
      "    creates the plots with two lines: original data and smoothed data. it also overlays the events from LCpro and RAIN.\n",
      "    '''\n",
      "    lcpro_events_select_list = event_summary[event_summary['LCpro, select'] >= 1].index.tolist() #list of only roi's found by RAIN\n",
      "    \n",
      "    for label, column in data_orignal.iteritems():\n",
      "        \n",
      "        plt.figure()\n",
      "        plt.xlabel('Time (s)')\n",
      "        plt.ylabel('Intensity')\n",
      "        plt.title(label)\n",
      "        plt.ylim(ymin = min(data_orignal.min()), ymax = max(data_orignal.max()))\n",
      "        plt.xlim(xmin = data_orignal.index[0], xmax = data_orignal.index[-1])\n",
      "        \n",
      "        plt.plot(data_orignal.index, data_orignal[label], label = 'original', color = 'r')\n",
      "        plt.plot(data_orignal.index, data_smooth[label], label = 'smooth', color = 'b')\n",
      "        if label in data_orignal.columns:     \n",
      "            plt.plot(events_x[label], events_y[label], marker = \"^\", color=\"r\", linestyle= \"None\")\n",
      "        if label in lcpro_events_select_list:\n",
      "            plt.plot(events_x[label], events_y[label], marker = \"^\", color=\"g\", linestyle= \"None\")\n",
      "        if label in peak_sets_temp_x.keys():\n",
      "            plt.plot(peak_sets_temp_x[label], peak_sets_temp_y[label], marker = \"^\", color=\"y\", linestyle= \"None\")\n",
      "        plt.savefig(r'%s/plots/%s.pdf' %(folder,label))\n",
      "        plt.close()\n",
      "\n",
      "def rrinterval(maxptime): \n",
      "    \"\"\"\n",
      "    find time from r peak to r peak, called the R-R interval. Input array must be a list of numbers (float).\n",
      "    \"\"\"\n",
      "    \n",
      "    rrint = [] #empty array for ttot to go into\n",
      "    \n",
      "    for time in maxptime[1:]: #for each r peak, starting with the second one\n",
      "        s2time = maxptime.index(time) \n",
      "        s2 = maxptime[s2time-1]\n",
      "        meas = time - s2 #measure the interval by subtracting\n",
      "        rrint.append(meas) #append the measurement to the ttotal array\n",
      "    return rrint #return array\n",
      "\n",
      "print \"Notebook initalized\"    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Notebook initalized\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"voltage-TBModel-sec600-eL\"-IP0_9.txt\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Define Folders and File Paths. Import Data and Plot Data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Quick Lookup for Files (I can't really promise that this will work)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_folders_files(folder):\n",
      "    dir_content = os.listdir(folder)\n",
      "    dir_files = []\n",
      "    dir_folders = []\n",
      "    for f in dir_content:\n",
      "        f = os.path.join(folder,f)\n",
      "        if os.path.isdir(f):\n",
      "            dir_folders.append(f)\n",
      "        else:\n",
      "            dir_files.append(f)\n",
      "    return dir_folders, dir_files\n",
      "\n",
      "def show_data_files(dir_files, data_type='voltage'):\n",
      "    #get dirname\n",
      "    print \"Folder: \",os.path.dirname(dir_files[0])\n",
      "    print\n",
      "    for n,i in enumerate(dir_files):\n",
      "        file_name = os.path.basename(i)\n",
      "        if data_type in file_name:\n",
      "            print n,\": \",file_name\n",
      "\n",
      "\n",
      "#may at some point need a function that picks out specific folders passed on passed in criteria"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#folder where results are stored\n",
      "results_folder = os.path.join(os.getcwd(), 'NMResults')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the subfolders and files of folder\n",
      "folder=results_folder\n",
      "\n",
      "subfolders, files = get_folders_files(folder)\n",
      "for n,f in enumerate(subfolders):\n",
      "    print n, \": \", f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 :  C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMResults\\TBModel-sec60-eL-IP0_9\n",
        "1 :  C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMResults\\TBModel-sec60-eL-IP0_95\n",
        "2 :  C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMResults\\TBModel-sec60-eL-IP1_0\n",
        "3 :  C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMResults\\TBModel-sec60-eL-IP1_2\n",
        "4 :  C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMResults\\TBModel-sec600-eL-IP0_9\n",
        "5 :  C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMResults\\TBModel-sec600-eL-IP0_95\n",
        "6 :  C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMResults\\TBModel-sec600-eL-IP1_0\n",
        "7 :  C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMResults\\TBModel-sec600-eL-IP1_2\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subfolders_2, files_2 = get_folders_files(subfolders[5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print files\n",
      "show_data_files(files_2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Folder:  C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMResults\\TBModel-sec600-eL-IP0_95\n",
        "\n",
        "1 :  voltage-TBModel-sec600-eL-IP0_95.txt\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#specify data file, find it and extract experiment information from its name\n",
      "\n",
      "File_Path = files_2[1]\n",
      "if not os.path.isfile(File_Path):\n",
      "    print \"Cannot find file\",data_file\n",
      "else:\n",
      "    file_info = os.path.basename(File_Path).partition('.')[0].split(\"-\")\n",
      "    print file_info\n",
      "    \n",
      "variable = file_info[3]\n",
      "variable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['voltage', 'TBModel', 'sec600', 'eL', 'IP0_95']\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "'eL'"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#read-in file and reset output dict\n",
      "data_raw = pd.read_csv(File_Path, index_col= 0)\n",
      "\n",
      "output_dict = {} # reset output dict each time I load a new data file\n",
      "output_dict['File_Path'] = File_Path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_raw.columns.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "array(['-57', '-60', '-63'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Set output directory and outputfile information and suffixes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#construct output directory path name and part of file name for plots and data files\n",
      "analysis_directory = os.path.join(os.getcwd(), 'NMAnalysis')\n",
      "#output_directory = \"/Users/mfinemorris/Desktop/Neuron Modeling\"\n",
      "mkdir_p(analysis_directory)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_ext = \".png\"\n",
      "data_ext = \".txt\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exp_info = \"-\".join(file_info[1:])\n",
      "output_suffix = exp_info + data_ext\n",
      "plot_suffix = exp_info + plot_ext\n",
      "output_suffix, plot_suffix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 107,
       "text": [
        "('TBModel-sec600-eL-IP0_95.txt', 'TBModel-sec600-eL-IP0_95.png')"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analysis_subdir = NMResources.element_sep.join(file_info[1:])\n",
      "output_directory = os.path.join(analysis_directory,analysis_subdir)                                     \n",
      "utility.mkdir_p(subdir)\n",
      "output_directory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "'C:\\\\Users\\\\mfinemorris\\\\repos\\\\WilsonLab\\\\NMAnalysis\\\\TBModel-sec600-eL-IP0_95'"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "meas = '-63'\n",
      "plt.plot(data_raw.index, data_raw[meas])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot all raw data time series\n",
      "for label, column in data_raw.iteritems():\n",
      "    \n",
      "    plt.plot(data_raw.index, column)\n",
      "    plt.title(label)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Process Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calc rate\n",
      "rate = data_raw.index[3] - data_raw.index[2]\n",
      "rate\n",
      "output_dict['rate'] = rate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make experiment label\n",
      "\n",
      "exp = (file_info[1]+\" with \"+\", \".join(file_info[2:])).replace(\"_\",\".\")\n",
      "output_dict['exp'] = exp\n",
      "exp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "'TBModel with sec600, eL, IP0.95'"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#event detection on all time series\n",
      "delta = 1\n",
      "peak_amp_temp, peak_sets_temp_x, peak_sets_temp_y = event_detection(data_raw, delta, rate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-57 took 8.87833557517 seconds to run\n",
        "-60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " took 8.70062649576 seconds to run\n",
        "-63"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " took 8.43676735371 seconds to run\n"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "peak_sets_temp_x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "{'-57': array([   7382.50123042,    7415.20123587,    7439.70123995, ...,\n",
        "         596837.69947295,  596863.09947718,  596895.69948262]),\n",
        " '-60': array([   7463.30124388,    7475.4012459 ,    7486.8012478 , ...,\n",
        "         596821.59947027,  596842.89947382,  596874.79947913]),\n",
        " '-63': array([  2.00000033e+00,   7.47820125e+03,   7.48980125e+03, ...,\n",
        "          5.96793499e+05,   5.96812799e+05,   5.96836899e+05])}"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save peak data for later operations in notebook\n",
      "peaks = {} \n",
      "\n",
      "#save peak data for later output\n",
      "peak_y = peak_sets_temp_y\n",
      "peak_x = peak_sets_temp_x\n",
      "temp = []\n",
      "\n",
      "max_peaks = max([len(peak_x[key]) for key in peak_x])\n",
      "\n",
      "for k in peak_x:\n",
      "    start_time = t.clock()\n",
      "\n",
      "    #### Collect peak data for later notebook operations\n",
      "    xlist = peak_x[k].tolist()\n",
      "    #get RR interval\n",
      "    RR = rrinterval(xlist)\n",
      "    RR.append(NaN)\n",
      "    peaks[k] = DataFrame({'Amplitude':peak_y[k].tolist(),'Interval':RR}, index = xlist)\n",
      "\n",
      "    #### Collect peak data for saving\n",
      "    temp.append(peak_x[k])\n",
      "    temp.append(peak_y[k])\n",
      "    temp.append(RR[:-1])\n",
      "    \n",
      "    end_time = t.clock()\n",
      "    print k, \"finished in\", np.round(end_time - start_time, 3)\n",
      "    \n",
      "#index/cols for the peak array that will be saved to file\n",
      "cols=pd.MultiIndex.from_product([data_raw.columns,[u'rr', u'x', u'y']],names=['variable','peak_data'])\n",
      "peak_x_y = pd.DataFrame(data=temp, index=cols, columns=range(0,max_peaks)).T.to_sparse()\n",
      "\n",
      "output_dict['peak_amp_temp'] = peak_amp_temp\n",
      "#output_dict['peaks_'] = peak_x_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-60 finished in 0.033\n",
        "-57 finished in 0.045\n",
        "-63"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " finished in 0.025\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_file = os.path.join(output_directory,'peaks-'+output_suffix)\n",
      "print save_file\n",
      "# IDK why this works and peak_x_y.to_csv() doesn't, but you can't argue with results...\n",
      "peak_dict = peak_x_y.to_dict()\n",
      "pd.DataFrame().from_dict(peak_dict).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\TBModel-sec600-eL-IP0_95\\peaks-TBModel-sec600-eL-IP0_95.txt\n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "peak to peak measurments, includes ibi"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#how many peaks occur in each trace?\n",
      "for key, value in peak_sets_temp_x.iteritems():\n",
      "    v = value.tolist()\n",
      "    print key, '=', len(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-60 = 2007\n",
        "-57 = 2341\n",
        "-63 = 1740\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all events detected\n",
      "peaks = {}\n",
      "for key, value in peak_sets_temp_x.iteritems():\n",
      "    start_time = t.clock()\n",
      "    peak_x = value.tolist()\n",
      "    peak_y = peak_sets_temp_y[key].tolist()\n",
      "    \n",
      "    RR = rrinterval(peak_x)\n",
      "    RR.append(NaN)\n",
      "    #make Dataframe with index as peak_x (time of peak) and store amplitude of peak(peak_y) and RR-interval\n",
      "    results_peaks = DataFrame({'Amplitude':peak_y,'Interval':RR}, index = peak_x)  \n",
      "    peaks[key] = results_peaks\n",
      "    end_time = t.clock()\n",
      "    print key, \"finished in\", np.round(end_time - start_time, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-60 finished in 0.033\n",
        "-57 finished in 0.044\n",
        "-63"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " finished in 0.024\n"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "peaks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 112,
       "text": [
        "{'-57':                Amplitude   Interval\n",
        " 7382.501230     5.759033  32.700005\n",
        " 7415.201236     5.754114  24.500004\n",
        " 7439.701240     5.802851  17.400003\n",
        " 7457.101243     5.771793  13.100002\n",
        " 7470.201245     5.511742  11.600002\n",
        " 7481.801247     5.170232  11.400002\n",
        " 7493.201249     5.053666  11.300002\n",
        " 7504.501251     5.056427  11.300002\n",
        " 7515.801253     5.019103  11.400002\n",
        " 7527.201255     4.947092  11.500002\n",
        " 7538.701256     4.979589  11.600002\n",
        " 7550.301258     5.059715  11.700002\n",
        " 7562.001260     5.124615  11.800002\n",
        " 7573.801262     5.146126  12.000002\n",
        " 7585.801264     5.076680  12.000002\n",
        " 7597.801266     5.259389  12.200002\n",
        " 7610.001268     5.289849  12.400002\n",
        " 7622.401270     5.252857  12.500002\n",
        " 7634.901272     5.351279  12.800002\n",
        " 7647.701275     5.240126  12.900002\n",
        " 7660.601277     5.381168  13.300002\n",
        " 7673.901279     5.358479  13.500002\n",
        " 7687.401281     5.498480  13.900002\n",
        " 7701.301284     5.533432  14.400002\n",
        " 7715.701286     5.417992  14.800002\n",
        " 7730.501288     5.446558  15.700003\n",
        " 7746.201291     5.569869  16.600003\n",
        " 7762.801294     5.676774  18.200003\n",
        " 7781.001297     5.549619  20.900003\n",
        " 7801.901300     5.720765  28.300005\n",
        " ...                  ...        ...\n",
        " 596477.499413   5.637645  18.100003\n",
        " 596495.599416   5.708173  13.500002\n",
        " 596509.099418   5.521818  11.700002\n",
        " 596520.799420   5.242445  11.300002\n",
        " 596532.099422   5.043611  11.300002\n",
        " 596543.399424   5.059771  11.300002\n",
        " 596554.699426   5.021366  11.400002\n",
        " 596566.099428   5.088156  11.500002\n",
        " 596577.599430   5.045181  11.500002\n",
        " 596589.099432   5.121864  11.700002\n",
        " 596600.799433   5.079169  11.700002\n",
        " 596612.499435   5.167812  11.900002\n",
        " 596624.399437   5.217298  12.000002\n",
        " 596636.399439   5.248968  12.100002\n",
        " 596648.499441   5.170028  12.300002\n",
        " 596660.799443   5.190160  12.500002\n",
        " 596673.299446   5.321391  12.700002\n",
        " 596685.999448   5.374468  12.900002\n",
        " 596698.899450   5.400891  13.100002\n",
        " 596711.999452   5.369375  13.500002\n",
        " 596725.499454   5.448178  13.800002\n",
        " 596739.299457   5.441295  14.200002\n",
        " 596753.499459   5.510471  14.700002\n",
        " 596768.199461   5.603985  15.400003\n",
        " 596783.599464   5.642110  16.300003\n",
        " 596799.899467   5.662943  17.700003\n",
        " 596817.599470   5.706872  20.100003\n",
        " 596837.699473   5.597253  25.400004\n",
        " 596863.099477   5.602379  32.600005\n",
        " 596895.699483 -45.112589        NaN\n",
        " \n",
        " [2341 rows x 2 columns], '-60':                Amplitude     Interval\n",
        " 7463.301244     6.014125    12.100002\n",
        " 7475.401246     5.435409    11.400002\n",
        " 7486.801248     5.163965    11.200002\n",
        " 7498.001250     5.102671    11.300002\n",
        " 7509.301252     5.102807    11.300002\n",
        " 7520.601253     5.128896    11.400002\n",
        " 7532.001255     5.052695    11.600002\n",
        " 7543.601257     5.155173    11.600002\n",
        " 7555.201259     5.192883    11.800002\n",
        " 7567.001261     5.262832    11.900002\n",
        " 7578.901263     5.270600    12.100002\n",
        " 7591.001265     5.324723    12.200002\n",
        " 7603.201267     5.293288    12.500002\n",
        " 7615.701269     5.299465    12.600002\n",
        " 7628.301271     5.437577    12.900002\n",
        " 7641.201274     5.432169    13.100002\n",
        " 7654.301276     5.486424    13.500002\n",
        " 7667.801278     5.506953    13.800002\n",
        " 7681.601280     5.588263    14.300002\n",
        " 7695.901283     5.458593    14.700002\n",
        " 7710.601285     5.533713    15.500003\n",
        " 7726.101288     5.669675    16.400003\n",
        " 7742.501290     5.685985    17.800003\n",
        " 7760.301293     5.755022    20.000003\n",
        " 7780.301297     5.700445    25.300004\n",
        " 7805.601301     5.756399    23.800004\n",
        " 7829.401305   -45.866661  8546.101424\n",
        " 16375.502729    5.982799    13.200002\n",
        " 16388.702731    5.607490    11.400002\n",
        " 16400.102733    5.145519    10.800002\n",
        " ...                  ...          ...\n",
        " 596486.499414   5.865669    13.600002\n",
        " 596500.099417   5.556158    11.400002\n",
        " 596511.499419   5.270539    10.800002\n",
        " 596522.299420   5.005101    10.700002\n",
        " 596532.999422   4.804328    10.600002\n",
        " 596543.599424   4.903356    10.700002\n",
        " 596554.299426   4.911627    10.800002\n",
        " 596565.099428   4.954252    10.900002\n",
        " 596575.999429   4.888162    10.900002\n",
        " 596586.899431   4.999557    11.100002\n",
        " 596597.999433   5.030573    11.200002\n",
        " 596609.199435   4.932432    11.200002\n",
        " 596620.399437   5.033333    11.500002\n",
        " 596631.899439   5.054387    11.500002\n",
        " 596643.399441   5.194312    11.700002\n",
        " 596655.099443   5.189073    11.900002\n",
        " 596666.999444   5.280026    12.100002\n",
        " 596679.099447   5.330683    12.300002\n",
        " 596691.399449   5.339805    12.500002\n",
        " 596703.899451   5.427550    12.800002\n",
        " 596716.699453   5.473337    13.100002\n",
        " 596729.799455   5.490028    13.500002\n",
        " 596743.299457   5.541081    14.000002\n",
        " 596757.299460   5.582828    14.500002\n",
        " 596771.799462   5.643676    15.300003\n",
        " 596787.099465   5.688927    16.400003\n",
        " 596803.499467   5.746932    18.100003\n",
        " 596821.599470   5.652484    21.300004\n",
        " 596842.899474   5.647813    31.900005\n",
        " 596874.799479   5.633926          NaN\n",
        " \n",
        " [2007 rows x 2 columns], '-63':                Amplitude     Interval\n",
        " 2.000000      -59.671540  7476.201246\n",
        " 7478.201246     5.986948    11.600002\n",
        " 7489.801248     5.333781    11.500002\n",
        " 7501.301250     5.236545    11.500002\n",
        " 7512.801252     5.207794    11.700002\n",
        " 7524.501254     5.284338    11.800002\n",
        " 7536.301256     5.278429    11.900002\n",
        " 7548.201258     5.359929    12.100002\n",
        " 7560.301260     5.396949    12.300002\n",
        " 7572.601262     5.379801    12.400002\n",
        " 7585.001264     5.342975    12.700002\n",
        " 7597.701266     5.432138    13.000002\n",
        " 7610.701268     5.479787    13.200002\n",
        " 7623.901271     5.567479    13.500002\n",
        " 7637.401273     5.586448    13.900002\n",
        " 7651.301275     5.592576    14.400002\n",
        " 7665.701278     5.663657    14.900002\n",
        " 7680.601280     5.629636    15.500003\n",
        " 7696.101283     5.752297    16.400003\n",
        " 7712.501285     5.687406    17.700003\n",
        " 7730.201288     5.802120    19.500003\n",
        " 7749.701292     5.729198    23.300004\n",
        " 7773.001296     5.821698    39.700007\n",
        " 7812.701302     5.580752  8586.001431\n",
        " 16398.702733    6.036896    10.900002\n",
        " 16409.602735    5.150415    10.700002\n",
        " 16420.302737    4.964090    10.700002\n",
        " 16431.002739    4.924118    10.700002\n",
        " 16441.702740    4.946834    10.900002\n",
        " 16452.602742    5.032553    10.900002\n",
        " ...                  ...          ...\n",
        " 587851.497975   5.770345    17.100003\n",
        " 587868.597978   5.798652    19.300003\n",
        " 587887.897981   5.839090    24.100004\n",
        " 587911.997985   5.690144  8598.501433\n",
        " 596510.499418   6.178345    10.800002\n",
        " 596521.299420   5.024432    10.500002\n",
        " 596531.799422   4.815199    10.600002\n",
        " 596542.399424   4.807003    10.700002\n",
        " 596553.099426   4.960913    10.800002\n",
        " 596563.899427   4.942088    10.800002\n",
        " 596574.699429   5.001237    11.000002\n",
        " 596585.699431   5.087798    11.100002\n",
        " 596596.799433   5.123567    11.200002\n",
        " 596607.999435   5.163878    11.400002\n",
        " 596619.399437   5.200165    11.500002\n",
        " 596630.899438   5.262221    11.700002\n",
        " 596642.599440   5.310272    11.900002\n",
        " 596654.499442   5.358068    12.100002\n",
        " 596666.599444   5.405730    12.300002\n",
        " 596678.899446   5.381392    12.600002\n",
        " 596691.499449   5.393351    13.000002\n",
        " 596704.499451   5.422668    13.200002\n",
        " 596717.699453   5.518841    13.700002\n",
        " 596731.399455   5.516817    14.300002\n",
        " 596745.699458   5.671208    14.900002\n",
        " 596760.599460   5.733384    15.800003\n",
        " 596776.399463   5.781812    17.100003\n",
        " 596793.499466   5.822268    19.300003\n",
        " 596812.799469   5.734753    24.100004\n",
        " 596836.899473   5.819190          NaN\n",
        " \n",
        " [1740 rows x 2 columns]}"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#interburst interval detection\n",
      "ibi_thresh = 200 #in ms #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ibi_average = Series(index = data_raw.columns)\n",
      "ibi_std = Series(index = data_raw.columns)\n",
      "for key, value in peaks.iteritems():\n",
      "    ibi = value[value['Interval']>ibi_thresh].Interval.mean()\n",
      "    ibi_average[key] = ibi\n",
      "    \n",
      "    std = value[value['Interval']>ibi_thresh].Interval.std()\n",
      "    ibi_std[key] = std\n",
      "    \n",
      "ibi_data = pd.concat({'ibi_average':ibi_average,'ibi_std':ibi_std}, axis=1)\n",
      "\n",
      "output_dict['ibi_thresh'] = ibi_thresh\n",
      "#output_dict['ibi_average'] = ibi_average\n",
      "#output_dict['ibi_std'] = ibi_std\n",
      "\n",
      "output_dict['ibi_avg_std']=ibi_data\n",
      "'''\n",
      "save_file = os.path.join(output_directory,'ibi-'+output_suffix)\n",
      "df = pd.DataFrame().from_dict(ibi_data.to_dict())\n",
      "df.to_csv(save_file)\n",
      "'''\n",
      "print ibi_thresh\n",
      "ibi_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>ibi_average</th>\n",
        "      <th>ibi_std</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>-57</th>\n",
        "      <td> 8311.581688</td>\n",
        "      <td>   3.510390</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>-60</th>\n",
        "      <td> 8536.439302</td>\n",
        "      <td>   1.679173</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>-63</th>\n",
        "      <td> 8581.237251</td>\n",
        "      <td> 137.063325</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "     ibi_average     ibi_std\n",
        "-57  8311.581688    3.510390\n",
        "-60  8536.439302    1.679173\n",
        "-63  8581.237251  137.063325"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ibi summary graph\n",
      "plt.errorbar(ibi_average.index, ibi_average, ibi_std, marker = '^', color = 'k')\n",
      "#plt.xlim(xmin = 0)\n",
      "plt.xlabel('%s' %(exp))\n",
      "plt.ylabel('Interburst Interval (ms)')\n",
      "plt.title('Interburst interval when %s is changed' %exp)\n",
      "plot_dict['ibi_summary'] = plt.gca()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "burst duration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bursts = {}\n",
      "burst_arr = []\n",
      "duration = Series(index = data_raw.columns)\n",
      "duration_std = Series(index = data_raw.columns)\n",
      "burst_ibi = Series(index = data_raw.columns)\n",
      "burst_ibi_std = Series(index = data_raw.columns)\n",
      "\n",
      "for key, value in peaks.iteritems():\n",
      "    b_start = []\n",
      "    b_end = []\n",
      "    b_ibi = []\n",
      "    try:\n",
      "        b_start.append(value.index[0])\n",
      "    except IndexError as e:\n",
      "        continue\n",
      "        \n",
      "    b_flag = True\n",
      "\n",
      "    for index, row in value['Interval'].iteritems():\n",
      "        if b_flag == False:\n",
      "            b_start.append(index)\n",
      "            b_flag = True\n",
      "\n",
      "        if b_flag == True:\n",
      "            if row>ibi_thresh:\n",
      "                b_end.append(index)\n",
      "                b_ibi.append(row)\n",
      "                b_flag = False\n",
      "                \n",
      "    if len(b_start) == len(b_end) +1:\n",
      "        del b_start[-1]\n",
      "        \n",
      "    #store info about bursts\n",
      "    Burst = DataFrame(data = {'Start':b_start})\n",
      "    Burst['End'] = b_end\n",
      "    Burst['Duration'] = Burst['End'] - Burst['Start']\n",
      "    Burst['Burst Interval'] = b_ibi\n",
      "    bursts[key] = Burst\n",
      "    \n",
      "    burst_arr.append(b_start)\n",
      "    burst_arr.append(b_end)\n",
      "    burst_arr.append(Burst['Duration'].values.tolist())\n",
      "    burst_arr.append(b_ibi)\n",
      "\n",
      "    \n",
      "    #information derived from burst indo\n",
      "    duration[key] = Burst['Duration'].mean()\n",
      "    duration_std[key] = Burst['Duration'].std()\n",
      "    burst_ibi[key] =  Burst['Burst Interval'].mean()\n",
      "    burst_ibi_std[key] = Burst['Burst Interval'].std()\n",
      "    \n",
      "\n",
      "#store the burst duration- and ibi- mean and std together in prep for final output\n",
      "burst_misc_data = pd.concat([duration, duration_std, burst_ibi, burst_ibi_std],keys=['duration mean','duration std','ibi mean', 'ibi std'], axis=1)#DataFrame(data =,index = data_raw.columns, )\n",
      "#output_dict['bursts_']=bursts\n",
      "output_dict['burst_stat_data'] = burst_misc_data\n",
      "\n",
      "#burst_misc_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save bursts\n",
      "save_file = os.path.join(output_directory,'bursts-'+output_suffix)\n",
      "print save_file\n",
      "\n",
      "# IDK why this works when .to_csv doesn't, but you can't argue with results...\n",
      "burst_ind = pd.MultiIndex.from_product([bursts.keys(), [u'start', u'end', u'duration', u'burst interval']], names=['variable','burst data'])\n",
      "burst_df = pd.DataFrame(data=burst_arr, index=burst_ind).T.to_sparse()\n",
      "burst_dict = burst_df.to_dict()\n",
      "pd.DataFrame().from_dict(burst_dict).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\TBModel-sec600-eL-IP0_95\\bursts-TBModel-sec600-eL-IP0_95.txt\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_info"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "['voltage', 'TBModel', 'sec600', 'eL', 'IP0_95']"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#burst duration summary plot\n",
      "plt.errorbar(duration.index, duration, duration_std, marker = '^')\n",
      "plt.xlabel('%s' %(variable))\n",
      "plt.ylabel('Burst Duration (ms)')\n",
      "plt.title('Burst duration when %s is changed' %(variable))\n",
      "plot_file = os.path.join(output_directory,\"burst_dur_summary-\"+plot_suffix)\n",
      "print plot_file\n",
      "plt.savefig(plot_file)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\TBModel-sec600-eL-IP0_95\\burst_dur_summary-TBModel-sec600-eL-IP0_95.png\n"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Raster Plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#raster plot\n",
      "for key, value in peak_sets_temp_x.iteritems():\n",
      "    key = float(key)\n",
      "    temp_y = []\n",
      "    for n in value:\n",
      "        temp_y.append(key)\n",
      "    plt.plot(value, temp_y, marker = '.', color = 'k', linestyle = 'None', markersize = 2)\n",
      "plt.xlabel('Time (ms)')\n",
      "plt.ylabel('%s' %variable)\n",
      "y_min = float(peak_sets_temp_x.keys()[0])\n",
      "y_max = float(peak_sets_temp_x.keys()[-1])\n",
      "print y_min, y_max\n",
      "y_diff = (y_max-y_min)/5\n",
      "#plt.ylim(ymin=y_min*(1-y_diff), ymax=y_max*(1+y_diff))\n",
      "plt.ylim(y_min-10, y_max+10)\n",
      "plt.xlim(xmin = 20000, xmax = 45000)\n",
      "plt.title('Raster plot: %s'%exp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-60.0 -63.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 129,
       "text": [
        "<matplotlib.text.Text at 0x3fabb438>"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save plot\n",
      "plot_file = os.path.join(output_directory,\"raster-\"+plot_suffix)\n",
      "print plot_file\n",
      "plt.savefig(plot_file)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-60.0 -63.0\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\TBModel-sec600-eL-IP0_95\\raster-TBModel-sec600-eL-IP0_95.png\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Freq plots"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "key = '1.0' #must be a string "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rris = {}\n",
      "for key in peaks:\n",
      "    rri = peaks[key]['Interval'].tolist()\n",
      "    try:\n",
      "        del rri[-1] #the last value is NaN, so we delete it.\n",
      "    except IndexError:\n",
      "        continue\n",
      "\n",
      "    rri_new = []\n",
      "    for i in rri:\n",
      "        bpm = 60000/i\n",
      "        rri_new.append(bpm)\n",
      "    time_int = peaks[key].index.tolist()\n",
      "    del time_int[-1] #must be the same length as rri\n",
      "\n",
      "    plt.ylabel('Event Rate (events/min.)')\n",
      "    plt.xlabel('Time (s)')\n",
      "    plt.title('Event Freqency-Peak detection')\n",
      "    plt.plot(time_int, rri_new)\n",
      "    plt.show()\n",
      "    ser = pd.Series(data=rri_new, index=time_int)\n",
      "    rris[key] = ser\n",
      "    \n",
      "#output_dict['rris_'] = rris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_file = os.path.join(output_directory,'rris-'+output_suffix)\n",
      "print save_file\n",
      "pd.DataFrame().from_dict(rris).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\rris-BRSModel-sec1320-eL.txt\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sliding_peak_freq(dictionary, data_raw, window):\n",
      "    '''\n",
      "    takes a window size in ms and does non-overlapping count (which is freq, since the windows are all the same size) and average ibi. \n",
      "    returns two dataframes with this information for each 'test' case.\n",
      "    '''\n",
      "    import math\n",
      "    num = math.trunc(data_raw.index[-1]/window) #get the number of windows to do the counts and averages over.\n",
      "    \n",
      "    sliding_count = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    sliding_mean = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    \n",
      "    for key, value in dictionary.iteritems():\n",
      "        \n",
      "        temp_count = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        temp_mean = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        \n",
      "        for i in (np.arange(num)*window):\n",
      "            temp_count[i] = value['Interval'][i:(i+window)].count() #get the count in the window\n",
      "            temp_mean[i] = value['Interval'][i:(i+window)].mean() #get the mean in the window\n",
      "        \n",
      "        temp_mean = temp_mean.fillna(0) #temp mean returns NaN for windows with no events. make it zero for graphing\n",
      "        \n",
      "        sliding_count[key] = temp_count #store series in results table\n",
      "        sliding_mean[key] = temp_mean #store series in results table\n",
      "    \n",
      "    sliding_count = sliding_count.sort_index(axis = 1)\n",
      "    sliding_mean = sliding_mean.sort_index(axis = 1) #my attempt at reordering so the columns are in increaing order\n",
      "    return sliding_mean, sliding_count\n",
      "\n",
      "\n",
      "def sliding_burst_freq(dictionary, data_raw, window):\n",
      "    '''\n",
      "    takes a window size in ms and does non-overlapping count (which is freq, since the windows are all the same size) and average ibi. \n",
      "    returns two dataframes with this information for each 'test' case.\n",
      "    '''\n",
      "    \n",
      "    import math\n",
      "    num = math.trunc(data_raw.index[-1]/window) #get the number of windows to do the counts and averages over.\n",
      "    \n",
      "    sliding_count = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    sliding_mean_dur = DataFrame(index= (np.arange(num)*window)) #where we're storing the results for each timeseries\n",
      "    sliding_mean_dur = DataFrame(index= (np.arange(num)*window))\n",
      "    \n",
      "    for key, value in dictionary.iteritems():\n",
      "        \n",
      "        temp_count = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        temp_mean_dur = Series(index= (np.arange(num)*window)) #temp storage\n",
      "        \n",
      "        for i in (np.arange(num)*window):\n",
      "            temp_count[i] = value['Duration'][i:(i+window)].count() #get the count in the window\n",
      "            temp_mean_dur[i] = value['Duration'][i:(i+window)].mean() #get the mean in the window\n",
      "        \n",
      "        temp_mean = temp_mean_dur.fillna(0) #temp mean returns NaN for windows with no events. make it zero for graphing\n",
      "        \n",
      "        sliding_count[key] = temp_count #store series in results table\n",
      "        sliding_mean_dur[key] = temp_mean #store series in results table\n",
      "    \n",
      "    sliding_count = sliding_count.sort_index(axis = 1)\n",
      "    sliding_mean = sliding_mean_dur.sort_index(axis = 1) #my attempt at reordering so the columns are in increaing order\n",
      "    return sliding_mean, sliding_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "window = 1000 #set window size, no overlap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sliding_p_mean, sliding_p_count = sliding_peak_freq(peaks, data_raw,  window = window)\n",
      "#output_dict['sliding_p_mean_'] = sliding_p_mean\n",
      "#output_dict['sliding_p_count_'] = sliding_p_count\n",
      "peak_c_m = pd.concat({'peak count':sliding_p_count, 'peak mean':sliding_p_mean}, axis=1).to_sparse()\n",
      "#output_dict['sliding_peaks_']=peak_c_m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sliding_b_mean, sliding_b_count = sliding_burst_freq(bursts, data_raw,  window = window)\n",
      "#output_dict['sliding_b_count_'] = sliding_b_count\n",
      "#output_dict['sliding_b_mean_'] = sliding_b_mean\n",
      "burst_c_m = pd.concat({'burst count':sliding_b_count, 'burst mean':sliding_b_mean}, axis=1).to_sparse()\n",
      "#output_dict['sliding_bursts_']=burst_c_m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_file = os.path.join(output_directory,'sliding_burst_cm-'+output_suffix)\n",
      "print save_file\n",
      "pd.DataFrame().from_dict(burst_c_m.to_dict()).to_csv(save_file)\n",
      "\n",
      "save_file = os.path.join(output_directory,'sliding_peak_cm-'+output_suffix)\n",
      "print save_file\n",
      "pd.DataFrame().from_dict(peak_c_m.to_dict()).to_csv(save_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_burst_cm-BRSModel-sec1320-eL.txt\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peak_cm-BRSModel-sec1320-eL.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save sliding data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick sharex plot of count and raw data for a given test varible \n",
      "foo = '0.95'\n",
      "fig, ax = plt.subplots(2, sharex= True)\n",
      "ax[0].plot(data_raw.index, data_raw[foo])\n",
      "ax[1].plot(sliding_p_count.index, sliding_p_count[foo], marker = '.')\n",
      "fig.subplots_adjust(hspace = 0.1)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'0.95'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-85-5de7332b2750>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'0.95'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfoo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliding_p_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msliding_p_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfoo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1741\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1748\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1749\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1750\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   2804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[0mloc\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0munique\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly\u001b[0m \u001b[0mslice\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \"\"\"\n\u001b[1;32m-> 1385\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\index.pyd\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3795)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\index.pyd\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3675)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\hashtable.pyd\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12299)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mfinemorris\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\hashtable.pyd\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12250)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: '0.95'"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rd_index = data_raw.index\n",
      "p_index = sliding_p_count.index\n",
      "for num, key in enumerate(data_raw[1:]):\n",
      "    peak_data = sliding_p_count[key]\n",
      "    raw_data = data_raw[key]\n",
      "    \n",
      "    fig = plt.figure(num)\n",
      "    fig.subplots_adjust(hspace=0.1)\n",
      "\n",
      "    ax1 = plt.subplot(211)\n",
      "    ax1.plot(rd_index, raw_data)\n",
      "    plt.ylabel('Membrane Potential (mV)')\n",
      "    plt.title(\"sliding peak count, \" + variable + \" = \"+ key)\n",
      "\n",
      "    ax2 = plt.subplot(212, sharex=ax1)\n",
      "    ax2.plot(p_index, peak_data, marker = '.')\n",
      "    plt.xlabel(\"Time (ms)\")\n",
      "    plt.ylabel(\"# Peaks\")\n",
      "    \n",
      "    plot_file = os.path.join(output_directory,\"sliding_peaks-\"+key.replace(\".\",\"_\")+\"-\"+plot_suffix)\n",
      "    print plot_file\n",
      "    fig.savefig(plot_file)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peaks--55-BRSModel-sec1320-eL.png\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peaks--60-BRSModel-sec1320-eL.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C:\\Users\\mfinemorris\\repos\\WilsonLab\\NMAnalysis\\sliding_peaks--65-BRSModel-sec1320-eL.png"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Optional Blocks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all time series overlay\n",
      "plt.plot(data_raw, label= data_raw.columns)\n",
      "plt.xlim(xmin = 30000, xmax = 45000)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot all events with specail start and end colors.\n",
      "meas = '0.95' #which setting to graph\n",
      "\n",
      "plt.plot(data_raw.index, data_raw[meas], color = 'k')\n",
      "plt.plot(peaks[meas].index, peaks[meas]['Amplitude'], marker ='^', color = 'g', linestyle = 'None')\n",
      "for index, row in bursts[meas]['Start'].iteritems():\n",
      "    plt.plot(row, peaks[meas]['Amplitude'].loc[row], marker ='^', color = 'm', linestyle = 'None')\n",
      "for index, row in bursts[meas]['End'].iteritems():\n",
      "    plt.plot(row, peaks[meas]['Amplitude'].loc[row], marker ='^', color = 'y', linestyle = 'None')\n",
      "#plt.xlim(xmin = 30000, xmax = 45000)\n",
      "plt.title('%s - %s' %(exp, meas))\n",
      "plt.xlabel('Time (ms)')\n",
      "plt.ylabel('Voltage')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#quick plot of events\n",
      "label = meas\n",
      "plt.plot(data_raw.index, data_raw[label])\n",
      "plt.plot(peak_sets_temp_x[label], peak_sets_temp_y[label], marker = \"^\", color=\"y\", linestyle= \"None\")\n",
      "plt.title(label)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Save out settings and analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import NMResources as nmr\n",
      "import operator\n",
      "from pprint import pprint\n",
      "import json\n",
      "output_file = os.path.join(output_directory,\"misc-\"+output_suffix+\".csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Save Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make all dataframes into csv strings\n",
      "#separate them from other elements of dictionary\n",
      "formatted_output = {}\n",
      "for i,ii in output_dict.iteritems():\n",
      "    try:\n",
      "        formatted_output[i]=ii.to_dict()\n",
      "    except:\n",
      "        formatted_output[i]=ii\n",
      "        \n",
      "with open(output_file,'w') as f:\n",
      "    json.dump(formatted_output,f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pat_ind = output_dict['peak_amp_temp'].index\n",
      "output_dict['peak_amp_temp']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0.9</th>\n",
        "      <th>0.95</th>\n",
        "      <th>1.0</th>\n",
        "      <th>1.2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>  0</td>\n",
        "      <td> 887.000000</td>\n",
        "      <td> 2148.000000</td>\n",
        "      <td> 3119.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.209998</td>\n",
        "      <td>    5.450821</td>\n",
        "      <td>    4.641696</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   1.709528</td>\n",
        "      <td>    1.107147</td>\n",
        "      <td>    6.659212</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>NaN</td>\n",
        "      <td> -44.963484</td>\n",
        "      <td>  -45.411611</td>\n",
        "      <td>  -45.888449</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.015600</td>\n",
        "      <td>    5.360962</td>\n",
        "      <td>    5.484921</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.246601</td>\n",
        "      <td>    5.472068</td>\n",
        "      <td>    5.540429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.508012</td>\n",
        "      <td>    5.575864</td>\n",
        "      <td>    5.589770</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.946941</td>\n",
        "      <td>    5.896579</td>\n",
        "      <td>    5.802625</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 130,
       "text": [
        "       0.9        0.95          1.0          1.2\n",
        "count    0  887.000000  2148.000000  3119.000000\n",
        "mean   NaN    5.209998     5.450821     4.641696\n",
        "std    NaN    1.709528     1.107147     6.659212\n",
        "min    NaN  -44.963484   -45.411611   -45.888449\n",
        "25%    NaN    5.015600     5.360962     5.484921\n",
        "50%    NaN    5.246601     5.472068     5.540429\n",
        "75%    NaN    5.508012     5.575864     5.589770\n",
        "max    NaN    5.946941     5.896579     5.802625"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Extract Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Extract Data\n",
      "with open(output_file,'r') as f:\n",
      "    misc_data = json.load(f)\n",
      "print misc_data.keys()\n",
      "\n",
      "temp = {}\n",
      "\n",
      "for k,v in misc_data.iteritems():\n",
      "    try:\n",
      "        temp[k] = pd.DataFrame.from_dict(v)\n",
      "        print k\n",
      "    except:\n",
      "        temp[k] = v\n",
      "        print k, \": \", v\n",
      "        \n",
      "temp['peak_amp_temp'].reindex_axis(pat_ind)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'burst_stat_data', u'peak_amp_temp', u'ibi_avg_std', u'ibi_thresh', u'File_Path', u'rate', u'exp', u'sg_setting']\n",
        "burst_stat_data\n",
        "peak_amp_temp\n",
        "ibi_avg_std\n",
        "ibi_thresh :  200\n",
        "File_Path :  C:\\Users\\mfinemorris\\Desktop\\Parallel Model Code\\Results\\voltage-TBModel-sec300-IP-gL2_5.txt\n",
        "rate :  0.100000033333\n",
        "exp :  TBModel with sec300, IP, gL2_5\n",
        "sg_setting :  301\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0.9</th>\n",
        "      <th>0.95</th>\n",
        "      <th>1.0</th>\n",
        "      <th>1.2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>  0</td>\n",
        "      <td> 887.000000</td>\n",
        "      <td> 2148.000000</td>\n",
        "      <td> 3119.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.209998</td>\n",
        "      <td>    5.450821</td>\n",
        "      <td>    4.641696</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   1.709528</td>\n",
        "      <td>    1.107147</td>\n",
        "      <td>    6.659212</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>NaN</td>\n",
        "      <td> -44.963484</td>\n",
        "      <td>  -45.411611</td>\n",
        "      <td>  -45.888449</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.015600</td>\n",
        "      <td>    5.360962</td>\n",
        "      <td>    5.484921</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.246601</td>\n",
        "      <td>    5.472068</td>\n",
        "      <td>    5.540429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.508012</td>\n",
        "      <td>    5.575864</td>\n",
        "      <td>    5.589770</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>NaN</td>\n",
        "      <td>   5.946941</td>\n",
        "      <td>    5.896579</td>\n",
        "      <td>    5.802625</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 183,
       "text": [
        "       0.9        0.95          1.0          1.2\n",
        "count    0  887.000000  2148.000000  3119.000000\n",
        "mean   NaN    5.209998     5.450821     4.641696\n",
        "std    NaN    1.709528     1.107147     6.659212\n",
        "min    NaN  -44.963484   -45.411611   -45.888449\n",
        "25%    NaN    5.015600     5.360962     5.484921\n",
        "50%    NaN    5.246601     5.472068     5.540429\n",
        "75%    NaN    5.508012     5.575864     5.589770\n",
        "max    NaN    5.946941     5.896579     5.802625"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#any key in output_dict that is suffixed with \"_\" should get its own file\n",
      "#what should the output file names look like?\n",
      "\n",
      "#make dir with \n",
      "small_info = {}\n",
      "for key,val in output_dict.items():\n",
      "    #print\n",
      "    if key.endswith('_'):\n",
      "        path = output_dict['File_Path']\n",
      "        basefile = os.path.basename(path)\n",
      "        file_name_parts = basefile.split(\"-\")\n",
      "        new_file_name = \"-\".join([key[:-1]]+file_name_parts[1:])\n",
      "        print key, basefile, new_file_name\n",
      "        #print type(val)\n",
      "        #now write file\n",
      "    else:\n",
      "        small_info[key] = val\n",
      "print\n",
      "print small_info\n",
      "output_dict.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{'burst_stat_data':       duration mean  duration std     ibi mean    ibi std\n",
        "0.9             NaN           NaN          NaN        NaN\n",
        "0.95     356.812619      7.056491  8567.724731   6.024775\n",
        "1.0      317.836380      8.984696  2602.449887   8.342934\n",
        "1.2      382.375127     13.851072  1441.743773  13.674764, 'peak_amp_temp':        0.9        0.95          1.0          1.2\n",
        "count    0  887.000000  2148.000000  3119.000000\n",
        "mean   NaN    5.209998     5.450821     4.641696\n",
        "std    NaN    1.709528     1.107147     6.659212\n",
        "min    NaN  -44.963484   -45.411611   -45.888449\n",
        "25%    NaN    5.015600     5.360962     5.484921\n",
        "50%    NaN    5.246601     5.472068     5.540429\n",
        "75%    NaN    5.508012     5.575864     5.589770\n",
        "max    NaN    5.946941     5.896579     5.802625, 'ibi_thresh': 200, 'File_Path': 'C:\\\\Users\\\\mfinemorris\\\\Desktop\\\\Parallel Model Code\\\\Results\\\\voltage-TBModel-sec300-IP-gL2_5.txt', 'rate': 0.1000000333333444, 'exp': 'TBModel with sec300, IP, gL2_5', 'sg_setting': 301}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 124,
       "text": [
        "['burst_stat_data',\n",
        " 'peak_amp_temp',\n",
        " 'sg_setting',\n",
        " 'File_Path',\n",
        " 'rate',\n",
        " 'exp',\n",
        " 'ibi_thresh']"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def all_time_series(data_raw, peaks, bursts, exp, output_directory):\n",
      "    '''\n",
      "    create and save all time series. requires that event detection has been performed. \n",
      "    saves out plots of graphs with the same scale, 30 s - 45 s.\n",
      "    '''\n",
      "    \n",
      "    for label, column in data_raw.iteritems():\n",
      "        \n",
      "        plt.figure()\n",
      "        plt.plot(data_raw.index, data_raw[label], color = 'k')\n",
      "        plt.plot(peaks[label].index, peaks[label]['Amplitude'], marker ='^', color = 'g', linestyle = 'None')\n",
      "        for index, row in bursts[label]['Start'].iteritems():\n",
      "            plt.plot(row, peaks[label]['Amplitude'].loc[row], marker ='^', color = 'm', linestyle = 'None')\n",
      "        for index, row in bursts[label]['End'].iteritems():\n",
      "            plt.plot(row, peaks[label]['Amplitude'].loc[row], marker ='^', color = 'y', linestyle = 'None')\n",
      "        plt.xlim(xmin = 30000, xmax = 45000)\n",
      "        plt.title('%s - %s' %(exp, label))\n",
      "        plt.xlabel('Time (ms)')\n",
      "        plt.ylabel('Voltage')\n",
      "        plt.savefig(r'%s/Time Series - %s.pdf'%(output_directory, label))\n",
      "        plt.close()\n",
      "\n",
      "all_time_series(data_raw, peaks, bursts, exp, output_directory)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in plt.get_fignums():\n",
      "    plt.figure(i)\n",
      "    plt.show()\n",
      "    plt.savefig('figure%d.png' % i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}